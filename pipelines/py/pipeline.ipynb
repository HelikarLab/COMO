{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This jupyter notebook run MADRID pipeline to identify drug targets and repurposing drugs for user-defined complex human diseases. The entire process contains four steps:\n",
    "1. Download and analyze transcriptomics and proteomics data, output a list of active genes.\n",
    "2. Create tissue specific models based on the list of active genes. If required the user can manually refine these models and supply them in Step 4. \n",
    "3. Identifying differential gene expressions from disease datasets.\n",
    "4. Identifying drug targets and repruposable drugs. This step consists of four substeps. \n",
    " (i) mapping drugs on automatically created or user-supplied models, (ii) knock-out simulation, (iii) compare simulation results of perturbed and unperturbed models, and (iv) integrate with disease genes and score drug targets.\n",
    "\n",
    "The users needs to create the input files for each step and upload input files to the docker container `/root/pipelines/data/`, and specify the input files in this notebook. In the original docker image, some exemplary input files are included to build metabolic models of naive, Th1, Th2, and Th17 subtypes and identify drug targets for rheumatoid arthritis. User should follow the documentation and the format of the exemplary input files to create your own input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyteruser/work\n"
     ]
    }
   ],
   "source": [
    "# import necessary python packages\n",
    "import sys\n",
    "import os\n",
    "import pandas\n",
    "import numpy\n",
    "import json\n",
    "import re\n",
    "from subprocess import call\n",
    "from project import configs\n",
    "\n",
    "\n",
    "# print root path of the project\n",
    "print(configs.rootdir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Identifying gene activity by analyzing transcriptomics and proteomics datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 1 here ***\n",
    "\n",
    "If proteomics data is not availabe, use:\n",
    "\n",
    "proteomics_data_file = 'dummy_proteomics_data.xlsx'\n",
    "\n",
    "proteomics_config_file = 'dummy_proteomics_config.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31mSystem has not been booted with systemd as init system (PID 1). Can't operate.\u001b[0m\n",
      "\u001b[0;1;31mFailed to create bus connection: Host is down\u001b[0m\n",
      "['bulkRNAPreprocess.py', '-n', 'NaiveB', '-c', 'True', '-f', 'Ensembl', '-t', 'quantile']\n",
      "Input directory is \"/home/jupyteruser/work/data/bulkData/NaiveB\"\n",
      "Output directory is \"/home/jupyteruser/work/data\"\n",
      "Active gene determination technique is \"quantile\"\n",
      "Creating Counts Matrix\n",
      "[1] \"/home/jupyteruser/work/data/bulkData/NaiveB\"\n",
      "Count Matrix written at  /home/jupyteruser/work/data/BulkRNAseqDataMatrix_NaiveB.csv \n",
      "Fetching gene info using genes in \"/home/jupyteruser/work/data/BulkRNAseqDataMatrix_NaiveB.csv\"\n",
      "retrieve 0:500\n",
      "retrieve 500:1000\n",
      "retrieve 1000:1500\n",
      "retrieve 1500:2000\n",
      "retrieve 2000:2500\n",
      "retrieve 2500:3000\n",
      "retrieve 3000:3500\n",
      "retrieve 3500:4000\n",
      "retrieve 4000:4500\n",
      "retrieve 4500:5000\n",
      "retrieve 5000:5500\n",
      "retrieve 5500:6000\n",
      "retrieve 6000:6500\n",
      "retrieve 6500:7000\n",
      "retrieve 7000:7500\n",
      "retrieve 7500:8000\n",
      "retrieve 8000:8500\n",
      "retrieve 8500:9000\n",
      "retrieve 9000:9500\n",
      "retrieve 9500:10000\n",
      "retrieve 10000:10500\n",
      "retrieve 10500:11000\n",
      "retrieve 11000:11500\n",
      "retrieve 11500:12000\n",
      "retrieve 12000:12500\n",
      "retrieve 12500:13000\n",
      "retrieve 13000:13500\n",
      "retrieve 13500:14000\n",
      "retrieve 14000:14500\n",
      "retrieve 14500:15000\n",
      "retrieve 15000:15500\n",
      "retrieve 15500:16000\n",
      "retrieve 16000:16500\n",
      "retrieve 16500:17000\n",
      "retrieve 17000:17500\n",
      "retrieve 17500:18000\n",
      "retrieve 18000:18500\n",
      "retrieve 18500:19000\n",
      "retrieve 19000:19500\n",
      "retrieve 19500:20000\n",
      "retrieve 20000:20500\n",
      "retrieve 20500:21000\n",
      "retrieve 21000:21500\n",
      "retrieve 21500:22000\n",
      "retrieve 22000:22500\n",
      "retrieve 22500:23000\n",
      "retrieve 23000:23500\n",
      "retrieve 23500:24000\n",
      "retrieve 24000:24500\n",
      "retrieve 24500:25000\n",
      "retrieve 25000:25500\n",
      "retrieve 25500:26000\n",
      "retrieve 26000:26500\n",
      "retrieve 26500:27000\n",
      "retrieve 27000:27500\n",
      "retrieve 27500:28000\n",
      "retrieve 28000:28500\n",
      "retrieve 28500:29000\n",
      "retrieve 29000:29500\n",
      "retrieve 29500:30000\n",
      "retrieve 30000:30500\n",
      "retrieve 30500:31000\n",
      "retrieve 31000:31500\n",
      "retrieve 31500:32000\n",
      "retrieve 32000:32500\n",
      "retrieve 32500:33000\n",
      "retrieve 33000:33500\n",
      "retrieve 33500:34000\n",
      "retrieve 34000:34500\n",
      "retrieve 34500:35000\n",
      "retrieve 35000:35500\n",
      "retrieve 35500:36000\n",
      "retrieve 36000:36500\n",
      "retrieve 36500:37000\n",
      "retrieve 37000:37500\n",
      "retrieve 37500:38000\n",
      "retrieve 38000:38500\n",
      "retrieve 38500:39000\n",
      "retrieve 39000:39500\n",
      "retrieve 39500:40000\n",
      "retrieve 40000:40500\n",
      "retrieve 40500:41000\n",
      "retrieve 41000:41500\n",
      "retrieve 41500:42000\n",
      "retrieve 42000:42500\n",
      "retrieve 42500:43000\n",
      "retrieve 43000:43500\n",
      "retrieve 43500:44000\n",
      "retrieve 44000:44500\n",
      "retrieve 44500:45000\n",
      "retrieve 45000:45500\n",
      "retrieve 45500:46000\n",
      "retrieve 46000:46500\n",
      "retrieve 46500:47000\n",
      "retrieve 47000:47500\n",
      "retrieve 47500:48000\n",
      "retrieve 48000:48500\n",
      "retrieve 48500:49000\n",
      "retrieve 49000:49500\n",
      "retrieve 49500:50000\n",
      "retrieve 50000:50500\n",
      "retrieve 50500:51000\n",
      "retrieve 51000:51500\n",
      "retrieve 51500:52000\n",
      "retrieve 52000:52500\n",
      "retrieve 52500:53000\n",
      "retrieve 53000:53500\n",
      "retrieve 53500:54000\n",
      "retrieve 54000:54500\n",
      "retrieve 54500:55000\n",
      "retrieve 55000:55500\n",
      "retrieve 55500:56000\n",
      "retrieve 56000:56500\n",
      "retrieve 56500:57000\n",
      "retrieve 57000:57500\n",
      "retrieve 57500:58000\n",
      "retrieve 58000:58500\n",
      "retrieve 58500:59000\n",
      "retrieve 59000:59500\n",
      "retrieve 59500:60000\n",
      "retrieve 60000:60500\n",
      "retrieve 60500:60671\n",
      "Gene Info file written at \"/home/jupyteruser/work/data/GeneInfo_NaiveB.csv\"\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Preprocess bulk RNAseq dat by generate count matrix from gene counts files\n",
    "# generated from STAR and/or fetching necessary gene info from BioDBnet\n",
    "\n",
    "technique = \"quantile\"      # technique for bulk RNA-seq active gene determination\n",
    "                            # for count matrix gen, only used to determine whether or not\n",
    "                            # picard output mean fragment sizes are required.\n",
    "\n",
    "tissue_name = \"NaiveB\"\n",
    "create_counts_matrix = True # set to false if using a pregenerated matrix file\n",
    "gene_format = \"Ensembl\"     # accepts 'Entrez', 'Ensembl', and 'Symbol'\n",
    "    \n",
    "cmd = ' '.join(['python3', 'bulkRNAPreprocess.py',\n",
    "                '-n', '\"{}\"'.format(tissue_name),\n",
    "                '-c', '\"{}\"'.format(create_counts_matrix),\n",
    "                '-f', '\"{}\"'.format(gene_format),\n",
    "                '-t', '\"{}\"'.format(technique)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific input files for step 1\n",
    "\n",
    "# config file for microarray\n",
    "transcriptomics_config_file = 'transcriptomics_data_inputs.xlsx'\n",
    "\n",
    "# count matrix file for bulk rna-seq\n",
    "bulk_data_file = 'BulkRNAseqDataMatrix_NaiveB.csv'\n",
    "\n",
    "# config for bulk rna-seq\n",
    "bulk_config_file = 'bulk_data_inputs.xlsx'\n",
    "\n",
    "# gene info file for bulk rna-seq\n",
    "gene_info_file = 'GeneInfo_NaiveB.csv'\n",
    "\n",
    "# data file for proteomics\n",
    "proteomics_data_file = 'ProteomicsDataMatrix.xlsx' \n",
    "\n",
    "# config file for proteomics\n",
    "proteomics_config_file = 'proteomics_data_inputs.xlsx'\n",
    "\n",
    "# ratio of replicates required for a gene to be considered active in that sample\n",
    "expression_proportion = 0.5\n",
    "\n",
    "# Genes can be considered high confidence (labeled as 'top') if they are expressed\n",
    "# in a high proportion of samples. High confidence genes will be considered expressed\n",
    "# regardless of agreement with other data sources\n",
    "top_proportion = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file is  transcriptomics_data_inputs.xlsx\n",
      "Expression Proportion for Gene Expression is  0.5\n",
      "Top proportion for high-confidence genes is  0.9\n",
      "---\n",
      "Start Collecting Data for:\n",
      "['GSE22886' 'GSE43005' 'GSE22045' 'GSE24634']\n",
      "['GSM565273' 'GSM565274' 'GSM565275' 'GSM565290' 'GSM565291' 'GSM565292'\n",
      " 'GSM1054773' 'GSM1054779' 'GSM1054781' 'GSM1054789' 'GSM548000'\n",
      " 'GSM548001' 'GSM607510' 'GSM607511' 'GSM607512']\n",
      "---\n",
      "\n",
      "Initialize project (GSE22886):\n",
      "Root: /home/jupyteruser/work\n",
      "Raw data: /home/jupyteruser/work/data/GSE22886_RAW\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565273.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565274.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565275.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565290.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565291.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565292.tar\n",
      "Retrieve Samples Completed.\n",
      "GSE22886 already in database, skip over.\n",
      "Initialize project (GSE43005):\n",
      "Root: /home/jupyteruser/work\n",
      "Raw data: /home/jupyteruser/work/data/GSE43005_RAW\n",
      "Sample exist: /home/jupyteruser/work/data/GSE43005_RAW/GSM1054773.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE43005_RAW/GSM1054779.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE43005_RAW/GSM1054781.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE43005_RAW/GSM1054789.tar\n",
      "Retrieve Samples Completed.\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "Need Append GSMs\n",
      "Create new table: /home/jupyteruser/work/data/GSE43005_RAW/GSE43005_sc500_full_table.csv\n",
      "agilent Read Path: /home/jupyteruser/work/data/GSE43005_RAW/GPL14550\n",
      "Read GSM1054773_US91203659_252800415876_S01_GE1_107_Sep09_1_1.txt.gz \n",
      "Read GSM1054779_US91203659_252800415876_S01_GE1_107_Sep09_2_3.txt.gz \n",
      "Read GSM1054781_US91203659_252800415877_S01_GE1_107_Sep09_1_1.txt.gz \n",
      "Read GSM1054789_US91203659_252800415878_S01_GE1_107_Sep09_1_1.txt.gz \n",
      "Array 1 corrected\n",
      "Array 2 corrected\n",
      "Array 3 corrected\n",
      "Array 4 corrected\n",
      "GPL14550: (0, 13)\n",
      "Full: (0, 13)\n",
      "Full table saved to:\n",
      "/home/jupyteruser/work/data/GSE43005_RAW/GSE43005_sc500_full_table.csv\n",
      "Initialize project (GSE22045):\n",
      "Root: /home/jupyteruser/work\n",
      "Raw data: /home/jupyteruser/work/data/GSE22045_RAW\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22045_RAW/GSM548000.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22045_RAW/GSM548001.tar\n",
      "Retrieve Samples Completed.\n",
      "GSE22045 already in database, skip over.\n",
      "Initialize project (GSE24634):\n",
      "Root: /home/jupyteruser/work\n",
      "Raw data: /home/jupyteruser/work/data/GSE24634_RAW\n",
      "Sample exist: /home/jupyteruser/work/data/GSE24634_RAW/GSM607510.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE24634_RAW/GSM607511.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE24634_RAW/GSM607512.tar\n",
      "Retrieve Samples Completed.\n",
      "GSE24634 already in database, skip over.\n",
      "900 single ENTREZ_GENE_IDs to merge\n",
      "id_list: 3853, set: 3014\n",
      "entrez_single_id_list: 20486, set: 20486\n",
      "entrez_id_list: 1393, set: 1393\n",
      "dups: 1322, set: 483\n",
      "1125 id merged\n",
      "Save to /home/jupyteruser/work/data/transcriptomics_Naive.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1.1 Download and analyze transcriptomics\n",
    "cmd = ' '.join(['python3', 'transcriptomic_gen.py', \n",
    "      '-i', '\"{}\"'.format(transcriptomics_config_file),\n",
    "      '-e', '\"{}\"'.format(expression_proportion),\n",
    "      '-t', '\"{}\"'.format(top_proportion)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31mSystem has not been booted with systemd as init system (PID 1). Can't operate.\u001b[0m\n",
      "\u001b[0;1;31mFailed to create bus connection: Host is down\u001b[0m\n",
      "Data file is \"BulkRNAseqDataMatrix_NaiveB.csv\"\n",
      "Supplementary Data file is \"bulk_data_inputs.xlsx\"\n",
      "Gene info file is \"GeneInfo_NaiveB.csv\"\n",
      "Output File is \"/home/jupyteruser/work/data/Bulk_Naive.csv\"\n",
      "[1] \"Reading Counts Matrix\"\n",
      "[1] \"Naive_B_S1R1\"\n",
      "[1] \"Naive_B_S1R2\"\n",
      "[1] \"Naive_B_S1R3\"\n",
      "[1] \"Naive_B_S1R4\"\n",
      "[1] \"Naive_B_S2R1\"\n",
      "[1] \"Naive_B_S2R2\"\n",
      "[1] \"Naive_B_S2R3\"\n",
      "[1] \"Naive_B_S2R4\"\n",
      "[1] \"Naive_B_S3R1\"\n",
      "[1] \"Naive_B_S3R2\"\n",
      "[1] \"Naive_B_S3R3\"\n",
      "[1] \"Naive_B_S3R4\"\n",
      "[1] \"Naive_B_S3R5\"\n",
      "[1] \"Naive_B_S3R6\"\n",
      "[1] \"merge complete\"\n",
      "[1] \"Filtering Counts\"\n",
      "Test data saved to /home/jupyteruser/work/data/Bulk_Naive.csv\n"
     ]
    }
   ],
   "source": [
    "# step 1.2 Analyze Bulk-RNA-seq \n",
    "\n",
    "# Bulk-RNA-seq can handle many more parameters, \n",
    "# bulk_data_file, bulk_config_file, gene_format, and species_dataset are required.\n",
    "\n",
    "exp_prop_rep = 0.5     # proportion of replicates for a gene to be active in a sample\n",
    "exp_prop_samp = 0.5    # proportion of samples with expression required for gene  \n",
    "top_prop_rep = 0.9     # proportion of replicates with expression required for high-confidence\n",
    "top_prop_samp = 0.9    # proportion of replicates with expression required for high-confidence\n",
    "technique = \"quantile\" # filtering technique for active gene detrmination\n",
    "quantile = 90          # cutoff TPM percentile for quantile filtering \n",
    "\n",
    "cmd = ' '.join(['python3', 'bulk_gen.py', \n",
    "      '-i', '\"{}\"'.format(bulk_data_file),   \n",
    "      '-c', '\"{}\"'.format(bulk_config_file), \n",
    "      '-g', '\"{}\"'.format(gene_info_file), \n",
    "      '-r', '\"{}\"'.format(exp_prop_rep),   \n",
    "      '-s', '\"{}\"'.format(exp_prop_samp),        \n",
    "      '-x', '\"{}\"'.format(top_prop_rep),    \n",
    "      '-y', '\"{}\"'.format(top_prop_samp),   \n",
    "      '-t', '\"{}\"'.format(technique),        \n",
    "      '-q', '\"{}\"'.format(quantile)])       \n",
    "                \n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file is \"ProteomicsDataMatrix.xlsx\"\n",
      "Supplementary Data file is \"proteomics_data_inputs.xlsx\"\n",
      "Test Data Saved to /home/jupyteruser/work/data/Proteomics_Naive.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1.3 Analyze proteomics\n",
    "quantile = 90\n",
    "\n",
    "cmd = ' '.join(['python3', 'proteomics_gen.py', \n",
    "      '-d', '\"{}\"'.format(proteomics_data_file), \n",
    "      '-s', '\"{}\"'.format(proteomics_config_file),\n",
    "      '-e', '\"{}\"'.format(expression_proportion),\n",
    "      '-t', '\"{}\"'.format(top_proportion),\n",
    "      '-p', '\"{}\"'.format(quantile)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31mSystem has not been booted with systemd as init system (PID 1). Can't operate.\u001b[0m\n",
      "\u001b[0;1;31mFailed to create bus connection: Host is down\u001b[0m\n",
      "Transcriptomics file is \"transcriptomics_data_inputs.xlsx\"\n",
      "Proteomics file is \"proteomics_data_inputs.xlsx\"\n",
      "Bulk RNA-seq file is \"bulk_data_inputs_test.csv\"\n",
      "Read from /home/jupyteruser/work/data/transcriptomics_Naive.csv\n",
      "proteomics exists\n",
      "Test Data Load From /home/jupyteruser/work/data/Proteomics_Naive.csv\n",
      "bulk exists\n",
      "Test Data Load From /home/jupyteruser/work/data/Bulk_Naive.csv\n",
      "2171 single ENTREZ_GENE_IDs to merge\n",
      "id_list: 3447, set: 3234\n",
      "entrez_single_id_list: 26988, set: 26987\n",
      "entrez_id_list: 1306, set: 1291\n",
      "dups: 401, set: 188\n",
      "1208 id merged\n",
      "Naive: save to /home/jupyteruser/work/data/GeneExpression_Naive_Merged.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1.4 Merge the gene lists of transcriptomics and proteomics, create a list of active gene IDs\n",
    "\n",
    "expression_requirement=2 # number of data souces with expression required for a gene\n",
    "                         # to be considered active if not a top gene for any source\n",
    "                         # (defaults to the total number of input data sources)\n",
    "\n",
    "cmd = ' '.join(['python3', 'merge_xomics.py', \n",
    "      '-t', '\"{}\"'.format(transcriptomics_config_file),\n",
    "      '-b', '\"{}\"'.format(bulk_config_file),\n",
    "      '-p', '\"{}\"'.format(proteomics_config_file),\n",
    "      '-r', '\"{}\"'.format(expression_requirement)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create tissue-specific or cell-type-specific Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Naive': '/home/jupyteruser/work/data/GeneExpression_Naive_Merged.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Load the output of step 1, which is a dictionary that specifies the merged list of active Gene IDs for each tissue\n",
    "\n",
    "step1_results_file = os.path.join(configs.rootdir, 'data', 'step1_results_files.json')\n",
    "with open(step1_results_file) as json_file:\n",
    "    tissue_gene_exp = json.load(json_file)\n",
    "print(tissue_gene_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 2 here ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (input) filename of General Model, Recon3D_Teff_ver2\n",
    "GeneralModelFile = 'GeneralModel.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Model file is \"GeneralModel.mat\"\n",
      "Gene Expression file is \"GeneExpression_Naive_Merged.csv\"\n",
      "Output file is \"Naive_SpecificModel.mat\"\n",
      "Using \"GIMME\" reconstruction algorithm\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "/usr/local/lib/python3.8/dist-packages/cobamp/gpr/core.py:115: UserWarning: Will not normalize rules with more than 20 average tokens per gene\n",
      "  warnings.warn(\n",
      "Map gene expression to reactions, 0 errors.\n",
      "Could not set parameters with this solver\n",
      "Could not set parameters with this solver\n",
      "Could not set parameters with this solver\n",
      "Genes: 1506\n",
      "Metabolites: 5693\n",
      "Reactions: 8592\n",
      "1.0*biomass_reaction_Mphage - 1.0*biomass_reaction_Mphage_reverse_6cff5\n",
      "<Solution 0.386 at 0x7efe0f273b80>\n",
      "{'Naive': 'Naive_SpecificModel.mat'}\n"
     ]
    }
   ],
   "source": [
    "# create tissue specific model, the names of output files are stored in dictionary tissue_spec_model\n",
    "tissue_spec_model = {}\n",
    "reconAlgorithm = \"GIMME\" # troppo reconstruction algorithm to use\n",
    "\n",
    "for key,value in tissue_gene_exp.items():\n",
    "    tissuefile = '{}_SpecificModel.mat'.format(key)\n",
    "    tissue_spec_model[key] = tissuefile\n",
    "    tissue_gene_file = re.split('/|\\\\\\\\', value)[-1]\n",
    "    tissue_gene_folder = os.path.join(configs.rootdir, 'data', key)\n",
    "    os.makedirs(tissue_gene_folder, exist_ok=True)\n",
    "    cmd = ' '.join(['python3', 'create_tissue_specific_model.py', \n",
    "                      '-m', '\"{}\"'.format(GeneralModelFile), \n",
    "                      '-g', '\"{}\"'.format(tissue_gene_file),\n",
    "                      '-o', '\"{}\"'.format(tissuefile),\n",
    "                      '-a', '\"{}\"'.format(reconAlgorithm)])\n",
    "    !{cmd}\n",
    "\n",
    "print(tissue_spec_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Identifying disease related genes by analyzing transcriptomics data of patients\n",
    "Differential Expression Analysis\n",
    "\n",
    "Only 1 disease to be analyzed, output files in data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 3 here ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input filename transcriptomics data of disease\n",
    "disease_config_file = 'disease_transcriptomics_data_inputs.xlsx'\n",
    "disease_bulk_config_file = 'disease_bulk_data_inputs.xlsx'\n",
    "disease_bulk_count_matrix = 'GSE149050_Bulk_Human_Tcell_RawCounts_Entrez.csv'\n",
    "data_source = 'bulk'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GSE': 'bulk', 'UP_Reg': '/home/jupyteruser/work/data/Disease_UP_bulk.txt', 'DN_Reg': '/home/jupyteruser/work/data/Disease_DOWN_bulk.txt', 'RAW_Data': '/home/jupyteruser/work/data/Raw_Fit_bulk.csv'}\n"
     ]
    }
   ],
   "source": [
    "# load the results of step 3 to dictionary 'disease_files'\n",
    "step3_results_file = os.path.join(configs.datadir, 'step2_results_files.json')\n",
    "with open(step3_results_file) as json_file:\n",
    "    disease_files = json.load(json_file)\n",
    "print(disease_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file is \" disease_bulk_data_inputs.xlsx\n",
      "Count Matrix File is \" GSE149050_Bulk_Human_Tcell_RawCounts_Entrez.csv\n",
      "[1] \"Reading Counts Matrix\"\n",
      "[1] \"Performing DGE\"\n",
      "disease_analysis.py:140: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Disease_UP.dropna(how='any', subset=['Gene ID'], inplace=True)\n",
      "disease_analysis.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Disease_DOWN.dropna(how='any', subset=['Gene ID'], inplace=True)\n",
      "retrieve 0:500\n",
      "retrieve 500:1000\n",
      "retrieve 1000:1500\n",
      "retrieve 1500:2000\n",
      "retrieve 2000:2500\n",
      "retrieve 2500:3000\n",
      "retrieve 3000:3500\n",
      "retrieve 3500:4000\n",
      "retrieve 4000:4500\n",
      "retrieve 4500:5000\n",
      "retrieve 5000:5500\n",
      "retrieve 5500:6000\n",
      "retrieve 6000:6500\n",
      "retrieve 6500:7000\n",
      "retrieve 7000:7500\n",
      "retrieve 7500:8000\n",
      "retrieve 8000:8500\n",
      "retrieve 8500:9000\n",
      "retrieve 9000:9500\n",
      "retrieve 9500:10000\n",
      "retrieve 10000:10500\n",
      "retrieve 10500:11000\n",
      "retrieve 11000:11500\n",
      "retrieve 11500:12000\n",
      "retrieve 12000:12500\n",
      "retrieve 12500:13000\n",
      "retrieve 13000:13500\n",
      "retrieve 13500:14000\n",
      "retrieve 14000:14500\n",
      "retrieve 14500:15000\n",
      "retrieve 15000:15500\n",
      "retrieve 15500:16000\n",
      "retrieve 16000:16500\n",
      "retrieve 16500:17000\n",
      "retrieve 17000:17500\n",
      "retrieve 17500:18000\n",
      "retrieve 18000:18500\n",
      "retrieve 18500:19000\n",
      "retrieve 19000:19500\n",
      "retrieve 19500:20000\n",
      "retrieve 20000:20500\n",
      "retrieve 20500:21000\n",
      "retrieve 21000:21500\n",
      "retrieve 21500:22000\n",
      "retrieve 22000:22500\n",
      "retrieve 22500:23000\n",
      "retrieve 23000:23500\n",
      "retrieve 23500:24000\n",
      "retrieve 24000:24500\n",
      "retrieve 24500:25000\n",
      "retrieve 25000:25500\n",
      "retrieve 25500:25774\n",
      "Raw Data saved to\n",
      "/home/jupyteruser/work/data/Raw_Fit_bulk.csv\n"
     ]
    }
   ],
   "source": [
    "# Differential gene expression analysis\n",
    "cmd = ' '.join(['python3', 'disease_analysis.py',\n",
    "              '-d', '\"{}\"'.format(data_source),\n",
    "              '-c', '\"{}\"'.format(disease_bulk_config_file),\n",
    "              '-m', '\"{}\"'.format(disease_bulk_count_matrix)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Identification of drug targets and repurposable drugs\n",
    "This step maps drug targets in metabolic models,prforms knock out simulation, and compare simulation results with disease genes and identifies drug targets and repurposable drugs\n",
    "\n",
    "*** Specify input files for step 4 here ***\n",
    "\n",
    "1. Instruction: A processed Drug-Target file is included in the `/root/pipelines/data/`. (Optional step) For the updated versions the users can download `Repurposing_Hub_export.txt` from [Drug Repurposing Hub](https://clue.io/repurposing-app). From the downloaded file first remove all the activators, agonists, and withdrawn drugs and then upload to to `/root/pipelines/data/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To use automatically created tissue specific models. Note: It is recommended to use refined and validated models for further analysis. User can define cutomized models in next sub-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'GSE': 'bulk', 'UP_Reg': '/home/jupyteruser/work/data/Disease_UP_bulk.txt', 'DN_Reg': '/home/jupyteruser/work/data/Disease_DOWN_bulk.txt', 'RAW_Data': '/home/jupyteruser/work/data/Raw_Fit_bulk.csv'}\n"
     ]
    }
   ],
   "source": [
    "# load the results of step 3 to dictionary 'disease_files'\n",
    "step3_results_file = os.path.join(configs.datadir, 'step2_results_files.json')\n",
    "with open(step3_results_file) as json_file:\n",
    "    disease_files = json.load(json_file)\n",
    "print(disease_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Naive': 'Naive_SpecificModel.mat'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tissue specific models\n",
    "tissue_spec_model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disease_Down = disease_files['DN_Reg']\n",
    "Disease_Up = disease_files['UP_Reg']\n",
    "drug_raw_file = 'Repurposing_Hub_export.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. To use customized model, please specify `tissue_spec_model` manually, e.g. uncomment tissue_spec_model in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually specify Up and Down Regulated Genes for Disease. (Please upload manually created files `/pipelines/data/`. Use filenames as given belwo or change them accordingly.)\n",
    "# Disease_Down = 'Disease_DOWN.txt'\n",
    "# Disease_Up = 'Disease_UP.txt'\n",
    "# drug_raw_file = 'Repurposing_Hub_export.txt'\n",
    "\n",
    "# Manually specify tissue specific models fine-tuned by user. Change names of the files accordingly. Users can use single or multiple models here. Using multiple models, simulation time will increase.\n",
    "# tissue_spec_model = {'Th1':'Th1Model.mat',\n",
    "#                      'Th2':'Th2Model.mat',\n",
    "#                      'Th17':'Th17Model.mat',\n",
    "#                      'Naive':'NaiveModel.mat'}\n",
    "\n",
    "# Manually specify tissue specific model created by matlab cobratoolbox. For example run, we have provided four models of CD4+ T cells (niave, Th1, Th2, and Th17) please uncomment all or any specific model\n",
    "# tissue_spec_model = {'Th1':'Th1_SpecificModel_matlab.mat',\n",
    "#                      'Th2':'Th2_SpecificModel_matlab.mat',\n",
    "#                      'Th17':'Th17_SpecificModel_matlab.mat',\n",
    "#                      'Naive':'Naive_SpecificModel_matlab.mat'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder: \"/home/jupyteruser/work/data/Naive\"\n",
      "Tissue Specific Model file is \"Naive_SpecificModel.mat\"\n",
      "Tissue Specific Inhibitors file is \"Naive_inhibitors_Entrez.txt\"\n",
      "retrieve 0:500\n",
      "retrieve 500:1000\n",
      "retrieve 1000:1500\n",
      "retrieve 1500:2000\n",
      "retrieve 2000:2500\n",
      "retrieve 2500:3000\n",
      "retrieve 3000:3500\n",
      "retrieve 3500:4000\n",
      "retrieve 4000:4500\n",
      "retrieve 4500:5000\n",
      "retrieve 5000:5500\n",
      "retrieve 5500:6000\n",
      "retrieve 6000:6500\n",
      "retrieve 6500:7000\n",
      "retrieve 7000:7500\n",
      "retrieve 7500:8000\n",
      "retrieve 8000:8500\n",
      "retrieve 8500:8875\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "1506\n",
      "1506\n",
      "288\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "# Knock out simulation for the analyzed tissues\n",
    "for key,value in tissue_spec_model.items():\n",
    "    tissueSpecificModelfile = value\n",
    "    tissue_gene_folder = os.path.join(configs.datadir, key)\n",
    "    os.makedirs(tissue_gene_folder, exist_ok=True)\n",
    "    inhibitors_file = '{}_inhibitors_Entrez.txt'.format(key)\n",
    "    cmd = ' '.join(['python3' , 'knock_out_simulation.py',\n",
    "                  '-t', tissueSpecificModelfile,\n",
    "                  '-i', inhibitors_file,\n",
    "                  '-u', Disease_Up,\n",
    "                  '-d', Disease_Down,\n",
    "                  '-f', key,\n",
    "                  '-r', drug_raw_file])\n",
    "    !{cmd}\n",
    "    \n",
    "    # copy generated output to output folder\n",
    "    cmd = ' '.join(['cp', '-a', os.path.join(configs.datadir, key), configs.outputdir])\n",
    "    !{cmd}\n",
    "    #break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
