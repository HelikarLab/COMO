{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This jupyter notebook run MADRID pipeline to identify drug targets and repurposing drugs for user-defined complex human diseases. The entire process contains five steps:\n",
    "\n",
    "0. Preprocess Bulk RNAseq data by converting STAR outputed Gene counts into a unified matrix and fetching necessary info about each gene needed for normalization via TPM or FPKM. \n",
    "1. Download and analyze microarray, bulk RNAseq, and proteomics data, output a list of active genes.\n",
    "2. Create tissue specific models based on the list of active genes. If required the user can manually refine these models and supply them in Step 4. \n",
    "3. Identify differential gene expressions from disease datasets using either microarray or bulk RNAseq transcriptomics information.\n",
    "4. Identify drug targets and repruposable drugs. This step consists of four substeps. \n",
    " (i) mapping drugs on automatically created or user-supplied models, (ii) knock-out simulation, (iii) compare simulation results of perturbed and unperturbed models, and (iv) integrate with disease genes and score drug targets.\n",
    "\n",
    "The user should upload config excel sheets to the docker container `/work/data/config_sheets`. The sheet names in these config files should correspond to different models where each sheet contains a list of the samples to include for that model. These sample names should correspond to the samples names in the source data which is defined in `/work/data/data_matrices/<model name>/`\n",
    "    \n",
    "In the original docker image, some exemplary input files are included to build metabolic models of naive, Th1, Th2, and Th17 subtypes and identify drug targets for rheumatoid arthritis. User should follow the documentation and the format of the exemplary input files to create your own input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating directory /home/jupyteruser/.config/bioservices \n",
      "/home/jupyteruser/work\n"
     ]
    }
   ],
   "source": [
    "# import necessary python packages\n",
    "import sys\n",
    "import os\n",
    "import pandas\n",
    "import numpy\n",
    "import json\n",
    "import re\n",
    "from subprocess import call\n",
    "from project import configs\n",
    "import bioservices\n",
    "\n",
    "# print root path of the project\n",
    "print(configs.rootdir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Preprocess Bulk RNA-seq data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulk RNA-seq data can be given as a count matrix where each column is a different sample/replicate named 'tissuename_SXRYrZ' where X is the sample or study number, Y is the replicate number, and Z is the run number. If the replicate does not contain multiple runs the rZ can be neglected. Replicates should come from the same study/sample group and different samples can come from different studies as long as the tissue/cell was under similar enough conditions for your model. \n",
    "\n",
    "If you wish to use raw .fastq data for your bulk RNA-seq inputs, you can align them with STAR using the --gene_counts option and rename the .tab outputs the same as the columns described above. Place the .tab files into a folder called SX where X is the unique study number for the tissue matching the filename. Place each study name folder into a folder titled the tissue name for the model you are building. Place the tissue folder into `/work/data/STAR_out`. An example of this file structure can be found in the STAR_out folder. If using STAR output, be sure that the '-c' argument is 'TRUE'.\n",
    "\n",
    "Currently, MADRID can filter raw RNA-seq counts using a flat cutoff of CPM (counts per million) normalized values and the recommended 'quantile' technique which normalizes using TPM (transcipts per million) and filters using an upper quantile. Future versions will also allow for the zFPKM method outlined in this paper: https://pubmed.ncbi.nlm.nih.gov/24215113/ \n",
    "\n",
    "Preprocessing will fetch relevent gene information needed for normalization such as the start and end postions, so be sure to supply either 'cpm' or 'quantile' as the -t argument in preprocess, and make sure its the same as the one used in bulk_gen.py in step 1. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31mSystem has not been booted with systemd as init system (PID 1). Can't operate.\u001b[0m\n",
      "\u001b[0;1;31mFailed to create bus connection: Host is down\u001b[0m\n",
      "['bulkRNAPreprocess.py', '-n', \"['liver_control']\", '-c', 'True', '-f', 'Ensembl', '-i', 'mouse', '-t', 'quantile']\n",
      "liver_control\n",
      "Input directory is \"/home/jupyteruser/work/data/STAR_output/liver_control\"\n",
      "Gene info output directory is \"/home/jupyteruser/work/data/results/liver_control\"\n",
      "Active gene determination technique is \"quantile\"\n",
      "Creating Counts Matrix\n",
      "[1] \"Organizing Files\"\n",
      "[1] 1\n",
      "[1] 2\n",
      "[1] 3\n",
      "[1] 4\n",
      "[1] 5\n",
      "[1] \"Creating counts matrix\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S3R2\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S3R3\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S4R3\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S4R4\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S4R5\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S4R6\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S5R3\"\n",
      "[1] \"pre-split\"\n",
      "[1] \"liver_control_S6R2r1\"\n",
      "[1] \"post-split\"\n",
      "[1] \"liver_control_S6R2\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S6R2\"\n",
      "[1] \"pre-split\"\n",
      "[1] \"liver_control_S6R3r1\"\n",
      "[1] \"post-split\"\n",
      "[1] \"liver_control_S6R3\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S6R3\"\n",
      "[1] \"pre-split\"\n",
      "[1] \"liver_control_S7R3r1\"\n",
      "[1] \"post-split\"\n",
      "[1] \"liver_control_S7R3\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S7R3\"\n",
      "[1] \"pre-split\"\n",
      "[1] \"liver_control_S7R4r1\"\n",
      "[1] \"post-split\"\n",
      "[1] \"liver_control_S7R4\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S7R4\"\n",
      "[1] \"pre-split\"\n",
      "[1] \"liver_control_S7R5r1\"\n",
      "[1] \"post-split\"\n",
      "[1] \"liver_control_S7R5\"\n",
      "[1] \"colname\"\n",
      "[1] \"liver_control_S7R5\"\n",
      "Count Matrix written at  /home/jupyteruser/work/data/data_matrices/liver_control/BulkRNAseqDataMatrix_liver_control.csv \n",
      "Fetching gene info using genes in \"/home/jupyteruser/work/data/data_matrices/liver_control/BulkRNAseqDataMatrix_liver_control.csv\"\n",
      "retrieve 0:300\n",
      "retrieve 300:600\n",
      "retrieve 600:900\n",
      "retrieve 900:1200\n",
      "retrieve 1200:1500\n",
      "retrieve 1500:1800\n",
      "retrieve 1800:2100\n",
      "retrieve 2100:2400\n",
      "retrieve 2400:2700\n",
      "retrieve 2700:3000\n",
      "retrieve 3000:3300\n",
      "retrieve 3300:3600\n",
      "retrieve 3600:3900\n",
      "retrieve 3900:4200\n",
      "retrieve 4200:4500\n",
      "retrieve 4500:4800\n",
      "retrieve 4800:5100\n",
      "retrieve 5100:5400\n",
      "retrieve 5400:5700\n",
      "retrieve 5700:6000\n",
      "retrieve 6000:6300\n",
      "retrieve 6300:6600\n",
      "retrieve 6600:6900\n",
      "retrieve 6900:7200\n",
      "retrieve 7200:7500\n",
      "retrieve 7500:7800\n",
      "retrieve 7800:8100\n",
      "retrieve 8100:8400\n",
      "retrieve 8400:8700\n",
      "retrieve 8700:9000\n",
      "retrieve 9000:9300\n",
      "retrieve 9300:9600\n",
      "retrieve 9600:9900\n",
      "retrieve 9900:10200\n",
      "retrieve 10200:10500\n",
      "retrieve 10500:10800\n",
      "retrieve 10800:11100\n",
      "retrieve 11100:11400\n",
      "retrieve 11400:11700\n",
      "retrieve 11700:12000\n",
      "retrieve 12000:12300\n",
      "retrieve 12300:12600\n",
      "retrieve 12600:12900\n",
      "retrieve 12900:13200\n",
      "retrieve 13200:13500\n",
      "retrieve 13500:13800\n",
      "retrieve 13800:14100\n",
      "retrieve 14100:14400\n",
      "retrieve 14400:14700\n",
      "retrieve 14700:15000\n",
      "retrieve 15000:15300\n",
      "retrieve 15300:15600\n",
      "retrieve 15600:15900\n",
      "retrieve 15900:16200\n",
      "retrieve 16200:16500\n",
      "retrieve 16500:16800\n",
      "retrieve 16800:17100\n",
      "retrieve 17100:17400\n",
      "retrieve 17400:17700\n",
      "retrieve 17700:18000\n",
      "retrieve 18000:18300\n",
      "retrieve 18300:18600\n",
      "retrieve 18600:18900\n",
      "retrieve 18900:19200\n",
      "retrieve 19200:19500\n",
      "retrieve 19500:19800\n",
      "retrieve 19800:20100\n",
      "retrieve 20100:20400\n",
      "retrieve 20400:20700\n",
      "retrieve 20700:21000\n",
      "retrieve 21000:21300\n",
      "retrieve 21300:21600\n",
      "retrieve 21600:21900\n",
      "retrieve 21900:22200\n",
      "retrieve 22200:22500\n",
      "retrieve 22500:22800\n",
      "retrieve 22800:23100\n",
      "retrieve 23100:23400\n",
      "retrieve 23400:23700\n",
      "retrieve 23700:24000\n",
      "retrieve 24000:24300\n",
      "retrieve 24300:24600\n",
      "retrieve 24600:24900\n",
      "retrieve 24900:25200\n",
      "retrieve 25200:25500\n",
      "retrieve 25500:25800\n",
      "retrieve 25800:26100\n",
      "retrieve 26100:26400\n",
      "retrieve 26400:26700\n",
      "retrieve 26700:27000\n",
      "retrieve 27000:27300\n",
      "retrieve 27300:27600\n",
      "retrieve 27600:27900\n",
      "retrieve 27900:28200\n",
      "retrieve 28200:28500\n",
      "retrieve 28500:28800\n",
      "retrieve 28800:29100\n",
      "retrieve 29100:29400\n",
      "retrieve 29400:29700\n",
      "retrieve 29700:30000\n",
      "retrieve 30000:30300\n",
      "retrieve 30300:30600\n",
      "retrieve 30600:30900\n",
      "retrieve 30900:31200\n",
      "retrieve 31200:31500\n",
      "retrieve 31500:31800\n",
      "retrieve 31800:32100\n",
      "retrieve 32100:32400\n",
      "retrieve 32400:32700\n",
      "retrieve 32700:33000\n",
      "retrieve 33000:33300\n",
      "retrieve 33300:33600\n",
      "retrieve 33600:33900\n",
      "retrieve 33900:34200\n",
      "retrieve 34200:34500\n",
      "retrieve 34500:34800\n",
      "retrieve 34800:35100\n",
      "retrieve 35100:35400\n",
      "retrieve 35400:35700\n",
      "retrieve 35700:36000\n",
      "retrieve 36000:36300\n",
      "retrieve 36300:36600\n",
      "retrieve 36600:36900\n",
      "retrieve 36900:37200\n",
      "retrieve 37200:37500\n",
      "retrieve 37500:37800\n",
      "retrieve 37800:38100\n",
      "retrieve 38100:38400\n",
      "retrieve 38400:38700\n",
      "retrieve 38700:39000\n",
      "retrieve 39000:39300\n",
      "retrieve 39300:39600\n",
      "retrieve 39600:39900\n",
      "retrieve 39900:40200\n",
      "retrieve 40200:40500\n",
      "retrieve 40500:40800\n",
      "retrieve 40800:41100\n",
      "retrieve 41100:41400\n",
      "retrieve 41400:41700\n",
      "retrieve 41700:42000\n",
      "retrieve 42000:42300\n",
      "retrieve 42300:42600\n",
      "retrieve 42600:42900\n",
      "retrieve 42900:43200\n",
      "retrieve 43200:43500\n",
      "retrieve 43500:43800\n",
      "retrieve 43800:44100\n",
      "retrieve 44100:44400\n",
      "retrieve 44400:44700\n",
      "retrieve 44700:45000\n",
      "retrieve 45000:45300\n",
      "retrieve 45300:45600\n",
      "retrieve 45600:45900\n",
      "retrieve 45900:46200\n",
      "retrieve 46200:46500\n",
      "retrieve 46500:46800\n",
      "retrieve 46800:47100\n",
      "retrieve 47100:47400\n",
      "retrieve 47400:47700\n",
      "retrieve 47700:48000\n",
      "retrieve 48000:48300\n",
      "retrieve 48300:48600\n",
      "retrieve 48600:48900\n",
      "retrieve 48900:49200\n",
      "retrieve 49200:49500\n",
      "retrieve 49500:49800\n",
      "retrieve 49800:50100\n",
      "retrieve 50100:50400\n",
      "retrieve 50400:50700\n",
      "retrieve 50700:51000\n",
      "retrieve 51000:51300\n",
      "retrieve 51300:51600\n",
      "retrieve 51600:51900\n",
      "retrieve 51900:52200\n",
      "retrieve 52200:52500\n",
      "retrieve 52500:52800\n",
      "retrieve 52800:53100\n",
      "retrieve 53100:53400\n",
      "retrieve 53400:53700\n",
      "retrieve 53700:54000\n",
      "retrieve 54000:54300\n",
      "retrieve 54300:54600\n",
      "retrieve 54600:54900\n",
      "retrieve 54900:55200\n",
      "retrieve 55200:55487\n",
      "Gene Info file written at \"/home/jupyteruser/work/data/results/liver_control/GeneInfo_liver_control.csv\"\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Preprocess bulk RNAseq dat by generate count matrix from gene counts files\n",
    "# generated from STAR and/or fetching necessary gene info from BioDBnet\n",
    "\n",
    "technique = \"quantile\"      # technique for bulk RNA-seq active gene determination\n",
    "                            # for count matrix gen, only used to determine whether or not\n",
    "                            # picard output mean fragment sizes are required.\n",
    "\n",
    "tissue_names = \"['liver_control']\"\n",
    "create_counts_matrix = True # set to false if using a pregenerated matrix file\n",
    "gene_format = \"Ensembl\"     # accepts 'Entrez', 'Ensembl', and 'Symbol'\n",
    "taxon_id = 'mouse'\n",
    "    \n",
    "cmd = ' '.join(['python3', 'bulkRNAPreprocess.py',\n",
    "                '-n', '\"{}\"'.format(tissue_names),\n",
    "                '-c', '\"{}\"'.format(create_counts_matrix),\n",
    "                '-f', '\"{}\"'.format(gene_format),\n",
    "                '-i', '\"{}\"'.format(taxon_id),\n",
    "                '-t', '\"{}\"'.format(technique)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Identifying gene activity by analyzing transcriptomics and proteomics datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 1 here ***\n",
    "\n",
    "All three data types are not needed for model generation. Skip any data sources not being used for your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific input files for step 1\n",
    "\n",
    "# config file for microarray\n",
    "microarray_config_file = 'microarray_data_inputs.xlsx'\n",
    "\n",
    "# config for bulk rna-seq\n",
    "bulk_config_file = 'bulk_data_inputs_mouse.xlsx'\n",
    "\n",
    "# config file for proteomics\n",
    "proteomics_config_file = 'proteomics_data_inputs.xlsx'\n",
    "\n",
    "# ratio of replicates required for a gene to be considered active in that sample\n",
    "expression_proportion = 0.5\n",
    "\n",
    "# Genes can be considered high confidence (labeled as 'top') if they are expressed\n",
    "# in a high proportion of samples. High confidence genes will be considered expressed\n",
    "# regardless of agreement with other data sources\n",
    "top_proportion = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "From cffi callback <function _processevents at 0x7f6b11e1b550>:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/rpy2/rinterface_lib/callbacks.py\", line 277, in _processevents\n",
      "    try:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/rpy2/rinterface.py\", line 87, in _sigint_handler\n",
      "    raise KeyboardInterrupt()\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# Step 1.1 Download and analyze microarray\n",
    "cmd = ' '.join(['python3', 'microarray_gen.py', \n",
    "      '-i', '\"{}\"'.format(microarray_config_file),\n",
    "      '-e', '\"{}\"'.format(expression_proportion),\n",
    "      '-t', '\"{}\"'.format(top_proportion)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31mSystem has not been booted with systemd as init system (PID 1). Can't operate.\u001b[0m\n",
      "\u001b[0;1;31mFailed to create bus connection: Host is down\u001b[0m\n",
      "Config file is \"bulk_data_inputs_mouse.xlsx\"\n",
      "Input count matrix is at \"/home/jupyteruser/work/data/data_matrices/liver_control/BulkRNAseqDataMatrix_liver_control.csv\"\n",
      "Gene info file is at \"/home/jupyteruser/work/data/results/liver_control/GeneInfo_liver_control.csv\"\n",
      "[1] \"Reading Counts Matrix\"\n",
      "[1] \"cmat\"\n",
      "[1] \"/home/jupyteruser/work/data/data_matrices/liver_control/BulkRNAseqDataMatrix_liver_control.csv\"\n",
      "[1] \"config\"\n",
      "[1] \"/home/jupyteruser/work/data/config_sheets/bulk_data_inputs_mouse.xlsx\"\n",
      "[1] \"info\"\n",
      "[1] \"/home/jupyteruser/work/data/results/liver_control/GeneInfo_liver_control.csv\"\n",
      "[1] \"model\"\n",
      "[1] \"liver_control\"\n",
      "[1] \"Filtering Counts\"\n",
      "Test data saved to /home/jupyteruser/work/data/results/liver_control/Bulk_liver_control.csv\n"
     ]
    }
   ],
   "source": [
    "# step 1.2 Analyze Bulk-RNA-seq \n",
    "\n",
    "exp_prop_rep = 0.5     # proportion of replicates for a gene to be active in a sample\n",
    "exp_prop_samp = 0.9    # proportion of samples with expression required for gene  \n",
    "top_prop_rep = 0.5     # proportion of replicates with expression required for high-confidence\n",
    "top_prop_samp = 0.9    # proportion of replicates with expression required for high-confidence\n",
    "technique = \"quantile\" # filtering technique for active gene detrmination\n",
    "quantile = 80           # cutoff TPM percentile for quantile filtering \n",
    "\n",
    "cmd = ' '.join(['python3', 'bulk_gen.py',   \n",
    "      '-c', '\"{}\"'.format(bulk_config_file), \n",
    "      '-r', '\"{}\"'.format(exp_prop_rep),   \n",
    "      '-s', '\"{}\"'.format(exp_prop_samp),        \n",
    "      '-x', '\"{}\"'.format(top_prop_rep),    \n",
    "      '-y', '\"{}\"'.format(top_prop_samp),   \n",
    "      '-t', '\"{}\"'.format(technique),        \n",
    "      '-q', '\"{}\"'.format(quantile)])       \n",
    "                \n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file is at \"/home/jupyteruser/work/data/config_sheets/proteomics_data_inputs.xlsx\"\n",
      "Data matrix is at \"/home/jupyteruser/work/data/data_matrices/Naive/ProteomicsDataMatrix_Naive.csv\"\n",
      "Test Data Saved to /home/jupyteruser/work/data/results/Naive/Proteomics_Naive.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1.3 Analyze proteomics\n",
    "quantile = 25\n",
    "\n",
    "cmd = ' '.join(['python3', 'proteomics_gen.py', \n",
    "      '-c', '\"{}\"'.format(proteomics_config_file),\n",
    "      '-e', '\"{}\"'.format(expression_proportion),\n",
    "      '-t', '\"{}\"'.format(top_proportion),\n",
    "      '-p', '\"{}\"'.format(quantile)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31mSystem has not been booted with systemd as init system (PID 1). Can't operate.\u001b[0m\n",
      "\u001b[0;1;31mFailed to create bus connection: Host is down\u001b[0m\n",
      "Microarray file is \"None\"\n",
      "Proteomics file is \"None\"\n",
      "Bulk RNA-seq file is \"bulk_data_inputs_mouse.xlsx\"\n",
      "Read from /home/jupyteruser/work/data/results/liver_control/Bulk_liver_control.csv\n",
      "83 single ENTREZ_GENE_IDs to merge\n",
      "id_list: 443, set: 394\n",
      "entrez_single_id_list: 26277, set: 26240\n",
      "entrez_id_list: 161, set: 161\n",
      "dups: 79, set: 30\n",
      "136 id merged\n",
      "liver_control: save to /home/jupyteruser/work/data/results/liver_control/GeneExpression_liver_control_Merged.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1.4 Merge the gene lists of transcriptomics and proteomics, create a list of active gene IDs\n",
    "\n",
    "expression_requirement=1 # number of data souces with expression required for a gene\n",
    "                         # to be considered active if not a top gene for any source\n",
    "                         # (defaults to the total number of input data sources)\n",
    "\n",
    "cmd = ' '.join(['python3', 'merge_xomics.py', \n",
    "      ##'-t', '\"{}\"'.format(microarray_config_file),\n",
    "      '-b', '\"{}\"'.format(bulk_config_file),\n",
    "      #'-p', '\"{}\"'.format(proteomics_config_file),\n",
    "      '-r', '\"{}\"'.format(expression_requirement)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 2: Create tissue-specific or cell-type-specific Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'liver_control': '/home/jupyteruser/work/data/results/liver_control/GeneExpression_liver_control_Merged.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Load the output of step 1, which is a dictionary that specifies the merged list of active Gene IDs for each tissue\n",
    "\n",
    "step1_results_file = os.path.join(configs.rootdir, 'data', 'results', 'step1_results_files.json')\n",
    "with open(step1_results_file) as json_file:\n",
    "    tissue_gene_exp = json.load(json_file)\n",
    "print(tissue_gene_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 2 here ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (input) filename of General Model, Recon3D_Teff_ver2\n",
    "GeneralModelFile = 'iMM1865_madrid.mat'\n",
    "#GeneralModelFile = 'GeneralModel.mat'\n",
    "excludeRxns = os.path.join(configs.datadir, 'inconsistant_rxns.csv') # flux inconsistant rxns to remove from core reactions in fastcore\n",
    "forceRxns = os.path.join(configs.datadir, 'lit_core_rxns.csv') \n",
    "reconAlgorithm = 'FASTCORE' # troppo reconstruction algorithm to use\n",
    "#objective = 'biomass_reaction_Mphage'\n",
    "objective = 'BIOMASS_reaction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tissue Name is \"liver_control\"\n",
      "General Model file is \"iMM1865_madrid.mat\"\n",
      "Gene Expression file is \"GeneExpression_liver_control_Merged.csv\"\n",
      "Output file is \"liver_control_SpecificModel.mat\"\n",
      "Using \"FASTCORE\" reconstruction algorithm\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "/usr/local/lib/python3.8/dist-packages/cobamp/gpr/core.py:115: UserWarning: Will not normalize rules with more than 20 average tokens per gene\n",
      "  warnings.warn(\n",
      "Map gene expression to reactions, 0 errors.\n",
      "J size2806\n",
      "[   30    31    32 ... 10608 10609 10611]\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-0.2805999999999854\n",
      "done LP7\n",
      "LP9\n",
      "Could not set parameters with this solver\n",
      "149974.14121764514\n",
      "Warning, Solution is not optimal\n",
      "done LP9\n",
      "197 5250\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-0.017900000000451777\n",
      "done LP7\n",
      "LP9\n",
      "Could not set parameters with this solver\n"
     ]
    }
   ],
   "source": [
    "# create tissue specific model, the names of output files are stored in dictionary tissue_spec_model\n",
    "tissue_spec_model = {}\n",
    "\n",
    "for key,value in tissue_gene_exp.items():\n",
    "    tissuefile = '{}_SpecificModel.mat'.format(key) # key is == tissue name\n",
    "    tissue_spec_model[key] = tissuefile\n",
    "    tissue_gene_file = re.split('/|\\\\\\\\', value)[-1]\n",
    "    #tissue_gene_folder = os.path.join(configs.rootdir, 'data', key)\n",
    "    #os.makedirs(tissue_gene_folder, exist_ok=True)\n",
    "    cmd = ' '.join(['python3', 'create_tissue_specific_model.py', \n",
    "                      '-t', '\"{}\"'.format(key),\n",
    "                      '-m', '\"{}\"'.format(GeneralModelFile), \n",
    "                      '-g', '\"{}\"'.format(tissue_gene_file),\n",
    "                      '-o', '\"{}\"'.format(tissuefile),\n",
    "                      '-s', '\"{}\"'.format(objective),\n",
    "                      '-x', '\"{}\"'.format(excludeRxns),\n",
    "                      #'-f', '\"{}\"'.format(forceRxns),\n",
    "                      '-a', '\"{}\"'.format(reconAlgorithm)])\n",
    "    !{cmd}\n",
    "\n",
    "print(tissue_spec_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Step 3: Identifying disease related genes by analyzing transcriptomics data of patients\n",
    "Differential Expression Analysis\n",
    "\n",
    "In the config_sheets folder, there should be a folder called \"disease\". You can add a spreadsheet for each cell/tissue type called `disease_data_inputs_<tissue_name>`. Each sheet of this file should correspond to a seperate disease to analyze using DGE nfor that tissue. The source data can be either microarray or bulk RNA-seq and is formatted the same as if creating the base tissue model. The sheet names should contain the disease name, an underscore, and than either \"microarray\" or \"bulk\" depending on the source data. For example, if the disease is lupus, and the source data is bulk RNA-seq, the name of the sheet should be \"lupus_bulk\". This can be seen in the example sheet. If using bulk RNA-seq data, there should be a count matrix file in `/work/data/data_matrices/<tissue_name>/disease/` called `BulkRNAseqDataMatrix_<disease name>_<tissue name>`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 3 here ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify tissue names to perform a disease analysis on. The diseases to analyze should be\n",
    "# specified in `/work/data/config_sheets/disease/diease_data_inputs_<tissue name>`\n",
    "tissue_names = ['Naive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file is at  /home/jupyteruser/work/data/config_sheets/disease/disease_data_inputs_Naive.xlsx\n",
      "Count Matrix File is at  /home/jupyteruser/work/data/data_matrices/Naive/disease/BulkRNAseqDataMatrix_lupus_Naive.csv\n",
      "[1] \"Reading Counts Matrix\"\n",
      "[1] \"Performing DGE\"\n",
      "Traceback (most recent call last):\n",
      "  File \"disease_analysis.py\", line 186, in <module>\n",
      "    main(sys.argv[1:])\n",
      "  File \"disease_analysis.py\", line 120, in main\n",
      "    data2 = DGEio.DGE_main(count_matrix_path, inqueryFullPath, tissue_name, disease_name)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/rpy2/robjects/functions.py\", line 198, in __call__\n",
      "    return (super(SignatureTranslatedFunction, self)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/rpy2/robjects/functions.py\", line 125, in __call__\n",
      "    res = super(Function, self).__call__(*new_args, **new_kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/rpy2/rinterface_lib/conversion.py\", line 45, in _\n",
      "    cdata = function(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/rpy2/rinterface.py\", line 680, in __call__\n",
      "    raise embedded.RRuntimeError(_rinterface._geterrmessage())\n",
      "rpy2.rinterface_lib.embedded.RRuntimeError: Error in file(file, ifelse(append, \"a\", \"w\")) : \n",
      "  cannot open the connection\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Differential gene expression analysis\n",
    "for tissue_name in tissue_names:\n",
    "    disease_config_file = \"\".join([\"disease_data_inputs_\", tissue_name, \".xlsx\"])\n",
    "    cmd = ' '.join(['python3', 'disease_analysis.py',\n",
    "                  '-t', '\"{}\"'.format(tissue_name),\n",
    "                  '-c', '\"{}\"'.format(disease_config_file)])\n",
    "    !{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Identification of drug targets and repurposable drugs\n",
    "This step maps drug targets in metabolic models,prforms knock out simulation, and compare simulation results with disease genes and identifies drug targets and repurposable drugs\n",
    "\n",
    "*** Specify input files for step 4 here ***\n",
    "\n",
    "1. Instruction: A processed Drug-Target file is included in the `/root/pipelines/data/`. (Optional step) For the updated versions the users can download `Repurposing_Hub_export.txt` from [Drug Repurposing Hub](https://clue.io/repurposing-app). From the downloaded file first remove all the activators, agonists, and withdrawn drugs and then upload to to `/root/pipelines/data/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To use automatically created tissue specific models. Note: It is recommended to use refined and validated models for further analysis. User can define cutomized models in next sub-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Naive': 'Naive_SpecificModel.mat'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tissue specific models\n",
    "tissue_spec_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. To use customized model, please specify `tissue_spec_model` manually, e.g. uncomment tissue_spec_model in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually specify Up and Down Regulated Genes for Disease. (Please upload manually created files `/pipelines/data/`. Use filenames as given belwo or change them accordingly.)\n",
    "# Disease_Down = 'Disease_DOWN.txt'\n",
    "# Disease_Up = 'Disease_UP.txt'\n",
    "# drug_raw_file = 'Repurposing_Hub_export.txt'\n",
    "\n",
    "# Manually specify tissue specific models fine-tuned by user. Change names of the files accordingly. Users can use single or multiple models here. Using multiple models, simulation time will increase.\n",
    "# tissue_spec_model = {'Th1':'Th1Model.mat',\n",
    "#                      'Th2':'Th2Model.mat',\n",
    "#                      'Th17':'Th17Model.mat',\n",
    "#                      'Naive':'NaiveModel.mat'}\n",
    "\n",
    "# Manually specify tissue specific model created by matlab cobratoolbox. For example run, we have provided four models of CD4+ T cells (niave, Th1, Th2, and Th17) please uncomment all or any specific model\n",
    "# tissue_spec_model = {'Th1':'Th1_SpecificModel_matlab.mat',\n",
    "#                      'Th2':'Th2_SpecificModel_matlab.mat',\n",
    "#                      'Th17':'Th17_SpecificModel_matlab.mat',\n",
    "#                      'Naive':'Naive_SpecificModel_matlab.mat'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/jupyteruser/work/data/results/Naive/lupus/step2_results_files.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_50/316705030.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         step3_results_file = os.path.join(configs.datadir, 'results', key, \n\u001b[1;32m      7\u001b[0m                                           dis, 'step2_results_files.json')\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep3_results_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjson_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mdisease_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;31m#print(disease_files)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/jupyteruser/work/data/results/Naive/lupus/step2_results_files.json'"
     ]
    }
   ],
   "source": [
    "# Knock out simulation for the analyzed tissues and diseases\n",
    "diseases = ['lupus', 'arthritis']\n",
    "for key,value in tissue_spec_model.items():\n",
    "    for dis in diseases:\n",
    "        # load the results of step 3 to dictionary 'disease_files'\n",
    "        step3_results_file = os.path.join(configs.datadir, 'results', key, \n",
    "                                          dis, 'step2_results_files.json')\n",
    "        with open(step3_results_file) as json_file:\n",
    "            disease_files = json.load(json_file)\n",
    "        #print(disease_files)\n",
    "        Disease_Down = disease_files['DN_Reg']\n",
    "        Disease_Up = disease_files['UP_Reg']\n",
    "        drug_raw_file = 'Repurposing_Hub_export.txt'\n",
    "        \n",
    "        out_dir = os.path.join(configs.datadir, \"results\", key, dis)\n",
    "        tissueSpecificModelfile  = os.path.join(configs.datadir, \"results\", key, value)\n",
    "        print(tissueSpecificModelfile)\n",
    "        tissue_gene_folder = os.path.join(configs.datadir, key)\n",
    "        os.makedirs(tissue_gene_folder, exist_ok=True)\n",
    "        inhibitors_file = '{}_inhibitors_Entrez.txt'.format(key)\n",
    "        cmd = ' '.join(['python3' , 'knock_out_simulation.py',\n",
    "                      '-t', tissueSpecificModelfile,\n",
    "                      '-i', inhibitors_file,\n",
    "                      '-u', Disease_Up,\n",
    "                      '-d', Disease_Down,\n",
    "                      '-f', out_dir,\n",
    "                      '-r', drug_raw_file])\n",
    "        !{cmd}\n",
    "\n",
    "        # copy generated output to output folder\n",
    "        cmd = ' '.join(['cp', '-a', os.path.join(configs.datadir, key), configs.outputdir])\n",
    "        !{cmd}\n",
    "        #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
