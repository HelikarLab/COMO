{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This jupyter notebook run MADRID pipeline to identify drug targets and repurposing drugs for user-defined complex human diseases. The entire process contains five steps:\n",
    "\n",
    "0. Preprocess Bulk RNAseq data by converting STAR outputed Gene counts into a unified matrix and fetching necessary info about each gene needed for normalization via TPM or FPKM. \n",
    "1. Download and analyze microarray, bulk RNAseq, and proteomics data, output a list of active genes.\n",
    "2. Create tissue specific models based on the list of active genes. If required the user can manually refine these models and supply them in Step 4. \n",
    "3. Identify differential gene expressions from disease datasets using either microarray or bulk RNAseq transcriptomics information.\n",
    "4. Identify drug targets and repruposable drugs. This step consists of four substeps. \n",
    " (i) mapping drugs on automatically created or user-supplied models, (ii) knock-out simulation, (iii) compare simulation results of perturbed and unperturbed models, and (iv) integrate with disease genes and score drug targets.\n",
    "\n",
    "The user should upload config excel sheets to the docker container `/work/data/config_sheets`. The sheet names in these config files should correspond to different models where each sheet contains a list of the samples to include for that model. These sample names should correspond to the samples names in the source data which is defined in `/work/data/data_matrices/<model name>/`\n",
    "    \n",
    "In the original docker image, some exemplary input files are included to build metabolic models of naive, Th1, Th2, and Th17 subtypes and identify drug targets for rheumatoid arthritis. User should follow the documentation and the format of the exemplary input files to create your own input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyteruser/work\n"
     ]
    }
   ],
   "source": [
    "# import necessary python packages\n",
    "import sys\n",
    "import os\n",
    "import pandas\n",
    "import numpy\n",
    "import json\n",
    "import re\n",
    "from subprocess import call\n",
    "from project import configs\n",
    "\n",
    "\n",
    "# print root path of the project\n",
    "print(configs.rootdir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Preprocess Bulk RNA-seq data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bulk RNA-seq data can be given as a count matrix where each column is a different sample/replicate named 'tissuename_SXRYrZ' where X is the sample or study number, Y is the replicate number, and Z is the run number. If the replicate does not contain multiple runs the rZ can be neglected. Replicates should come from the same study/sample group and different samples can come from different studies as long as the tissue/cell was under similar enough conditions for your model. \n",
    "\n",
    "If you wish to use raw .fastq data for your bulk RNA-seq inputs, you can align them with STAR using the --gene_counts option and rename the .tab outputs the same as the columns described above. Place the .tab files into a folder called SX where X is the unique study number for the tissue matching the filename. Place each study name folder into a folder titled the tissue name for the model you are building. Place the tissue folder into `/work/data/STAR_out`. An example of this file structure can be found in the STAR_out folder. If using STAR output, be sure that the '-c' argument is 'TRUE'.\n",
    "\n",
    "Currently, MADRID can filter raw RNA-seq counts using a flat cutoff of CPM (counts per million) normalized values and the recommended 'quantile' technique which normalizes using TPM (transcipts per million) and filters using an upper quantile. Future versions will also allow for the zFPKM method outlined in this paper: https://pubmed.ncbi.nlm.nih.gov/24215113/ \n",
    "\n",
    "Preprocessing will fetch relevent gene information needed for normalization such as the start and end postions, so be sure to supply either 'cpm' or 'quantile' as the -t argument in preprocess, and make sure its the same as the one used in bulk_gen.py in step 1. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31mSystem has not been booted with systemd as init system (PID 1). Can't operate.\u001b[0m\n",
      "\u001b[0;1;31mFailed to create bus connection: Host is down\u001b[0m\n",
      "['bulkRNAPreprocess.py', '-n', \"['Naive']\", '-c', 'True', '-f', 'Ensembl', '-t', 'quantile']\n",
      "Naive\n",
      "Input directory is \"/home/jupyteruser/work/data/STAR_output/Naive\"\n",
      "Gene info output directory is \"/home/jupyteruser/work/data/results/Naive\"\n",
      "Active gene determination technique is \"quantile\"\n",
      "Creating Counts Matrix\n",
      "[1] \"/home/jupyteruser/work/data/STAR_output/Naive\"\n",
      "Count Matrix written at  /home/jupyteruser/work/data/data_matrices/Naive/BulkRNAseqDataMatrix_Naive.csv \n",
      "Fetching gene info using genes in \"/home/jupyteruser/work/data/data_matrices/Naive/BulkRNAseqDataMatrix_Naive.csv\"\n",
      "retrieve 0:500\n",
      "retrieve 500:1000\n",
      "retrieve 1000:1500\n",
      "retrieve 1500:2000\n",
      "retrieve 2000:2500\n",
      "retrieve 2500:3000\n",
      "retrieve 3000:3500\n",
      "retrieve 3500:4000\n",
      "retrieve 4000:4500\n",
      "retrieve 4500:5000\n",
      "retrieve 5000:5500\n",
      "retrieve 5500:6000\n",
      "retrieve 6000:6500\n",
      "retrieve 6500:7000\n",
      "retrieve 7000:7500\n",
      "retrieve 7500:8000\n",
      "retrieve 8000:8500\n",
      "retrieve 8500:9000\n",
      "retrieve 9000:9500\n",
      "retrieve 9500:10000\n",
      "retrieve 10000:10500\n",
      "retrieve 10500:11000\n",
      "retrieve 11000:11500\n",
      "retrieve 11500:12000\n",
      "retrieve 12000:12500\n",
      "retrieve 12500:13000\n",
      "retrieve 13000:13500\n",
      "retrieve 13500:14000\n",
      "retrieve 14000:14500\n",
      "retrieve 14500:15000\n",
      "retrieve 15000:15500\n",
      "retrieve 15500:16000\n",
      "retrieve 16000:16500\n",
      "retrieve 16500:17000\n",
      "retrieve 17000:17500\n",
      "retrieve 17500:18000\n",
      "retrieve 18000:18500\n",
      "retrieve 18500:19000\n",
      "retrieve 19000:19500\n",
      "retrieve 19500:20000\n",
      "retrieve 20000:20500\n",
      "retrieve 20500:21000\n",
      "retrieve 21000:21500\n",
      "retrieve 21500:22000\n",
      "retrieve 22000:22500\n",
      "retrieve 22500:23000\n",
      "retrieve 23000:23500\n",
      "retrieve 23500:24000\n",
      "retrieve 24000:24500\n",
      "retrieve 24500:25000\n",
      "retrieve 25000:25500\n",
      "retrieve 25500:26000\n",
      "retrieve 26000:26500\n",
      "retrieve 26500:27000\n",
      "retrieve 27000:27500\n",
      "retrieve 27500:28000\n",
      "retrieve 28000:28500\n",
      "retrieve 28500:29000\n",
      "retrieve 29000:29500\n",
      "retrieve 29500:30000\n",
      "retrieve 30000:30500\n",
      "retrieve 30500:31000\n",
      "retrieve 31000:31500\n",
      "retrieve 31500:32000\n",
      "retrieve 32000:32500\n",
      "retrieve 32500:33000\n",
      "retrieve 33000:33500\n",
      "retrieve 33500:34000\n",
      "retrieve 34000:34500\n",
      "retrieve 34500:35000\n",
      "retrieve 35000:35500\n",
      "retrieve 35500:36000\n",
      "retrieve 36000:36500\n",
      "retrieve 36500:37000\n",
      "retrieve 37000:37500\n",
      "retrieve 37500:38000\n",
      "retrieve 38000:38500\n",
      "retrieve 38500:39000\n",
      "retrieve 39000:39500\n",
      "retrieve 39500:40000\n",
      "retrieve 40000:40500\n",
      "retrieve 40500:41000\n",
      "retrieve 41000:41500\n",
      "retrieve 41500:42000\n",
      "retrieve 42000:42500\n",
      "retrieve 42500:43000\n",
      "retrieve 43000:43500\n",
      "retrieve 43500:44000\n",
      "retrieve 44000:44500\n",
      "retrieve 44500:45000\n",
      "retrieve 45000:45500\n",
      "retrieve 45500:46000\n",
      "retrieve 46000:46500\n",
      "retrieve 46500:47000\n",
      "retrieve 47000:47500\n",
      "retrieve 47500:48000\n",
      "retrieve 48000:48500\n",
      "retrieve 48500:49000\n",
      "retrieve 49000:49500\n",
      "retrieve 49500:50000\n",
      "retrieve 50000:50500\n",
      "retrieve 50500:51000\n",
      "retrieve 51000:51500\n",
      "retrieve 51500:52000\n",
      "retrieve 52000:52500\n",
      "retrieve 52500:53000\n",
      "retrieve 53000:53500\n",
      "retrieve 53500:54000\n",
      "retrieve 54000:54500\n",
      "retrieve 54500:55000\n",
      "retrieve 55000:55500\n",
      "retrieve 55500:56000\n",
      "retrieve 56000:56500\n",
      "retrieve 56500:57000\n",
      "retrieve 57000:57500\n",
      "retrieve 57500:58000\n",
      "retrieve 58000:58500\n",
      "retrieve 58500:59000\n",
      "retrieve 59000:59500\n",
      "retrieve 59500:60000\n",
      "retrieve 60000:60500\n",
      "retrieve 60500:60671\n",
      "Gene Info file written at \"/home/jupyteruser/work/data/results/Naive/GeneInfo_Naive.csv\"\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Preprocess bulk RNAseq dat by generate count matrix from gene counts files\n",
    "# generated from STAR and/or fetching necessary gene info from BioDBnet\n",
    "\n",
    "technique = \"quantile\"      # technique for bulk RNA-seq active gene determination\n",
    "                            # for count matrix gen, only used to determine whether or not\n",
    "                            # picard output mean fragment sizes are required.\n",
    "\n",
    "tissue_names = \"['Naive']\"\n",
    "create_counts_matrix = True # set to false if using a pregenerated matrix file\n",
    "gene_format = \"Ensembl\"     # accepts 'Entrez', 'Ensembl', and 'Symbol'\n",
    "    \n",
    "cmd = ' '.join(['python3', 'bulkRNAPreprocess.py',\n",
    "                '-n', '\"{}\"'.format(tissue_names),\n",
    "                '-c', '\"{}\"'.format(create_counts_matrix),\n",
    "                '-f', '\"{}\"'.format(gene_format),\n",
    "                '-t', '\"{}\"'.format(technique)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Identifying gene activity by analyzing transcriptomics and proteomics datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 1 here ***\n",
    "\n",
    "All three data types are not needed for model generation. Skip any data sources not being used for your model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specific input files for step 1\n",
    "\n",
    "# config file for microarray\n",
    "microarray_config_file = 'microarray_data_inputs.xlsx'\n",
    "\n",
    "# config for bulk rna-seq\n",
    "bulk_config_file = 'bulk_data_inputs.xlsx'\n",
    "\n",
    "# config file for proteomics\n",
    "proteomics_config_file = 'proteomics_data_inputs.xlsx'\n",
    "\n",
    "# ratio of replicates required for a gene to be considered active in that sample\n",
    "expression_proportion = 0.5\n",
    "\n",
    "# Genes can be considered high confidence (labeled as 'top') if they are expressed\n",
    "# in a high proportion of samples. High confidence genes will be considered expressed\n",
    "# regardless of agreement with other data sources\n",
    "top_proportion = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file is  microarray_data_inputs.xlsx\n",
      "Expression Proportion for Gene Expression is  0.5\n",
      "Top proportion for high-confidence genes is  0.9\n",
      "---\n",
      "Start Collecting Data for:\n",
      "['GSE22886' 'GSE43005' 'GSE22045' 'GSE24634']\n",
      "['GSM565273' 'GSM565274' 'GSM565275' 'GSM565290' 'GSM565291' 'GSM565292'\n",
      " 'GSM1054773' 'GSM1054779' 'GSM1054781' 'GSM1054789' 'GSM548000'\n",
      " 'GSM548001' 'GSM607510' 'GSM607511' 'GSM607512']\n",
      "---\n",
      "\n",
      "Initialize project (GSE22886):\n",
      "Root: /home/jupyteruser/work\n",
      "Raw data: /home/jupyteruser/work/data/GSE22886_RAW\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565273.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565274.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565275.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565290.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565291.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22886_RAW/GSM565292.tar\n",
      "Retrieve Samples Completed.\n",
      "GSE22886 already in database, skip over.\n",
      "Initialize project (GSE43005):\n",
      "Root: /home/jupyteruser/work\n",
      "Raw data: /home/jupyteruser/work/data/GSE43005_RAW\n",
      "Sample exist: /home/jupyteruser/work/data/GSE43005_RAW/GSM1054773.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE43005_RAW/GSM1054779.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE43005_RAW/GSM1054781.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE43005_RAW/GSM1054789.tar\n",
      "Retrieve Samples Completed.\n",
      "GSE43005 already in database, skip over.\n",
      "Initialize project (GSE22045):\n",
      "Root: /home/jupyteruser/work\n",
      "Raw data: /home/jupyteruser/work/data/GSE22045_RAW\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22045_RAW/GSM548000.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE22045_RAW/GSM548001.tar\n",
      "Retrieve Samples Completed.\n",
      "GSE22045 already in database, skip over.\n",
      "Initialize project (GSE24634):\n",
      "Root: /home/jupyteruser/work\n",
      "Raw data: /home/jupyteruser/work/data/GSE24634_RAW\n",
      "Sample exist: /home/jupyteruser/work/data/GSE24634_RAW/GSM607510.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE24634_RAW/GSM607511.tar\n",
      "Sample exist: /home/jupyteruser/work/data/GSE24634_RAW/GSM607512.tar\n",
      "Retrieve Samples Completed.\n",
      "GSE24634 already in database, skip over.\n",
      "1985 single ENTREZ_GENE_IDs to merge\n",
      "id_list: 5225, set: 3655\n",
      "entrez_single_id_list: 22887, set: 22887\n",
      "entrez_id_list: 1954, set: 1900\n",
      "dups: 2531, set: 961\n",
      "1365 id merged\n",
      "Save to /home/jupyteruser/work/data/results/Naive/Microarray_Naive.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1.1 Download and analyze microarray\n",
    "cmd = ' '.join(['python3', 'microarray_gen.py', \n",
    "      '-i', '\"{}\"'.format(microarray_config_file),\n",
    "      '-e', '\"{}\"'.format(expression_proportion),\n",
    "      '-t', '\"{}\"'.format(top_proportion)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31mSystem has not been booted with systemd as init system (PID 1). Can't operate.\u001b[0m\n",
      "\u001b[0;1;31mFailed to create bus connection: Host is down\u001b[0m\n",
      "Config file is \"bulk_data_inputs.xlsx\"\n",
      "Input count matrix is at \"/home/jupyteruser/work/data/data_matrices/Naive/BulkRNAseqDataMatrix_Naive.csv\"\n",
      "Gene info file is at \"/home/jupyteruser/work/data/results/Naive/GeneInfo_Naive.csv\"\n",
      "[1] \"Reading Counts Matrix\"\n",
      "[1] \"Filtering Counts\"\n",
      "Test data saved to /home/jupyteruser/work/data/results/Naive/Bulk_Naive.csv\n"
     ]
    }
   ],
   "source": [
    "# step 1.2 Analyze Bulk-RNA-seq \n",
    "\n",
    "exp_prop_rep = 0.5     # proportion of replicates for a gene to be active in a sample\n",
    "exp_prop_samp = 0.5    # proportion of samples with expression required for gene  \n",
    "top_prop_rep = 0.9     # proportion of replicates with expression required for high-confidence\n",
    "top_prop_samp = 0.9    # proportion of replicates with expression required for high-confidence\n",
    "technique = \"quantile\" # filtering technique for active gene detrmination\n",
    "quantile = 25        # cutoff TPM percentile for quantile filtering \n",
    "\n",
    "cmd = ' '.join(['python3', 'bulk_gen.py',   \n",
    "      '-c', '\"{}\"'.format(bulk_config_file), \n",
    "      '-r', '\"{}\"'.format(exp_prop_rep),   \n",
    "      '-s', '\"{}\"'.format(exp_prop_samp),        \n",
    "      '-x', '\"{}\"'.format(top_prop_rep),    \n",
    "      '-y', '\"{}\"'.format(top_prop_samp),   \n",
    "      '-t', '\"{}\"'.format(technique),        \n",
    "      '-q', '\"{}\"'.format(quantile)])       \n",
    "                \n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file is at \"/home/jupyteruser/work/data/config_sheets/proteomics_data_inputs.xlsx\"\n",
      "Data matrix is at \"/home/jupyteruser/work/data/data_matrices/Naive/ProteomicsDataMatrix_Naive.csv\"\n",
      "Test Data Saved to /home/jupyteruser/work/data/results/Naive/Proteomics_Naive.csv\n"
     ]
    }
   ],
   "source": [
    "# Step 1.3 Analyze proteomics\n",
    "quantile = 25\n",
    "\n",
    "cmd = ' '.join(['python3', 'proteomics_gen.py', \n",
    "      '-c', '\"{}\"'.format(proteomics_config_file),\n",
    "      '-e', '\"{}\"'.format(expression_proportion),\n",
    "      '-t', '\"{}\"'.format(top_proportion),\n",
    "      '-p', '\"{}\"'.format(quantile)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;1;31mSystem has not been booted with systemd as init system (PID 1). Can't operate.\u001b[0m\n",
      "\u001b[0;1;31mFailed to create bus connection: Host is down\u001b[0m\n",
      "Microarray file is \"microarray_data_inputs.xlsx\"\n",
      "Proteomics file is \"proteomics_data_inputs.xlsx\"\n",
      "Bulk RNA-seq file is \"bulk_data_inputs.xlsx\"\n",
      "Read from /home/jupyteruser/work/data/results/Naive/Microarray_Naive.csv\n",
      "Read from /home/jupyteruser/work/data/results/Naive/Proteomics_Naive.csv\n",
      "Read from /home/jupyteruser/work/data/results/Naive/Bulk_Naive.csv\n",
      "2621 single ENTREZ_GENE_IDs to merge\n",
      "id_list: 4103, set: 3733\n",
      "entrez_single_id_list: 27037, set: 26995\n",
      "entrez_id_list: 1547, set: 1509\n",
      "dups: 707, set: 337\n",
      "1380 id merged\n",
      "Naive: save to /home/jupyteruser/work/data/results/Naive/GeneExpression_Naive_Merged.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1.4 Merge the gene lists of transcriptomics and proteomics, create a list of active gene IDs\n",
    "\n",
    "expression_requirement=2 # number of data souces with expression required for a gene\n",
    "                         # to be considered active if not a top gene for any source\n",
    "                         # (defaults to the total number of input data sources)\n",
    "\n",
    "cmd = ' '.join(['python3', 'merge_xomics.py', \n",
    "      '-t', '\"{}\"'.format(microarray_config_file),\n",
    "      '-b', '\"{}\"'.format(bulk_config_file),\n",
    "      '-p', '\"{}\"'.format(proteomics_config_file),\n",
    "      '-r', '\"{}\"'.format(expression_requirement)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create tissue-specific or cell-type-specific Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Naive': '/home/jupyteruser/work/data/results/Naive/GeneExpression_Naive_Merged.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Load the output of step 1, which is a dictionary that specifies the merged list of active Gene IDs for each tissue\n",
    "\n",
    "step1_results_file = os.path.join(configs.rootdir, 'data', 'results', 'step1_results_files.json')\n",
    "with open(step1_results_file) as json_file:\n",
    "    tissue_gene_exp = json.load(json_file)\n",
    "print(tissue_gene_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 2 here ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (input) filename of General Model, Recon3D_Teff_ver2\n",
    "GeneralModelFile = 'GeneralModel.mat'\n",
    "excludeRxns = os.path.join(configs.datadir, 'inconsistant_rxns.csv') # flux inconsistant rxns to remove from core reactions in fastcore\n",
    "reconAlgorithm = 'fastcore' # troppo reconstruction algorithm to use\n",
    "objective = 'biomass_reaction_Mphage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tissue Name is \"Naive\"\n",
      "General Model file is \"GeneralModel.mat\"\n",
      "Gene Expression file is \"GeneExpression_Naive_Merged.csv\"\n",
      "Output file is \"Naive_SpecificModel.mat\"\n",
      "Using \"FASTCORE\" reconstruction algorithm\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "/usr/local/lib/python3.8/dist-packages/cobamp/gpr/core.py:115: UserWarning: Will not normalize rules with more than 20 average tokens per gene\n",
      "  warnings.warn(\n",
      "Map gene expression to reactions, 0 errors.\n",
      "J size4229\n",
      "[    6     7    14 ... 10607 10608 10609]\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-0.42289999999996974\n",
      "done LP7\n",
      "LP9\n",
      "Could not set parameters with this solver\n",
      "45031.716371448434\n",
      "Warning, Solution is not optimal\n",
      "done LP9\n",
      "216 7234\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-0.013900000000543478\n",
      "done LP7\n",
      "LP9\n",
      "Could not set parameters with this solver\n",
      "650.0\n",
      "Warning, Solution is not optimal\n",
      "done LP9\n",
      "216 7462\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-1.09122299141607e-12\n",
      "done LP7\n",
      "49 7462\n",
      "Flipped\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-0.0034000000169748055\n",
      "done LP7\n",
      "LP9\n",
      "Could not set parameters with this solver\n",
      "365.0\n",
      "done LP9\n",
      "49 7532\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-4.902177161382124e-13\n",
      "done LP7\n",
      "15 7532\n",
      "Flipped\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "1.215084849686028e-12\n",
      "done LP7\n",
      "LP9\n",
      "Could not set parameters with this solver\n",
      "10.000000715255737\n",
      "Warning, Solution is not optimal\n",
      "done LP9\n",
      "15 7535\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-3.263267612943835e-13\n",
      "done LP7\n",
      "13 7535\n",
      "Flipped\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-3.263267612943835e-13\n",
      "done LP7\n",
      "13 7535\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-0.0001\n",
      "done LP7\n",
      "LP9\n",
      "Could not set parameters with this solver\n",
      "20.0\n",
      "done LP9\n",
      "13 7541\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-2.5102058561106422e-14\n",
      "done LP7\n",
      "9 7541\n",
      "Flipped\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-0.0001\n",
      "done LP7\n",
      "LP9\n",
      "Could not set parameters with this solver\n",
      "10.0\n",
      "Warning, Solution is not optimal\n",
      "done LP9\n",
      "9 7544\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-0.0001\n",
      "done LP7\n",
      "LP9\n",
      "Could not set parameters with this solver\n",
      "10.0\n",
      "Warning, Solution is not optimal\n",
      "done LP9\n",
      "7 7547\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-0.0001\n",
      "done LP7\n",
      "LP9\n",
      "Could not set parameters with this solver\n",
      "10.000000953674316\n",
      "Warning, Solution is not optimal\n",
      "done LP9\n",
      "5 7549\n",
      "Flipped\n",
      "before LP7\n",
      "LP7\n",
      "Could not set parameters with this solver\n",
      "-2.5102058561106422e-14\n",
      "done LP7\n",
      "5 7549\n",
      "Error: Global network is not consistent\n",
      "[ 7479  9331  9395 10022 10051]\n",
      "Genes: 1892\n",
      "Metabolites: 5837\n",
      "Reactions: 10610\n",
      "1.0*biomass_reaction_Mphage - 1.0*biomass_reaction_Mphage_reverse_6cff5\n",
      "<Solution 1.722 at 0x7f5c31ac9af0>\n",
      "{'Naive': 'Naive_SpecificModel.mat'}\n"
     ]
    }
   ],
   "source": [
    "# create tissue specific model, the names of output files are stored in dictionary tissue_spec_model\n",
    "tissue_spec_model = {}\n",
    "\n",
    "for key,value in tissue_gene_exp.items():\n",
    "    tissuefile = '{}_SpecificModel.mat'.format(key) # key is == tissue name\n",
    "    tissue_spec_model[key] = tissuefile\n",
    "    tissue_gene_file = re.split('/|\\\\\\\\', value)[-1]\n",
    "    #tissue_gene_folder = os.path.join(configs.rootdir, 'data', key)\n",
    "    os.makedirs(tissue_gene_folder, exist_ok=True)\n",
    "    cmd = ' '.join(['python3', 'create_tissue_specific_model.py', \n",
    "                      '-t', '\"{}\"'.format(key),\n",
    "                      '-m', '\"{}\"'.format(GeneralModelFile), \n",
    "                      '-g', '\"{}\"'.format(tissue_gene_file),\n",
    "                      '-o', '\"{}\"'.format(tissuefile),\n",
    "                      '-s', '\"{}\"'.format(objective),\n",
    "                      '-x', '\"{}\"'.format(excludeRxns),\n",
    "                      '-a', '\"{}\"'.format(reconAlgorithm)])\n",
    "    !{cmd}\n",
    "\n",
    "print(tissue_spec_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Identifying disease related genes by analyzing transcriptomics data of patients\n",
    "Differential Expression Analysis\n",
    "\n",
    "In the config_sheets folder, there should be a folder called \"disease\". You can add a spreadsheet for each cell/tissue type called `disease_data_inputs_<tissue_name>`. Each sheet of this file should correspond to a seperate disease to analyze using DGE nfor that tissue. The source data can be either microarray or bulk RNA-seq and is formatted the same as if creating the base tissue model. The sheet names should contain the disease name, an underscore, and than either \"microarray\" or \"bulk\" depending on the source data. For example, if the disease is lupus, and the source data is bulk RNA-seq, the name of the sheet should be \"lupus_bulk\". This can be seen in the example sheet. If using bulk RNA-seq data, there should be a count matrix file in `/work/data/data_matrices/<tissue_name>/disease/` called `BulkRNAseqDataMatrix_<disease name>_<tissue name>`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 3 here ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify tissue names to perform a disease analysis on. The diseases to analyze should be\n",
    "# specified in `/work/data/config_sheets/disease/diease_data_inputs_<tissue name>`\n",
    "tissue_names = ['Naive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config file is at  /home/jupyteruser/work/data/config_sheets/disease/disease_data_inputs_Naive.xlsx\n",
      "Count Matrix File is at  /home/jupyteruser/work/data/data_matrices/Naive/disease/BulkRNAseqDataMatrix_lupus_Naive.csv\n",
      "[1] \"Reading Counts Matrix\"\n",
      "[1] \"Performing DGE\"\n",
      "disease_analysis.py:151: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Disease_UP.dropna(how='any', subset=['Gene ID'], inplace=True)\n",
      "disease_analysis.py:152: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Disease_DOWN.dropna(how='any', subset=['Gene ID'], inplace=True)\n",
      "retrieve 0:500\n",
      "retrieve 500:1000\n",
      "retrieve 1000:1500\n",
      "retrieve 1500:2000\n",
      "retrieve 2000:2500\n",
      "retrieve 2500:3000\n",
      "retrieve 3000:3500\n",
      "retrieve 3500:4000\n",
      "retrieve 4000:4500\n",
      "retrieve 4500:5000\n",
      "retrieve 5000:5500\n",
      "retrieve 5500:6000\n",
      "retrieve 6000:6500\n",
      "retrieve 6500:7000\n",
      "retrieve 7000:7500\n",
      "retrieve 7500:8000\n",
      "retrieve 8000:8500\n",
      "retrieve 8500:9000\n",
      "retrieve 9000:9500\n",
      "retrieve 9500:10000\n",
      "retrieve 10000:10500\n",
      "retrieve 10500:11000\n",
      "retrieve 11000:11500\n",
      "retrieve 11500:12000\n",
      "retrieve 12000:12500\n",
      "retrieve 12500:13000\n",
      "retrieve 13000:13500\n",
      "retrieve 13500:14000\n",
      "retrieve 14000:14500\n",
      "retrieve 14500:15000\n",
      "retrieve 15000:15500\n",
      "retrieve 15500:16000\n",
      "retrieve 16000:16500\n",
      "retrieve 16500:17000\n",
      "retrieve 17000:17500\n",
      "retrieve 17500:18000\n",
      "retrieve 18000:18500\n",
      "retrieve 18500:19000\n",
      "retrieve 19000:19500\n",
      "retrieve 19500:20000\n",
      "retrieve 20000:20500\n",
      "retrieve 20500:21000\n",
      "retrieve 21000:21500\n",
      "retrieve 21500:22000\n",
      "retrieve 22000:22500\n",
      "retrieve 22500:23000\n",
      "retrieve 23000:23500\n",
      "retrieve 23500:24000\n",
      "retrieve 24000:24500\n",
      "retrieve 24500:25000\n",
      "retrieve 25000:25500\n",
      "retrieve 25500:25774\n",
      "Raw Data saved to\n",
      "/home/jupyteruser/work/data/results/Naive/lupus/Raw_Fit_bulk.csv\n",
      "Initialize project (GSE56649):\n",
      "Root: /home/jupyteruser/work\n",
      "Raw data: /home/jupyteruser/work/data/GSE56649_RAW\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366348.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366349.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366350.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366351.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366352.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366353.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366354.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366355.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366356.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366357.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366358.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366359.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366360.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366361.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366362.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366363.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366364.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366365.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366366.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366367.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366368.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Sample: /home/jupyteruser/work/data/GSE56649_RAW/GSM1366369.tar\n",
      "Extract to: /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Retrieve Samples Completed.\n",
      "GPL570:affy, /home/jupyteruser/work/data/GSE56649_RAW/GPL570\n",
      "Background correcting\n",
      "Normalizing\n",
      "Calculating Expression\n",
      "retrieve 0:500\n",
      "retrieve 500:731\n",
      "retrieve 0:500\n",
      "retrieve 500:565\n",
      "retrieve 0:500\n",
      "retrieve 500:1000\n",
      "retrieve 1000:1500\n",
      "retrieve 1500:2000\n",
      "retrieve 2000:2500\n",
      "retrieve 2500:3000\n",
      "retrieve 3000:3500\n",
      "retrieve 3500:4000\n",
      "retrieve 4000:4500\n",
      "retrieve 4500:5000\n",
      "retrieve 5000:5500\n",
      "retrieve 5500:6000\n",
      "retrieve 6000:6500\n",
      "retrieve 6500:7000\n",
      "retrieve 7000:7500\n",
      "retrieve 7500:8000\n",
      "retrieve 8000:8500\n",
      "retrieve 8500:9000\n",
      "retrieve 9000:9500\n",
      "retrieve 9500:10000\n",
      "retrieve 10000:10500\n",
      "retrieve 10500:11000\n",
      "retrieve 11000:11500\n",
      "retrieve 11500:12000\n",
      "retrieve 12000:12500\n",
      "retrieve 12500:13000\n",
      "retrieve 13000:13500\n",
      "retrieve 13500:14000\n",
      "retrieve 14000:14500\n",
      "retrieve 14500:15000\n",
      "retrieve 15000:15500\n",
      "retrieve 15500:16000\n",
      "retrieve 16000:16500\n",
      "retrieve 16500:17000\n",
      "retrieve 17000:17500\n",
      "retrieve 17500:18000\n",
      "retrieve 18000:18500\n",
      "retrieve 18500:19000\n",
      "retrieve 19000:19500\n",
      "retrieve 19500:20000\n",
      "retrieve 20000:20500\n",
      "retrieve 20500:21000\n",
      "retrieve 21000:21500\n",
      "retrieve 21500:22000\n",
      "retrieve 22000:22500\n",
      "retrieve 22500:23000\n",
      "retrieve 23000:23500\n",
      "retrieve 23500:24000\n",
      "retrieve 24000:24500\n",
      "retrieve 24500:25000\n",
      "retrieve 25000:25500\n",
      "retrieve 25500:26000\n",
      "retrieve 26000:26500\n",
      "retrieve 26500:27000\n",
      "retrieve 27000:27500\n",
      "retrieve 27500:28000\n",
      "retrieve 28000:28500\n",
      "retrieve 28500:29000\n",
      "retrieve 29000:29500\n",
      "retrieve 29500:30000\n",
      "retrieve 30000:30500\n",
      "retrieve 30500:31000\n",
      "retrieve 31000:31500\n",
      "retrieve 31500:32000\n",
      "retrieve 32000:32500\n",
      "retrieve 32500:33000\n",
      "retrieve 33000:33500\n",
      "retrieve 33500:34000\n",
      "retrieve 34000:34500\n",
      "retrieve 34500:35000\n",
      "retrieve 35000:35500\n",
      "retrieve 35500:36000\n",
      "retrieve 36000:36500\n",
      "retrieve 36500:37000\n",
      "retrieve 37000:37500\n",
      "retrieve 37500:38000\n",
      "retrieve 38000:38500\n",
      "retrieve 38500:39000\n",
      "retrieve 39000:39500\n",
      "retrieve 39500:40000\n",
      "retrieve 40000:40500\n",
      "retrieve 40500:41000\n",
      "retrieve 41000:41500\n",
      "retrieve 41500:42000\n",
      "retrieve 42000:42500\n",
      "retrieve 42500:43000\n",
      "retrieve 43000:43500\n",
      "retrieve 43500:44000\n",
      "retrieve 44000:44500\n",
      "retrieve 44500:45000\n",
      "retrieve 45000:45500\n",
      "retrieve 45500:46000\n",
      "retrieve 46000:46500\n",
      "retrieve 46500:47000\n",
      "retrieve 47000:47500\n",
      "retrieve 47500:48000\n",
      "retrieve 48000:48500\n",
      "retrieve 48500:49000\n",
      "retrieve 49000:49500\n",
      "retrieve 49500:50000\n",
      "retrieve 50000:50500\n",
      "retrieve 50500:51000\n",
      "retrieve 51000:51500\n",
      "retrieve 51500:52000\n",
      "retrieve 52000:52500\n",
      "retrieve 52500:53000\n",
      "retrieve 53000:53500\n",
      "retrieve 53500:54000\n",
      "retrieve 54000:54500\n",
      "retrieve 54500:54675\n",
      "Raw Data saved to\n",
      "/home/jupyteruser/work/data/results/Naive/arthritis/Raw_Fit_GSE56649.csv\n"
     ]
    }
   ],
   "source": [
    "# Differential gene expression analysis\n",
    "for tissue_name in tissue_names:\n",
    "    disease_config_file = \"\".join([\"disease_data_inputs_\", tissue_name, \".xlsx\"])\n",
    "    cmd = ' '.join(['python3', 'disease_analysis.py',\n",
    "                  '-t', '\"{}\"'.format(tissue_name),\n",
    "                  '-c', '\"{}\"'.format(disease_config_file)])\n",
    "    !{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Identification of drug targets and repurposable drugs\n",
    "This step maps drug targets in metabolic models,prforms knock out simulation, and compare simulation results with disease genes and identifies drug targets and repurposable drugs\n",
    "\n",
    "*** Specify input files for step 4 here ***\n",
    "\n",
    "1. Instruction: A processed Drug-Target file is included in the `/root/pipelines/data/`. (Optional step) For the updated versions the users can download `Repurposing_Hub_export.txt` from [Drug Repurposing Hub](https://clue.io/repurposing-app). From the downloaded file first remove all the activators, agonists, and withdrawn drugs and then upload to to `/root/pipelines/data/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To use automatically created tissue specific models. Note: It is recommended to use refined and validated models for further analysis. User can define cutomized models in next sub-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Naive': 'Naive_SpecificModel.mat'}"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tissue specific models\n",
    "tissue_spec_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. To use customized model, please specify `tissue_spec_model` manually, e.g. uncomment tissue_spec_model in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually specify Up and Down Regulated Genes for Disease. (Please upload manually created files `/pipelines/data/`. Use filenames as given belwo or change them accordingly.)\n",
    "# Disease_Down = 'Disease_DOWN.txt'\n",
    "# Disease_Up = 'Disease_UP.txt'\n",
    "# drug_raw_file = 'Repurposing_Hub_export.txt'\n",
    "\n",
    "# Manually specify tissue specific models fine-tuned by user. Change names of the files accordingly. Users can use single or multiple models here. Using multiple models, simulation time will increase.\n",
    "# tissue_spec_model = {'Th1':'Th1Model.mat',\n",
    "#                      'Th2':'Th2Model.mat',\n",
    "#                      'Th17':'Th17Model.mat',\n",
    "#                      'Naive':'NaiveModel.mat'}\n",
    "\n",
    "# Manually specify tissue specific model created by matlab cobratoolbox. For example run, we have provided four models of CD4+ T cells (niave, Th1, Th2, and Th17) please uncomment all or any specific model\n",
    "# tissue_spec_model = {'Th1':'Th1_SpecificModel_matlab.mat',\n",
    "#                      'Th2':'Th2_SpecificModel_matlab.mat',\n",
    "#                      'Th17':'Th17_SpecificModel_matlab.mat',\n",
    "#                      'Naive':'Naive_SpecificModel_matlab.mat'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyteruser/work/data/results/Naive/Naive_SpecificModel.mat\n",
      "Output directory: \"/home/jupyteruser/work/data/results/Naive/lupus\"\n",
      "Tissue Specific Model file is at \"/home/jupyteruser/work/data/results/Naive/Naive_SpecificModel.mat\"\n",
      "Tissue Specific Inhibitors file is \"Naive_inhibitors_Entrez.txt\"\n",
      "Scaling...\n",
      " A: min|aij| =  1.000e+00  max|aij| =  1.000e+00  ratio =  1.000e+00\n",
      "Problem data seem to be well scaled\n",
      "1892\n",
      "1892\n",
      "631\n"
     ]
    }
   ],
   "source": [
    "# Knock out simulation for the analyzed tissues and diseases\n",
    "diseases = ['lupus', 'arthritis']\n",
    "for key,value in tissue_spec_model.items():\n",
    "    for dis in diseases:\n",
    "        # load the results of step 3 to dictionary 'disease_files'\n",
    "        step3_results_file = os.path.join(configs.datadir, 'results', key, \n",
    "                                          dis, 'step2_results_files.json')\n",
    "        with open(step3_results_file) as json_file:\n",
    "            disease_files = json.load(json_file)\n",
    "        #print(disease_files)\n",
    "        Disease_Down = disease_files['DN_Reg']\n",
    "        Disease_Up = disease_files['UP_Reg']\n",
    "        drug_raw_file = 'Repurposing_Hub_export.txt'\n",
    "        \n",
    "        out_dir = os.path.join(configs.datadir, \"results\", key, dis)\n",
    "        tissueSpecificModelfile  = os.path.join(configs.datadir, \"results\", key, value)\n",
    "        print(tissueSpecificModelfile)\n",
    "        tissue_gene_folder = os.path.join(configs.datadir, key)\n",
    "        os.makedirs(tissue_gene_folder, exist_ok=True)\n",
    "        inhibitors_file = '{}_inhibitors_Entrez.txt'.format(key)\n",
    "        cmd = ' '.join(['python3' , 'knock_out_simulation.py',\n",
    "                      '-t', tissueSpecificModelfile,\n",
    "                      '-i', inhibitors_file,\n",
    "                      '-u', Disease_Up,\n",
    "                      '-d', Disease_Down,\n",
    "                      '-f', out_dir,\n",
    "                      '-r', drug_raw_file])\n",
    "        !{cmd}\n",
    "\n",
    "        # copy generated output to output folder\n",
    "        cmd = ' '.join(['cp', '-a', os.path.join(configs.datadir, key), configs.outputdir])\n",
    "        !{cmd}\n",
    "        #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
