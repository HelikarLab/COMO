{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This jupyter notebook run MADRID pipeline to identify drug targets and repurposing drugs for user-defined complex human diseases. The entire process contains four steps:\n",
    "1. Download and analyze transcriptomics and proteomics data, output a list of active genes.\n",
    "2. Create tissue specific models based on the list of active genes. If required the user can manually refine these models and supply them in Step 4. \n",
    "3. Identifying differential gene expressions from disease datasets.\n",
    "4. Identifying drug targets and repruposable drugs. This step consists of four substeps. \n",
    " (i) mapping drugs on automatically created or user-supplied models, (ii) knock-out simulation, (iii) compare simulation results of perturbed and unperturbed models, and (iv) integrate with disease genes and score drug targets.\n",
    "\n",
    "The users needs to create the input files for each step and upload input files to the docker container `/root/pipelines/data/`, and specify the input files in this notebook. In the original docker image, some exemplary input files are included to build metabolic models of naive, Th1, Th2, and Th17 subtypes and identify drug targets for rheumatoid arthritis. User should follow the documentation and the format of the exemplary input files to create your own input files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:/GitHub/MADRID/docker/pipelines/\n"
     ]
    }
   ],
   "source": [
    "# import necessary python packages\n",
    "import sys\n",
    "import os\n",
    "import pandas\n",
    "import numpy\n",
    "import json\n",
    "import re\n",
    "from subprocess import call\n",
    "from project import configs\n",
    "\n",
    "# print root path of the project\n",
    "print(configs.rootdir) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Identifying gene activity by analyzing transcriptomics and proteomics datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 1 here ***\n",
    "\n",
    "If proteomics data is not availabe, use:\n",
    "\n",
    "proteomics_data_file = 'dummy_proteomics_data.xlsx'\n",
    "\n",
    "proteomics_config_file = 'dummy_proteomics_config.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['generateCountMatrix.py', '-i', 'G:/GitHub/New Folder/MADRID_olddev/docker/pipelines/py/data/bulkData/NaiveB/', '-o', 'G:/GitHub/MADRID/docker/pipelines/data/', '-t', 'quantile']\n",
      "Input directory is \"G:/GitHub/New Folder/MADRID_olddev/docker/pipelines/py/data/bulkData/NaiveB/\"\n",
      "Output file is \"G:/GitHub/MADRID/docker/pipelines/data/\"\n",
      "Active gene determination technique is \"quantile\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Generate count matrix from gene counts files generated from STAR\n",
    "\n",
    "technique = \"quantile\" # technique for bulk RNA-seq active gene determination\n",
    "                        # for count matrix gen, only used to determine whether or not\n",
    "                        # picard output mean fragment sizes are required.\n",
    "        \n",
    "input_dir = \"G:/GitHub/New Folder/MADRID_olddev/docker/pipelines/py/data/bulkData/NaiveB/\"\n",
    "output_dir = \"G:/GitHub/MADRID/docker/pipelines/data/\"\n",
    "        \n",
    "cmd = ' '.join(['python', 'generateCountMatrix.py',\n",
    "                '-i', '\"{}\"'.format(input_dir),\n",
    "                '-o', '\"{}\"'.format(output_dir),\n",
    "                '-t', '\"{}\"'.format(technique)])\n",
    "#print(cmd)\n",
    "!{cmd}\n",
    "# Alternatively, the gene count matrix for RNA-seq can be crafted any other way desired\n",
    "# and this step can be skipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wd for development\n",
    "\n",
    "# Specific input files for step 1\n",
    "\n",
    "# config file for transcriptomics (microarray)\n",
    "transcriptomics_config_file = 'transcriptomics_data_inputs.xlsx'\n",
    "\n",
    "# data file for bulk rna-seq\n",
    "bulk_data_file = 'BulkRNAseqDataMatrix.csv'\n",
    "\n",
    "# config for bulk rna-seq\n",
    "bulk_config_file = 'bulk_data_inputs.csv'\n",
    "\n",
    "# data file for proteomics\n",
    "proteomics_data_file = 'ProteomicsDataMatrix.xlsx' \n",
    "\n",
    "# config file for proteomics\n",
    "proteomics_config_file = 'proteomics_data_inputs.xlsx'\n",
    "\n",
    "# proportion of replicates required for a gene to be considered active in that sample\n",
    "\n",
    "expression_proportion = 0.5\n",
    "# if gene is in the top nth percentile in any sample it is considered high confidence and will be considered\n",
    "# expressed regardless of the results of other methods\n",
    "top_percentile =  10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file is \" transcriptomics_data_inputs.xlsx\n",
      "G:/GitHub/MADRID/docker/pipelines/data\\transcriptomics_data_inputs.xlsx\n",
      "---\n",
      "Start Collecting Data for:\n",
      "['GSE22886' 'GSE43005' 'GSE22045' 'GSE24634']\n",
      "['GSM565273' 'GSM565274' 'GSM565275' 'GSM565290' 'GSM565291' 'GSM565292'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n",
      "30-Jun-2021 12:51:32 INFO GEOparse - Parsing ./GSE22886_family.soft.gz: \n",
      "30-Jun-2021 12:51:32 DEBUG GEOparse - DATABASE: GeoMiame\n",
      "30-Jun-2021 12:51:32 DEBUG GEOparse - SERIES: GSE22886\n",
      "30-Jun-2021 12:51:32 DEBUG GEOparse - PLATFORM: GPL96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 'GSM1054773' 'GSM1054779' 'GSM1054781' 'GSM1054789' 'GSM548000'\n",
      " 'GSM548001' 'GSM607510' 'GSM607511' 'GSM607512']\n",
      "---\n",
      "\n",
      "Initialize project (GSE22886):\n",
      "Root: G:/GitHub/MADRID/docker/pipelines/\n",
      "Raw data: G:/GitHub/MADRID/docker/pipelines/data\\GSE22886_RAW\n",
      "Sample exist: G:/GitHub/MADRID/docker/pipelines/data\\GSE22886_RAW\\GSM565273.tar\n",
      "Sample exist: G:/GitHub/MADRID/docker/pipelines/data\\GSE22886_RAW\\GSM565274.tar\n",
      "Sample exist: G:/GitHub/MADRID/docker/pipelines/data\\GSE22886_RAW\\GSM565275.tar\n",
      "Sample exist: G:/GitHub/MADRID/docker/pipelines/data\\GSE22886_RAW\\GSM565290.tar\n",
      "Sample exist: G:/GitHub/MADRID/docker/pipelines/data\\GSE22886_RAW\\GSM565291.tar\n",
      "Sample exist: G:/GitHub/MADRID/docker/pipelines/data\\GSE22886_RAW\\GSM565292.tar\n",
      "Retrieve Samples Completed.\n",
      "Create new table: G:/GitHub/MADRID/docker/pipelines/data\\GSE22886_RAW\\GSE22886_sc500_full_table.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"transcriptomic_gen.py\", line 347, in <module>\n",
      "    main(sys.argv[1:])\n",
      "  File \"transcriptomic_gen.py\", line 338, in main\n",
      "    df_output = queryTest(df)\n",
      "  File \"transcriptomic_gen.py\", line 140, in queryTest\n",
      "    updateTranscriptomicsDB(gseXXX)\n",
      "  File \"transcriptomic_gen.py\", line 84, in updateTranscriptomicsDB\n",
      "    df_clean = gseXXX.get_entrez_table_pipeline()\n",
      "  File \"G:\\GitHub\\MADRID\\docker\\pipelines\\py\\GSEpipelineFast.py\", line 182, in get_entrez_table_pipeline\n",
      "    gsm_maps = self.get_gsm_tables()\n",
      "  File \"G:\\GitHub\\MADRID\\docker\\pipelines\\py\\GSEpipelineFast.py\", line 125, in get_gsm_tables\n",
      "    gse = load_gse_soft(self.gsename)\n",
      "  File \"G:\\GitHub\\MADRID\\docker\\pipelines\\py\\GSEpipeline.py\", line 23, in load_gse_soft\n",
      "    gse = GEOparse.get_GEO(filepath=softfile)\n",
      "  File \"C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\GEOparse\\GEOparse.py\", line 84, in get_GEO\n",
      "    return parse_GSE(filepath)\n",
      "  File \"C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\GEOparse\\GEOparse.py\", line 521, in parse_GSE\n",
      "    gpls[entry_name] = parse_GPL(data_group, entry_name)\n",
      "  File \"C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\GEOparse\\GEOparse.py\", line 462, in parse_GPL\n",
      "    table_data = parse_table_data(gpl_soft)\n",
      "  File \"C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\GEOparse\\GEOparse.py\", line 332, in parse_table_data\n",
      "    return DataFrame.from_csv(StringIO(data), index_col=None, sep=\"\\t\")\n",
      "AttributeError: type object 'DataFrame' has no attribute 'from_csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 1.1 Download and analyze transcriptomics\n",
    "cmd = ' '.join(['python', 'transcriptomic_gen.py', \n",
    "      '-i', '\"{}\"'.format(transcriptomics_config_file)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file is \"BulkRNAseqDataMatrix.csv\"\n",
      "Supplementary Data file is \"bulk_data_inputs.csv\"\n",
      "G:/GitHub/MADRID/docker/pipelines/data\\Bulk_Naive.csv\n",
      "Test data saved to G:/GitHub/MADRID/docker/pipelines/data\\Bulk_Naive.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n"
     ]
    }
   ],
   "source": [
    "# step 1.2 Analyze Bulk-RNA-seq \n",
    "\n",
    "# Bulk-RNA-seq can handle many more parameters, \n",
    "# bulk_data_file, bulk_config_file, gene_format, and species_dataset are required.\n",
    "\n",
    "gene_format = \"ensembl\" # gene format in count file for biomart\n",
    "species_dataset = \"human\" # species dataset for biomart\n",
    "exp_prop_rep = 0.5  # proportion of replicates for a gene to be active in a sample\n",
    "exp_prop_samp = 0.5 # proportion of samples with expression required for gene   \n",
    "top_percentile = 25 # any replicate with expression in this percentile is expressed, regardless of other sources  \n",
    "technique = \"quantile\" # quantile, cpm, or zFPKM\n",
    "quantile = 90 # only used with quantile\n",
    "\n",
    "cmd = ' '.join(['python', 'bulk_gen.py', \n",
    "      '-f', '\"{}\"'.format(bulk_data_file),   # bulk rna-seq data sheet (required)\n",
    "      '-c', '\"{}\"'.format(bulk_config_file), # config file for bulk RNA-seq (required)\n",
    "      '-g', '\"{}\"'.format(gene_format),      # gene format in count file for biomart (required)\n",
    "      '-d', '\"{}\"'.format(species_dataset),  # species dataset for biomart (required)\n",
    "      '-r', '\"{}\"'.format(exp_prop_rep),     # proportion of replicates for a gene to be active in a sample\n",
    "      '-s', '\"{}\"'.format(exp_prop_samp),    # proportion of samples with expression required for gene       \n",
    "      '-p', '\"{}\"'.format(top_percentile),   # top percentile \n",
    "      '-t', '\"{}\"'.format(technique),        # technique for filtering and normalization    \n",
    "      '-q', '\"{}\"'.format(quantile)])         # cutoff TPM quantile for quantile techique\n",
    "                \n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file is \"ProteomicsDataMatrix.xlsx\"\n",
      "Supplementary Data file is \"proteomics_data_inputs.xlsx\"\n",
      "                                Naïve \n",
      "0     CopyNumber_T4.naive_01_activated\n",
      "1     CopyNumber_T4.naive_02_activated\n",
      "2     CopyNumber_T4.naive_03_activated\n",
      "3     CopyNumber_T4.naive_04_activated\n",
      "4  CopyNumber_T4.naive_01_steady-state\n",
      "5  CopyNumber_T4.naive_02_steady-state\n",
      "6  CopyNumber_T4.naive_03_steady-state\n",
      "7  CopyNumber_T4.naive_04_steady-state\n",
      "Test Data Saved to G:/GitHub/MADRID/docker/pipelines/data\\Proteomics_Naive.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n"
     ]
    }
   ],
   "source": [
    "# Step 1.3 Analyze proteomics\n",
    "cmd = ' '.join(['python', 'proteomics_gen.py', \n",
    "      '-d', '\"{}\"'.format(proteomics_data_file), \n",
    "      '-s', '\"{}\"'.format(proteomics_config_file),\n",
    "      '-e', '\"{}\"'.format(expression_proportion),\n",
    "      '-p', '\"{}\"'.format(top_percentile)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcriptomics file is \"None\"\n",
      "Proteomics file is \"proteomics_data_inputs.xlsx\"\n",
      "Bulk RNA-seq file is \"bulk_data_inputs.csv\"\n",
      "                                Naïve \n",
      "0     CopyNumber_T4.naive_01_activated\n",
      "1     CopyNumber_T4.naive_02_activated\n",
      "2     CopyNumber_T4.naive_03_activated\n",
      "3     CopyNumber_T4.naive_04_activated\n",
      "4  CopyNumber_T4.naive_01_steady-state\n",
      "5  CopyNumber_T4.naive_02_steady-state\n",
      "6  CopyNumber_T4.naive_03_steady-state\n",
      "7  CopyNumber_T4.naive_04_steady-state\n",
      "proteomics exists\n",
      "Naïve \n",
      "Test Data Load From G:/GitHub/MADRID/docker/pipelines/data\\Proteomics_Naive.csv\n",
      "{'Naive':                 CopyNumber_T4.naive_01_activated  ...  top\n",
      "ENTREZ_GENE_ID                                    ...     \n",
      "1                                          42776  ...    0\n",
      "2                                         341085  ...    1\n",
      "144568                                         0  ...    0\n",
      "8086                                      109983  ...    1\n",
      "65985                                      13945  ...    0\n",
      "...                                          ...  ...  ...\n",
      "440590                                     11600  ...    0\n",
      "79699                                      10117  ...    0\n",
      "7791                                      784378  ...    1\n",
      "23140                                      11113  ...    0\n",
      "26009                                          0  ...    0\n",
      "\n",
      "[8768 rows x 11 columns]}\n",
      "      SampleName InsertSize\n",
      "0       FILENAME      Naive\n",
      "1       GROUP_S1   GROUP_S1\n",
      "2   Naive_B_S1R1          0\n",
      "3   Naive_B_S1R2          0\n",
      "4   Naive_B_S1R3          0\n",
      "5   Naive_B_S1R4          0\n",
      "6       GROUP_S2   GROUP_S1\n",
      "7   Naive_B_S2R1          0\n",
      "8   Naive_B_S2R2          0\n",
      "9   Naive_B_S2R3          0\n",
      "10  Naive_B_S2R4          0\n",
      "11      GROUP_S3   GROUP_S1\n",
      "12  Naive_B_S3R1          0\n",
      "13  Naive_B_S3R2          0\n",
      "14  Naive_B_S3R3          0\n",
      "15  Naive_B_S3R4          0\n",
      "16  Naive_B_S3R5          0\n",
      "17  Naive_B_S3R6          0\n",
      "  SampleName InsertSize\n",
      "0   FILENAME      Naive\n",
      "0    Naive\n",
      "Name: InsertSize, dtype: object\n",
      "bulk exists\n",
      "Naive\n",
      "expressed    int64\n",
      "top          int64\n",
      "dtype: object\n",
      "Test Data Load From G:/GitHub/MADRID/docker/pipelines/data\\Bulk_Naive.csv\n",
      "{'Naive':                 expressed  top\n",
      "ENTREZ_GENE_ID                \n",
      "7105                    0    0\n",
      "64102                   0    0\n",
      "8813                    0    0\n",
      "57147                   0    0\n",
      "55732                   0    0\n",
      "...                   ...  ...\n",
      "105370174               0    0\n",
      "100533105               0    0\n",
      "109617009               0    0\n",
      "2831                    0    0\n",
      "1038                    0    0\n",
      "\n",
      "[25639 rows x 2 columns]}\n",
      "dict_keys(['Naive'])\n",
      "dict_keys(['dummy'])\n",
      "dict_keys(['Naive'])\n",
      "keys1 generated\n",
      "{'Naive'}\n",
      "Naive\n",
      "                prote_exp  prote_top\n",
      "ENTREZ_GENE_ID                      \n",
      "1                       1          0\n",
      "2                       1          1\n",
      "144568                  1          0\n",
      "8086                    1          1\n",
      "65985                   1          0\n",
      "...                   ...        ...\n",
      "440590                  0          0\n",
      "79699                   1          0\n",
      "7791                    1          1\n",
      "23140                   1          0\n",
      "26009                   0          0\n",
      "\n",
      "[8768 rows x 2 columns]\n",
      "                bulk_exp  bulk_top\n",
      "ENTREZ_GENE_ID                    \n",
      "7105                   0         0\n",
      "64102                  0         0\n",
      "8813                   0         0\n",
      "57147                  0         0\n",
      "55732                  0         0\n",
      "...                  ...       ...\n",
      "105370174              0         0\n",
      "100533105              0         0\n",
      "109617009              0         0\n",
      "2831                   0         0\n",
      "1038                   0         0\n",
      "\n",
      "[25639 rows x 2 columns]\n",
      "                prote_exp  prote_top  bulk_exp  bulk_top\n",
      "ENTREZ_GENE_ID                                          \n",
      "1                     NaN        NaN       0.0       0.0\n",
      "2                     NaN        NaN       0.0       0.0\n",
      "3                     NaN        NaN       0.0       0.0\n",
      "9                     NaN        NaN       0.0       0.0\n",
      "10                    NaN        NaN       0.0       0.0\n",
      "...                   ...        ...       ...       ...\n",
      "999                   0.0        0.0       NaN       NaN\n",
      "9990                  1.0        0.0       NaN       NaN\n",
      "9991                  1.0        1.0       NaN       NaN\n",
      "9994                  1.0        0.0       NaN       NaN\n",
      "9997                  1.0        0.0       NaN       NaN\n",
      "\n",
      "[34407 rows x 4 columns]\n",
      "ENTREZ_GENE_ID     object\n",
      "prote_exp         float64\n",
      "prote_top         float64\n",
      "bulk_exp          float64\n",
      "bulk_top          float64\n",
      "dtype: object\n",
      "17 single ENTREZ_GENE_IDs to merge\n",
      "id_list: 20, set: 20\n",
      "entrez_single_id_list: 34399, set: 25710\n",
      "entrez_id_list: 8, set: 8"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "dups: 0, set: 0\n",
      "8 id merged\n",
      "                prote_exp  prote_top  bulk_exp  bulk_top\n",
      "ENTREZ_GENE_ID                                          \n",
      "1                     1.0        0.0       0.0       0.0\n",
      "10                    NaN        NaN       0.0       0.0\n",
      "100                   1.0        1.0       0.0       0.0\n",
      "1000                  0.0        0.0       0.0       0.0\n",
      "10000                 1.0        0.0       0.0       0.0\n",
      "...                   ...        ...       ...       ...\n",
      "9991                  1.0        1.0       0.0       0.0\n",
      "9992                  NaN        NaN       0.0       0.0\n",
      "9993                  NaN        NaN       0.0       0.0\n",
      "9994                  1.0        0.0       0.0       0.0\n",
      "9997                  1.0        0.0       0.0       0.0\n",
      "\n",
      "[25701 rows x 4 columns]\n",
      "(25693, 2)\n",
      "(8, 2)\n",
      "(20, 2)\n",
      "(25713, 2)\n",
      "Naive: save to G:/GitHub/MADRID/docker/pipelines/data\\GeneExpression_Naive_Merged.csv\n",
      "\n",
      "{'Naive': 'G:/GitHub/MADRID/docker/pipelines/data\\\\GeneExpression_Naive_Merged.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Step 1.4 Merge the gene lists of transcriptomics and proteomics, create a list of active gene IDs\n",
    "merge_method = \"union\" # determine expression for genes that are either the \n",
    "\n",
    "cmd = ' '.join(['python', 'merge_xomics.py', \n",
    "      #'-t', '\"{}\"'.format(transcriptomics_config_file),\n",
    "      '-b', '\"{}\"'.format(bulk_config_file),\n",
    "      '-p', '\"{}\"'.format(proteomics_config_file),])\n",
    "      #'-m', '\"{}\"'.format(merge_method))\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create tissue-specific or cell-type-specific Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Naive': 'G:/GitHub/MADRID/docker/pipelines/data\\\\GeneExpression_Naive_Merged.csv'}\n"
     ]
    }
   ],
   "source": [
    "# Load the output of step 1, which is a dictionary that specifies the merged list of active Gene IDs for each tissue\n",
    "\n",
    "step1_results_file = os.path.join(configs.rootdir, 'data', 'step1_results_files.json')\n",
    "with open(step1_results_file) as json_file:\n",
    "    tissue_gene_exp = json.load(json_file)\n",
    "print(tissue_gene_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 2 here ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (input) filename of General Model, Recon3D_Teff_ver2\n",
    "GeneralModelFile = 'GeneralModel.mat'\n",
    "\n",
    "# (input) filename of Tissue Gene Expression\n",
    "# genefile = 'merged_Th1.csv'\n",
    "\n",
    "# (output) filename of Tissue Specific Model\n",
    "# tissuefile = 'Th1_SpecificModel.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General Model file is \"GeneralModel.mat\"\n",
      "Gene Expression file is \"GeneExpression_Naive_Merged.csv\"\n",
      "Output file is \"Naive_SpecificModel.mat\"\n",
      "Using \"GIMME\" reconstruction algorithm\n",
      "(25713, 2)\n",
      "(0, 2)\n",
      "(0, 2)\n",
      "(25713, 2)\n",
      "Map gene expression to reactions, 0 errors.\n",
      "1's: 6707\n",
      "2's: 0\n",
      "model\n",
      "Genes: 890\n",
      "Metabolites: 5461\n",
      "Reactions: 6707\n",
      "1.0*biomass_reaction_Mphage - 1.0*biomass_reaction_Mphage_reverse_6cff5\n",
      "<Solution 0.000 at 0x1f362baf898>\n",
      "{'Naive': 'Naive_SpecificModel.mat'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\cobamp\\gpr\\core.py:116: UserWarning: Will not normalize rules with more than 20 average tokens per gene\n",
      "  'Will not normalize rules with more than ' + str(token_to_gene_ratio) + ' average tokens per gene')\n"
     ]
    }
   ],
   "source": [
    "# create tissue specific model, the names of output files are stored in dictionary tissue_spec_model\n",
    "tissue_spec_model = {}\n",
    "reconAlgorithm = \"FASTCORE\" # troppo reconstruction algorithm to use\n",
    "\n",
    "for key,value in tissue_gene_exp.items():\n",
    "    tissuefile = '{}_SpecificModel.mat'.format(key)\n",
    "    tissue_spec_model[key] = tissuefile\n",
    "    tissue_gene_file = re.split('/|\\\\\\\\', value)[-1]\n",
    "    tissue_gene_folder = os.path.join(configs.rootdir, 'data', key)\n",
    "    os.makedirs(tissue_gene_folder, exist_ok=True)\n",
    "    cmd = ' '.join(['python', 'create_tissue_specific_model.py', \n",
    "                      '-m', '\"{}\"'.format(GeneralModelFile), \n",
    "                      '-g', '\"{}\"'.format(tissue_gene_file),\n",
    "                      '-o', '\"{}\"'.format(tissuefile),\n",
    "                      '-a', '\"{}\"'.format(reconAlgorithm)])\n",
    "    !{cmd}\n",
    "\n",
    "print(tissue_spec_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Identifying disease related genes by analyzing transcriptomics data of patients\n",
    "Differential Expression Analysis\n",
    "\n",
    "Only 1 disease to be analyzed, output files in data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** Specify input files for step 3 here ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input filename transcriptomics data of disease\n",
    "disease_gene_file = 'disease_transcriptomics_data_inputs.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file is \" disease_transcriptomics_data_inputs.xlsx\n",
      "Initialize project (GSE56649):\n",
      "Root: G:/GitHub/MADRID/docker/pipelines/\n",
      "Raw data: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366348.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366349.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366350.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366351.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366352.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366353.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366354.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366355.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366356.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366357.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366358.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366359.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366360.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366361.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366362.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366363.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366364.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366365.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366366.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366367.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366368.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\pandas2ri.py:17: FutureWarning: pandas.core.index is deprecated and will be removed in a future version.  The public classes are available in the top-level namespace.\n",
      "  from pandas.core.index import Index as PandasIndex\n",
      "Traceback (most recent call last):\n",
      "  File \"disease_analysis.py\", line 123, in <module>\n",
      "    main(sys.argv[1:])\n",
      "  File \"disease_analysis.py\", line 83, in main\n",
      "    data2 = affyio.fitaffydir(rawdir, targetdir)\n",
      "  File \"C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\functions.py\", line 178, in __call__\n",
      "    return super(SignatureTranslatedFunction, self).__call__(*args, **kwargs)\n",
      "  File \"C:\\Users\\babes\\Anaconda3\\lib\\site-packages\\rpy2\\robjects\\functions.py\", line 106, in __call__\n",
      "    res = super(Function, self).__call__(*new_args, **new_kwargs)\n",
      "rpy2.rinterface.RRuntimeError: Error in file(file, \"rt\") : cannot open the connection\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Retrieve Sample: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GSM1366369.tar\n",
      "Extract to: G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Retrieve Samples Completed.\n",
      "GPL570:affy, G:/GitHub/MADRID/docker/pipelines/data\\GSE56649_RAW\\GPL570\n",
      "Error in file(file, \"rt\") : cannot open the connection\n",
      "In addition: Warning message:\n",
      "In file(file, \"rt\") :\n",
      "  cannot open file 'data\\targets.txt': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Differential gene expression analysis\n",
    "cmd = ' '.join(['python', 'disease_analysis.py', \n",
    "              '-i', '\"{}\"'.format(disease_gene_file)])\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results of step 3 to dictionary 'disease_files'\n",
    "step3_results_file = os.path.join(configs.datadir, 'step2_results_files.json')\n",
    "with open(step3_results_file) as json_file:\n",
    "    disease_files = json.load(json_file)\n",
    "print(disease_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Identification of drug targets and repurposable drugs\n",
    "This step maps drug targets in metabolic models,prforms knock out simulation, and compare simulation results with disease genes and identifies drug targets and repurposable drugs\n",
    "\n",
    "*** Specify input files for step 4 here ***\n",
    "\n",
    "1. Instruction: A processed Drug-Target file is included in the `/root/pipelines/data/`. (Optional step) For the updated versions the users can download `Repurposing_Hub_export.txt` from [Drug Repurposing Hub](https://clue.io/repurposing-app). From the downloaded file first remove all the activators, agonists, and withdrawn drugs and then upload to to `/root/pipelines/data/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. To use automatically created tissue specific models. Note: It is recommended to use refined and validated models for further analysis. User can define cutomized models in next sub-step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tissue specific models\n",
    "tissue_spec_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Disease_Down = disease_files['DN_Reg']\n",
    "Disease_Up = disease_files['UP_Reg']\n",
    "drug_raw_file = 'Repurposing_Hub_export.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. To use customized model, please specify `tissue_spec_model` manually, e.g. uncomment tissue_spec_model in the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually specify Up and Down Regulated Genes for Disease. (Please upload manually created files `/pipelines/data/`. Use filenames as given belwo or change them accordingly.)\n",
    "# Disease_Down = 'Disease_DOWN.txt'\n",
    "# Disease_Up = 'Disease_UP.txt'\n",
    "# drug_raw_file = 'Repurposing_Hub_export.txt'\n",
    "\n",
    "# Manually specify tissue specific models fine-tuned by user. Change names of the files accordingly. Users can use single or multiple models here. Using multiple models, simulation time will increase.\n",
    "# tissue_spec_model = {'Th1':'Th1Model.mat',\n",
    "#                      'Th2':'Th2Model.mat',\n",
    "#                      'Th17':'Th17Model.mat',\n",
    "#                      'Naive':'NaiveModel.mat'}\n",
    "\n",
    "# Manually specify tissue specific model created by matlab cobratoolbox. For example run, we have provided four models of CD4+ T cells (niave, Th1, Th2, and Th17) please uncomment all or any specific model\n",
    "# tissue_spec_model = {'Th1':'Th1_SpecificModel_matlab.mat',\n",
    "#                      'Th2':'Th2_SpecificModel_matlab.mat',\n",
    "#                      'Th17':'Th17_SpecificModel_matlab.mat',\n",
    "#                      'Naive':'Naive_SpecificModel_matlab.mat'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Knock out simulation for the analyzed tissues\n",
    "for key,value in tissue_spec_model.items():\n",
    "    tissueSpecificModelfile = value\n",
    "    tissue_gene_folder = os.path.join(configs.datadir, key)\n",
    "    os.makedirs(tissue_gene_folder, exist_ok=True)\n",
    "    inhibitors_file = '{}_inhibitors_Entrez.txt'.format(key)\n",
    "    cmd = ' '.join(['python3' , 'knock_out_simulation.py',\n",
    "                  '-t', tissueSpecificModelfile,\n",
    "                  '-i', inhibitors_file,\n",
    "                  '-u', Disease_Up,\n",
    "                  '-d', Disease_Down,\n",
    "                  '-f', key,\n",
    "                  '-r', drug_raw_file])\n",
    "    !{cmd}\n",
    "    \n",
    "    # copy generated output to output folder\n",
    "    cmd = ' '.join(['cp', '-a', os.path.join(configs.datadir, key), configs.outputdir])\n",
    "    !{cmd}\n",
    "    #break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
