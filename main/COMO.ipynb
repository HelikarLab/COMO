{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMO: Constraint-based Optomization of Metabolic Objectives\n",
    "\n",
    "COMO is used to build computational models that simulate the biochemical and phisiological processes that occur in a cell or organism, known as constraint-based metabolic models. The basic idea behind a constraint-based metabolic model is to use a set of constraints to place boundaries on the system being modeled. These constraints may include (but are not limited to) limits on the availability of nutrients, energy requirements, and the maximum rates of metabolic reactions. COMO imposes these constraints within a specific context. This context includes the cell or tissue type being modeled, along with its disease state. In addition to creating metabolic models, COMO serves as a platform to identify (1) drug targets and (2) repurposable drugs for metabolism-impacting diseases.\n",
    "\n",
    "\n",
    "This pipeline has everything necessary to build a model from any combination of the following sources:\n",
    "- Bulk RNA-seq\n",
    "- Single-cell RNA-seq\n",
    "- Proteomics\n",
    "- Microarray\n",
    "\n",
    "\n",
    "COMO does not require programming experience to create models. However, every step of the pipeline is easily accessable to promote modification, addition, or replacement of analysis steps. In addition, this docker container comes pre-loaded with popular R and Python libraries; if you would like to use a library and cannot install it for any reason, please [request it on our GitHub page](https://github.com/HelikarLab/COMO)!\n",
    "\n",
    "\n",
    "<h2>\n",
    "<font color='red'>⚠️ WARNING ⚠️</font>\n",
    "</h2>\n",
    "\n",
    "If you terminate your session after running Docker, any changes you make *will <ins>**not**</ins> be saved*. Please mount a local directory to the docker image, [as instructed on the GitHub page](https://helikarlab.github.io/COMO/#choosing-a-tag), to prevent data loss.\n",
    "\n",
    "# Before Starting\n",
    "## Input Files\n",
    "The proper input files, dependent on the types of data you are using, must be loaded before model creation. Some example files are included to build metabolic models of naive, Th1, Th2, and Th17 T-cell subtypes, and identify targets for rheumatoid arthritis.\n",
    "\n",
    "### RNA-seq\n",
    "A correctly formatted folder named \"COMO inputs\" in the data directory. Proper inputs can be generated using our Snakemake pipeline, [FastqToGeneCounts](https://github.com/HelikarLab/FastqToGeneCounts), which is specifically designed for use with COMO. RNA sequencing data can be single-cell, or bulk, but the provided Snakemake pipeline does not process single-cell data as of now. If you are processing RNA-seq data with an alternate procedure or importing a pre-made gene count matrix, follow the instructions [listed under Step 1](#Importing-a-Pre-Generated-Counts-Matrix)\n",
    "\n",
    "### Proteomics\n",
    "A matrix of measurement values, where rows are protein names in Entrez format and columns are sample names\n",
    "\n",
    "### Microarray\n",
    "Results must be uploaded to the [Gene Expression Omnibus](https://www.ncbi.nlm.nih.gov/geo/). In COMO, a configuration file with the GSE, GSM, and GPL codes is required. A template file is located under `data/config_sheets/microarray_data_inputs_template.xlsx`.\n",
    "\n",
    "> Note: Microarray has become mostly obsolete, and it is highly recommended to use RNA-seq if possible\n",
    "\n",
    "## Configuration Information\n",
    "You should upload configuration files (in Excel format, `.xlsx`) to `data/config_sheets`. The sheet names in these configuration files should correspond to the context (tissue name, cell name, etc.). The data in each sheet contains the sample names to include in that context-specific model. These sample names should correspond to the column name in the source data matrix, which will be output (or uploaded, if you have your own data) to `data/data_matrices/MODEL-NAME`\n",
    "\n",
    "# Drug Target Identification\n",
    "\n",
    "1. Preprocess Bulk RNA-seq data\n",
    "    1. Convert STAR-output gene count files into a unified matrix\n",
    "    2. Fetch necessary information about each gene in the matrix\n",
    "    3. Generate a configuration file\n",
    "2. Analyze any combination of microarray, RNA-seq, or proteomics data, and output a list of active genes for each strategy\n",
    "3. Check for a consensus amongst strategies according to a desired rigor and merge into a singular set of active genes\n",
    "4. Create a tissue-specific model based on the list of active genes (from Step 3)\n",
    "5. Identify differential gene expression from disease datasets using microarray or RNA-seq transcriptomics information\n",
    "6. Identify drug targets and repurposable drugs. This step consists of four substeps:\n",
    "    1. Map drugs to models\n",
    "    2. Knock-out simulation\n",
    "    3. Compare results between perturbed and unperturbed models (i.e., knocked-out models vs non-knocked-out models)\n",
    "    4. Integrate with disease genes and create a score of drug targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Initialize and Preprocess RNA-seq data\n",
    "> Skip if not using RNA-seq\n",
    "\n",
    "RNA sequencing data is read by COMO as a count matrix, where each column is a different sample or replicate named \"tissueName_SXRYrZ\", where:\n",
    "- \"`X`\" represents the study (or batch) number. Each study represents a new experiment\n",
    "- \"`Y`\" represents the replicate number\n",
    "- \"`Z`\" represents the run number. If the replicate does not contain multiple runs for a single replicate, then \"`rZ`\" should not be included.\n",
    "- \"`tissueName`\" represents the name of the model that will be built from this data. It should be consistent with other data sources if you would like them to be integrated.\n",
    "\n",
    "❗The `tissueName` identifier should not contain any special characters, including `_`. Doing so may interfere with parsing throughout this pipeline.\n",
    "\n",
    "Replicates should come from the same study or batch group. Different studies/batches can come from different published studies, as long as the tissue/cell was under similar enough conditions for your personal modeling purposes. \"Run numbers\" in the same replicate will be summed together.\n",
    "\n",
    "## Example\n",
    "Pretend `S1` represents a study done by Margaret and `S2` represents a different study done by John. Margaret's experiment contains three replicates, while John's only contains two. Each of these studies comes from m0 Macrophages. Using this cell name, we will set our tissue name to `m0Macro`. The studies were conducted in different labs, by different researches, at different points in time, even using different preparation kits. . Using this information, we have the following samples:\n",
    "\n",
    "<table style=\"border: 1px solid black; border-collapse: collapse;\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th colspan=\"1000\" style=\"text-align: center;\">m0 Macrophage Data</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td colspan=\"3\" style=\"padding: 10px; text-align: center; border-bottom: 1px solid black;\">Margaret's Data</td>\n",
    "            <td colspan=\"3\" style=\"padding: 10px; text-align: center; border-left: 1px solid black; border-bottom: 1px solid black;\">John's Data</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; text-align: center;\">Study</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">Replicate</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">Resulting Name</td>\n",
    "            <td style=\"padding: 10px; text-align: center; border-left: 1px solid black;\">Study</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">Replicate</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">Resulting Name</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; text-align: center;\">S1</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">R1</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">m0Macro_S1R1</td>\n",
    "            <td style=\"padding: 10px; text-align: center; border-left: 1px solid black;\">S2</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">R1</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">m0Macro_S2R1</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; text-align: center;\">S1</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">R2</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">m0Macro_S1R2</td>\n",
    "            <td style=\"padding: 10px; text-align: center; border-left: 1px solid black;\">S2</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">R2</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">m0Macro_S2R2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; text-align: center;\">S1</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">R3</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">m0Macro_S1R3</td>\n",
    "            <td style=\"padding: 10px; text-align: center; border-left: 1px solid black;\">-</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">-</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">-</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "From the `Resulting Name` column, the `m0Macro_S1R1`, `m0Macro_S1R2`, and `m0Macro_S1R3` samples (Margaret's data) will be checked for gene expression consensus to generate a list of active genes in all three replicates. The same will be done for `m0Macro_S2R1` and `m0Macro_S2R2` (John's data). Once these two *separate* lists of active genes have been generated, expression *between* lists will be checked for additional consensus between the studies. This system is used not only to help maintain organization throughout COMO, but because most types of normalized gene counts cannot undergo direct comparisons across replicates. This is especially true for comparisons between different experiments. Therefore, COMO will convert normalized gene counts into a boolean list of active genes. These lists will be compared at the level of replicates in a study, and then again at the level of all provided studies. Finally, the active genes will be merged with the outputs of proteomics, microarray, and various RNA-sequencing strategies if provided. The rigor used at each level is easily modifiable.\n",
    "\n",
    "\n",
    "## Initializing RNA-seq Data\n",
    "\n",
    "Please choose an option below:\n",
    "1. Importing a `COMO inputs` directory\n",
    "    1. [Initialization using the Snakemake Pipeline](#1.-Snakemake-Pipeline)\n",
    "    2. [Creating your own Inputs](#Creating-a-Properly-Formatted-COMO-inputs-Folder)\n",
    "2. [Importing a pre-generated gene counts file](#Importing-a-Pre-Generated-Counts-Matrix)\n",
    "\n",
    "### Snakemake Pipeline\n",
    "It is recommended you use the available Snakemake pipeline to align to create a properly formatted `COMO inputs` folder. The pipeline also runs a series of quality control steps to help determine if any of the provided samples are not suitable for model creation. This pipeline can be found at https://github.com/HelikarLab/FastqToGeneCounts.\n",
    "\n",
    "The folder output from the snakemake pipeline can be uploaded directly to the folder `data/COMO inputs` in this pipeline\n",
    "\n",
    "Once this is done, continue to the code block at the end of this section\n",
    "\n",
    "### Creating a Properly Formatted `COMO inputs` Folder\n",
    "\n",
    "\n",
    "If you are using your own alignment protocol, follow this section to create a properly formatted `COMO inputs` folder.\n",
    "\n",
    "The top-level of the directory will have separate tissue/cell types that models should be created from. The next level must have a folder called `geneCounts`, and optionally a `strandedness` folder. If you are using zFPKM normalization, two additional folders must be included: `layouts` and `fragmentSizes`. Inside each of these folders should be folders named `SX`, where `X` is a number that replicates are associated with.\n",
    "\n",
    "#### Gene Counts\n",
    "Create a folder named `geneCounts`. The outputs of the STAR aligner using the `-quantMode GeneCounts` option should be included inside the \"study-number\" folders (`SX`) of `geneCounts`. To help you (and COMO!) stay organized, these outputs should be renamed `tissueName_SXRYrZ.tab`. Just like above, `X` is the study number, `Y` is the replicate number, and (if present), `Z` is the run number. If the replicate does not contain multiple runs, the `rZ` should be excluded from the name. Replicates should come from the same study/sample group. Different samples can come from different published studies as long as the experiments were performed under similar enough conditions for your modeling purposes.\n",
    "\n",
    "#### Strandedness\n",
    "Create a folder named `strandedness`. This folder should contain files named `tissueName_SXRYrZ_strandedness.txt`. These files must tell the strandedness of the RNA-sequencing method used. It should contain one of the following texts (and nothing else):\n",
    "    - `NONE`: If you don't know the strandedness\n",
    "    - `FIRST_READ_TRANSCRIPTION_STRAND`: If this RNA-sequencing sample originates from the first strand of cDNA, or the \"antisense\" strand\n",
    "    - `SECOND_READ_TRANSCRIPTION_STRAND`: If this RNA-sequencing sample originates from the second strand of cDNA, or the \"sense\" strand\n",
    "\n",
    "#### Layouts\n",
    "Create a folder a folder named `layouts`. Files should be named `tissueName_SXRYrZ_layout.txt, where each file tells the layout of the library used. It must contain one of the following texts, and nothing else:\n",
    "- `paired-end`: Paired-end reads were generated\n",
    "- `single-end`: Single-end reads were generated\n",
    "\n",
    "#### Fragment Sizes\n",
    "Create a folder named `fragmentSizes`. Files should be named `tissueName_SXRYrZ_fragment_sizes.txt` and contain the output of [RSeQC](https://rseqc.sourceforge.net/)'s `py/RNA_fragment_size.py` function.\n",
    "\n",
    "#### Preparation Methods\n",
    "Create a folder named `prepMethods`. Files should be named `tissueName_SXRYrZ_prep_method.txt`. Each file should tell the library preparation strategy. It must contain one of the following texts, and nothing else:\n",
    "- `total`: All mRNA expression was measured (mRNA, ncRNA, rRNA, etc.)\n",
    "- `mRNA`: Only polyA mRNA expression was measured\n",
    "\n",
    "It should be noted that these strategies only serve to differentiate the methods in the event that both are used to build a model. If a different library strategy is desired, you have two options:\n",
    "1. Replace one of these with a placeholder. If you only have polyA mRNA expression, you only have to enter data for those samples. Do not fill out any samples with `total`.\n",
    "2. With a little Python knowledge, a new strategy can easily be added to the `py/merge_xomics.py` file. If you would like to do so, the file is located under `py/merge_xomics.py` in this Jupyter Notebook\n",
    "\n",
    "### Importing a Pre-Generated Counts Matrix\n",
    "Import a properly formatted counts matrix to `data/data_matrices/exampleTissue/gene_counts_matrix_exampleTissue.csv`. The rows should be named `exampleTissue_SXRY` (note the lack of a run number (`rZ`), runs should be summed into each replicate). If you are providing the count matrix this way, instead of generating one using the snakemake pipeline mentioned above, you must create a configuration file that has each sample's name, study number, and if using zFPKM, layout and mean fragment length. Use the provided template below to create yours. Once you have created this file and placed it under the `data/data_matrices/exampleTissue` directory, run the `py/rnaseq_preprocess.py` file with `preprocess-mode` set to `provide-matrix`.\n",
    "\n",
    "This method is best if you are downloading a premade count matrix, or using single-cell data that has already been batch corrected, clustered, and sorted into only the cell type of interest!\n",
    "\n",
    "\n",
    "<table style=\"border: 1px solid black; border-collapse: collapse;\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th colspan=\"1000\" style=\"text-align: center; border-bottom: 1px solid black;\">Example Gene Count Table</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; text-align: center; border-bottom: 1px solid black;\">genes</td>\n",
    "            <td style=\"padding: 10px; text-align: center; border-left: 1px solid black; border-bottom: 1px solid black;\">exampleTissue_S1R1</td>\n",
    "            <td style=\"padding: 10px; text-align: center; border-left: 1px solid black; border-bottom: 1px solid black;\">exampleTissue_S1R2</td>\n",
    "            <td style=\"padding: 10px; text-align: center; border-left: 1px solid black; border-bottom: 1px solid black;\">exampleTissue_S2R1</td>\n",
    "            <td style=\"padding: 10px; text-align: center; border-left: 1px solid black; border-bottom: 1px solid black;\">exampleTissue_S2R2</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; text-align: center;\">ENSG00000000003</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">20</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">29</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">52</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">71</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; text-align: center;\">ENSG00000000005</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">0</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">0</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">0</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">0</td>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <td style=\"padding: 10px; text-align: center;\">ENSG00000000419</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">1354</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">2081</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">1760</td>\n",
    "            <td style=\"padding: 10px; text-align: center;\">3400</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "\n",
    "\n",
    "## Parameters\n",
    "- `context_names`: The tissue/cell types to use. This is a simple space-separated list of items, such as \"naiveB regulatoryTcell\"\n",
    "- `gene_format`: The format of input genes, accepts `\"Extrez\"`, `\"Emsembl\"` or `\"Symbol\"`\n",
    "- `taxon_id`: The [NCBI Taxon ID](https://www.ncbi.nlm.nih.gov/taxonomy) to use\n",
    "- `preprocess_mode`: This should be set to `\"create-matrix\"` if you are **not** providing a matrix, otherwise set it to `\"provide-matrix\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "context_names = \"naiveB smB\"\n",
    "gene_format = \"Ensembl\"      # accepts \"Entrez\", \"Ensembl\", and \"Symbol\"\n",
    "taxon_id = \"human\"           # accepts integer (bioDBnet taxon id) or \"human\" or \"mouse\"\n",
    "preprocess_mode = \"create-matrix\" # \"create-matrix\" or \"provide-matrix\"\n",
    "\n",
    "cmd = \" \".join(\n",
    "    [\n",
    "        \"python3\", \"py/rnaseq_preprocess.py\",\n",
    "        \"--context-names\", f'{context_names}',\n",
    "        \"--gene-format\", f\"{gene_format}\",\n",
    "        \"--taxon-id\", f\"{taxon_id}\",\n",
    "        f\"--{preprocess_mode}\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Identifying Gene Activity in Transcriptomics and Proteomics Datasets\n",
    "\n",
    "Identify gene activity in the following data sources:\n",
    "- RNA-seq (bulk or single cell)\n",
    "- Proteomics\n",
    "- Microarray\n",
    "\n",
    "Only one source is required for model generation, but multiple sources can be helpful for additional validation if they are of high enough quality\n",
    "\n",
    "## Filtering Raw Counts\n",
    "Regardless of normalization technique used, or provided files used for RNA-seq, preprocessing is required to fetch relevent gene information needed for harmonization and normalization such as Entrez ID, and the start and end postions. Currently, COMO can filter raw RNA-sequencing counts using one of the following normalization techniques:\n",
    "\n",
    "### Transcripts Per Million Quantile\n",
    "TPM Quantile. Each replicate is normalized with Transcripts-Per-Million, and an upper quantiile is taken to create a boolean list of active genes for the replicate (i.e., `R1`). Replicates are compared for consensus within the study, and then studies are compared between one another for additional consensus. The strictness of the consensus easily be set using the appropriate option within the `rnaseq_gen.py` code-block.\n",
    "\n",
    "This method is recommended if you want more control over the size of the model; smaller models can include only the most expressed reactions, and larger models can encompass less essentail reactions\n",
    "\n",
    "### zFPKM\n",
    "This method is outlined by [Hart et. al](https://pubmed.ncbi.nlm.nih.gov/24215113/). Counts will be normalized using zFPKM and genes > -3 will be considered \"expressed\" per Hart's recommendation. Expressed genes will be checked for consensus at the replicate and study level.\n",
    "\n",
    "This method is recommended if you want to less control over which genes are essential, and instead use the most standardized method of active gene determination. This method is more \"hands-off\" than the above TPM Quantile method.\n",
    "\n",
    "### Counts Per Million\n",
    "This is a flat cutoff value of counts per million normalized values. Gene expression will be checked for consensus at the replicate and study level.\n",
    "\n",
    "This method is not recommended, as zFPKM is much more robust for a similar level of \"hands-off\" model building\n",
    "\n",
    "## Microarray\n",
    "COMO can directly download and analyze microarray data from NCBI's [Gene Expression Omnibus](https://www.ncbi.nlm.nih.gov/geo/) for Agilent or Affymetrix platforms. Follow the microarray template below to use microarray data in your model creation.\n",
    "\n",
    "> NOTE: Microarray technology is becoming increasingly obsolete. If possible, it is **highly** recommended that you using RNA-sequencing data instead. Although different strategies exist for microarray, COMO does not distinguish between them, nor are there any plans to do so due to better methods existing for RNA quantification\n",
    "\n",
    "## RNA Sequencing Analysis\n",
    "### Bulk RNA Sequencing\n",
    "\n",
    "This has multiple strategies of library preparation (total, polyA-mRNA). If you are using public data, you may encounter a situation where you would like to use a combination of bulk RNA sequencing data produced using two different library preparation strategies.\n",
    "\n",
    "COMO currently supports the two most common strategies, mRNA polyA enriched RNA sequencing, and total RNA sequencing. Because of the expected differences in distribution of transcripts, COMO is written to handle each strategy seperately before the integration step. The recommended Snakemake alignment pipeline is designed to work with COMO's preprocessing step ([Step 1, above](Step-1:-Initialize-and-Preprocess-RNA-seq-data)) to split RNA sequencing data from GEO into seperate input matrices and configuration files.\n",
    "\n",
    "To create a gene expression file for total RNA sequencing data, use `\"total\"` for the \"`--library-prep`\" argument.\n",
    "To create a gene expression file for mRNA polyA enriched data, use `\"mRNA\"` for the  \"`--library-prep`\" argument.\n",
    "\n",
    "The analysis of each strategy is identical. Specifying the type of analysis (total vs mRNA) only serves to ensure COMO analyzes them seperately.\n",
    "\n",
    "### Single Cell RNA Sequencing\n",
    "While the Snakemake pipeline does not yet support single-cell alignment, and COMO does not yet support automated configuration file and counts matrix file creation for single-cell alignment output from STAR, it is possible to use single-cell data to create a model with COMO. Because normalization strategies can be applied to single-cell data in the same way it is applied to bulk RNA sequencing, `py/rnaseq_gen.py` can be used with a provided counts matrix and configuration file, from [Step 1](Step-1:-Initialize-and-Preprocess-RNA-seq-data), above. Just like `\"total\"` and `\"mRNA\"`, `py/rnaseq_gen.py` can be executed with `\"SC\"` as the \"`--library-prep`\" argument to help COMO differentiate it from any bulk RNA sequencing data if multiple strategies are being used.\n",
    "\n",
    "## Total RNA Sequencing Generation\n",
    "### Parameters\n",
    "- `trnaseq_config_file`: The configuration filename for total RNA. This file is found under the `data/config_sheets` folder\n",
    "- `rep_ratio`: The proportion of replicates before a gene is considered \"active\" in a study\n",
    "- `group_ratio`: The proportion of studies with expression required for a gene to be considered \"active\"\n",
    "- `rep_ratio_h`: The proportion of replicates that must express a gene before that gene is considered \"high-confidience\"\n",
    "- `group_ratio_h`: The proportion of studies that must express a gene before that gene is considered \"high-confidence\"\n",
    "- `technique`: The technique to use. Options are: `\"quantile\"`, `\"cpm\"`, or `\"zfpkm\"`. The difference in these options is discussed above\n",
    "- `quantile`: The cutoff Transcripts-Per-Million quantile for filtering\n",
    "- `min_zfpkm`: The cutoff for Counts-Per-Million filtering\n",
    "- `prep_method`: The library method used for preparation. Options are: `\"total\"`, `\"mRNA\"`, or `\"SC\"`,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 2.2 RNA-seq Analysis for Total RNA-seq library preparation\n",
    "\n",
    "trnaseq_config_file = \"trnaseq_data_inputs_auto.xlsx\"\n",
    "rep_ratio = 0.75\n",
    "group_ratio = 0.75\n",
    "rep_ratio_h = 1.0\n",
    "group_ratio_h = 1.0\n",
    "technique = \"zFPKM\"\n",
    "quantile = 50\n",
    "min_zfpkm = -3\n",
    "prep_method = \"total\"\n",
    "\n",
    "cmd = \" \".join(\n",
    "    [\n",
    "        \"python3\", \"py/rnaseq_gen.py\",\n",
    "        \"--config-file\", f\"{trnaseq_config_file}\",\n",
    "        \"--replicate-ratio\", f\"{rep_ratio}\",\n",
    "        '--batch-ratio', f\"{group_ratio}\",\n",
    "        \"--high-replicate-ratio\", f\"{rep_ratio_h}\",\n",
    "        \"--high-batch-ratio\", f\"{group_ratio_h}\",\n",
    "        \"--filt-technique\", f\"{technique}\",\n",
    "        \"--min-zfpkm\", f\"{min_zfpkm}\",\n",
    "        \"--library-prep\", f\"{prep_method}\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## mRNA Sequencing Generation\n",
    "These parameters are identical to the ones listed for [total RNA sequencing](#Total-RNA-Sequencing-Generation), but they are listed again here for ease of reference\n",
    "\n",
    "### Parameters\n",
    "- `mrnaseq_config_file`: The configuration filename for total RNA. This file is found under the `data/config_sheets` folder\n",
    "- `rep_ratio`: The proportion of replicates before a gene is considered \"active\" in a study\n",
    "- `group_ratio`: The proportion of studies with expression required for a gene to be considered \"active\"\n",
    "- `rep_ratio_h`: The proportion of replicates that must express a gene before that gene is considered \"high-confidience\"\n",
    "- `group_ratio_h`: The proportion of studies that must express a gene before that gene is considered \"high-confidence\"\n",
    "- `technique`: The technique to use. Options are: `\"quantile\"`, `\"cpm\"`, or `\"zfpkm\"`. The difference in these options is discussed above\n",
    "- `quantile`: The cutoff Transcripts-Per-Million quantile for filtering\n",
    "- `min_zfpkm`: The cutoff for Counts-Per-Million filtering\n",
    "- `prep_method`: The library method used for preparation. Options are: `\"total\"`, `\"mRNA\"`, or `\"SC\"`,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mrnaseq_config_file = \"mrnaseq_data_inputs_auto.xlsx\"\n",
    "rep_ratio = 0.75\n",
    "group_ratio = 0.75\n",
    "rep_ratio_h = 1.0\n",
    "group_ratio_h = 1.0\n",
    "technique = \"zfpkm\"\n",
    "quantile = 50\n",
    "min_zfpkm = -3\n",
    "prep_method = \"mrna\"\n",
    "\n",
    "cmd = \" \".join(\n",
    "    [\n",
    "        \"python3\", \"py/rnaseq_gen.py\",\n",
    "        \"--config-file\", f\"{mrnaseq_config_file}\",\n",
    "        \"--replicate-ratio\", f\"{rep_ratio}\",\n",
    "        \"--batch-ratio\", f\"{group_ratio}\",\n",
    "        \"--high-replicate-ratio\", f\"{rep_ratio_h}\",\n",
    "        \"--high-batch-ratio\", f\"{group_ratio_h}\",\n",
    "        \"--filt-technique\", f\"{technique}\",\n",
    "        \"--min-zfpkm\", f\"{min_zfpkm}\",\n",
    "        \"--quantile\", f\"{quantile}\",\n",
    "        \"--library-prep\", f\"{prep_method}\"\n",
    "    ]\n",
    ")\n",
    "                \n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Proteomics Analysis\n",
    "The parameters here are mostly the same to total RNA and mRNA sequencing analysis, and are listed here for easier reference\n",
    "\n",
    "### Parameters\n",
    "- `proteomics_config_file`: The file path to the proteomics configuration file\n",
    "- `rep_ratio`: The ratio required before a gene is considered active in the replicate\n",
    "- `batch_ratio`: The ratio required before a gene is considered active in the study\n",
    "- `high_rep_ratio`: The ratio required before a gene is considered \"high-confidence\" in the replicate\n",
    "- `high_batch_ratio`: The ratio required before a gene is considered \"high-confidence\" in the study\n",
    "- `quantile`: The cutoff Transcripts-Per-Million quantile for filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteomics_config_file = \"proteomics_data_inputs_paper.xlsx\"\n",
    "rep_ratio = 0.75\n",
    "batch_ratio = 0.75\n",
    "high_rep_ratio = 1.0\n",
    "high_batch_ratio = 1.0\n",
    "quantile = 25\n",
    "\n",
    "cmd = \" \".join(\n",
    "    [\n",
    "        \"python3\", \"py/proteomics_gen.py\",\n",
    "        \"--config-file\", f\"{proteomics_config_file}\",\n",
    "        \"--replicate-ratio\", f\"{rep_ratio}\",\n",
    "        \"--high-replicate-ratio\", f\"{high_rep_ratio}\",\n",
    "        \"--batch-ratio\", f\"{batch_ratio}\",\n",
    "        \"--high-batch-ratio\", f\"{high_batch_ratio}\",\n",
    "        \"--quantile\", f\"{quantile}\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Merge Expression from Different Data Sources\n",
    "\n",
    "Thus far, active genes have been determined for at least one data source. If multiple data sources are being used, we can merge the active genes from these sources to make a list of active genes that is more comprehensive (or strict!) than any data source on its own.\n",
    "\n",
    "`py/merge_xomics.py` takes each data source discussed so far as an argument. The other arguments to consider are:\n",
    "- `--expression-requirement`: The number of data sources with expression required for a gene to be considered active, if the gene is not \"high-confidence\" for any source. (default: total number of input sources provided)\n",
    "- `--requirement-adjust`: This is used to adjust the expression requirement argument in the event that tissues have a different number of provided data sources. This does nothing if there is only one tissue type in the configuration files.\n",
    "    - `\"progressive\"`: The expression requirement applies to tissue(s) with the lowest number of data sources. Tissues with more than this value will require its genes to be expressed in 1 additional source before it is \"active\" in the model\n",
    "    - `\"regressive\"` (default): The expression requirement applies to the tissue(s) with the largest number of data sources. Tissues with less than this value will require its genes to be expressed in 1 fewer sources before the gene is considered \"active\" in the model.\n",
    "    - `\"flat\"`: The expression requirement is used regardless of differences in the number of data sources provided for different tissues\n",
    "\n",
    "- `--no-hc`: This flag should be set to prevent high-confidence genes from overriding the expression requirement set.\n",
    "    - If this flag is not used, any gene that was determined to be \"high-confidence\" in any input source will cause the gene to be active in the final model, regardless of agreement with other sources\n",
    "- `--no-na-adjustment`: This flag should be used to prevent genes that are not present in one data source, but are present in others, from subtracting one from the expression requirement.\n",
    "    - If this flag is not used, any time a gene is \"NA\" in a source, meaning it was not tested for in the library of that data sources but <ins>was</ins> tested in the library of another source, it will subtract one from the expression requirement.\n",
    "\n",
    "The adjusted expression requirement will never resolve to be less than one or greater than the number of data sources for a given tissue\n",
    "\n",
    "## Parameters\n",
    "The three parameters listed here were used in RNA Sequencing generation, and should not need to be defined. If you did **not** use one of these, simply un-comment it from the command below by placing a \"`#`\" at the beginning of the appropriate lines\n",
    "- `trnaseq_config_file`: The file name used in the [total RNA Sequencing](#Total-RNA-Sequencing-Generation) section of the notebook\n",
    "- `mrnaseq_config_file`: The file name used in the [mRNA Sequencing](#mRNA-Sequencing-Generation) section of the notebook\n",
    "- `proteomics_config_file`: The file name used in the [proteomics generation](#Proteomics-Analysis) section of the notebook\n",
    "\n",
    "The following parameters have not been used in a previous section of the notebook, so they are defined in the below code block\n",
    "- `expression_requirement`: This is the number of sources a gene must be active in for it to be considered active\n",
    "- `requirement_adjust`: The technique to adjust expression requirement based on differences in number of provided data source types\n",
    "- `total_rna_weight`: Total RNA-seq weight for merging zFPKM distribution\n",
    "- `mrna_weight`: mRNA weight for merging zFPKM distribution\n",
    "- `single_cell_weight`: Single-cell weight for merging zFPKM distribution\n",
    "- `proteomics_weight`: Proteomic weight for merging zFPKM distribution\n",
    "\n",
    "Each of the \"weights\" (`total_rna_weight`, `mrna_weight`, etc.) are used to place a significance on each method. Becuase there are many steps in the Dogma from transcription to translation, the gene expression as seen by total RNA or mRNA sequencing may not be representative of the gene's protein expression. Because of this, you are able to weight each source more (or less) than another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression_requirement = 3\n",
    "requirement_adjust = \"regressive\" \n",
    "total_rna_weight = 6\n",
    "mrna_weight = 6\n",
    "single_cell_weight = 6\n",
    "proteomics_weight = 10\n",
    "\n",
    "\n",
    "cmd = \" \".join(\n",
    "    [\n",
    "        \"python3\", \"py/merge_xomics.py\",\n",
    "        \"--merge-distribution\",\n",
    "        #\"--microarray-config-file\", f\"{microarray_config_file}\",  # If using micro-array, uncomment the start of this line\n",
    "        \"--total-rnaseq-config-file\", f\"{trnaseq_config_file}\",\n",
    "        \"--mrnaseq-config-file\", f\"{mrnaseq_config_file}\",\n",
    "        #\"--scrnaseq-config-file\", f\"{scrnaseq_config_file}\",      # If using single-cell data, uncomment the start of this line\n",
    "        #\"--proteomics-config-file\", f\"{proteomics_config_file}\",\n",
    "        \"--expression-requirement\", f\"{expression_requirement}\",\n",
    "        \"--requirement-adjust\", f\"{requirement_adjust}\",\n",
    "        \"--total-rnaseq-weight\", f\"{total_rna_weight}\",\n",
    "        \"--mrnaseq-weight\", f\"{mrna_weight}\",\n",
    "        #\"--single-cell-rnaseq-weight\", f\"{single_cell_weight}\",             # If using single-cell data, uncomment the start of this line\n",
    "        \"--protein-weight\", f\"{proteomics_weight}\",\n",
    "        \"--no-hc\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Create Tissue/Cell-Type Specific Models\n",
    "\n",
    "### Creation\n",
    "To create a metabolic model, the following information about each metabolite or reaction involved is required:\n",
    "- **Reaction Type**\n",
    "    - Exchange\n",
    "    - Demand\n",
    "    - Sink\n",
    "- **Metabolic/Reaction Abbreviation**\n",
    "    - You can use the [Virutal Metabolic Human](https://www.vmh.life/#home) to look up your metabolite and reaction abbreviations\n",
    "- **Compartments**\n",
    "    - Cytosol\n",
    "    - Extracellular\n",
    "    - Golgi Apparatus\n",
    "    - Internal Membranes\n",
    "    - Lysosome\n",
    "    - Mitochondria\n",
    "    - Nucleus\n",
    "    - Endoplasmic Reticulum\n",
    "    - Unknown\n",
    "- **Minimum Reaction Rate**\n",
    "- **Maximum Reaction Rate**\n",
    "\n",
    "\n",
    "*Below is an example of a properly formatted table of metabolic and reaction information*\n",
    "\n",
    "| Reaction | Abbreviation |    Compartment     | Minimum Reaction Rate | Maximum Reaction Rate |\n",
    "|:--------:|:------------:|:------------------:|:---------------------:|:---------------------:|\n",
    "| Exchange |    glc_D     |   Extracellular    |         -100          |         1000          |\n",
    "|  Demand  |  15HPETATP   |      Cytosol       |          -1           |         1000          |\n",
    "|   Sink   |    met_L     | Internal Membranes |         -1000         |           1           |\n",
    "\n",
    "\n",
    "These reactions should be placed into a CSV file; a template can be found under `data/boundary_rxns`. Place your file next to the one found here. COMO will load\n",
    "\n",
    "## Adding Reference Models\n",
    "This Jupyter notebook uses Recon3D's [Virtual Metabolic Human](https://www.vmh.life/) as a base to map reactions onto, and is included with the Jupyter notebook. If you would like to include other reference models, simply upload them to the `data` folder, and set the name of the `general_model_file` below to the name of your reference model.\n",
    "\n",
    "## Parameters\n",
    "The following is a list of parameters and their function in this section of the pipeline\n",
    "- `low_thres`: If you are using the `IMAT` reconstruction algorithm, gene expression above this value will be placed in the \"mid-expression\" bin\n",
    "- `high_thres`: If you are using the `IMAT` reconstruction algorithm, gene expression above this value will be placed in the \"high-expression\" bin\n",
    "- `output_filetypes`: These are the file types you would like to save your model as. It should be one (or multiple) of the following: `\"xml\"`, `\"mat\"`, `\"json\"`\n",
    "- `objective_dict`: This is an objective the model should be solved for. Popular options are `\"biomass_reaction\"` or `\"biomass_maintenance\"`\n",
    "- `general_model_file`: This is the reference model file to load\n",
    "- `recon_algorithm`: The troppo reconstruction algorithm to use. This should be one of the following: `\"FastCORE\"`, `\"CORDA\"`, `\"GIMME\"`, `\"tINIT\"`, `\"IMAT\"`\n",
    "- `solver`: The solver to use for optimizing the model. Options are: `\"GUROBI\"` or `\"GLPK\"`\n",
    "- `boundary_reactions_filename`: The filename of boundary reactions that should be used\n",
    "- `force_reactions_filename`: The filename of the force reactions to be used. Force reactions will (as the name implies) force the optimizer to use these reactions, **no matter their expression**\n",
    "- `exclude_reactions_filename`: The filename of reactions to exclude from the model, no matter their expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_threshold = -5\n",
    "high_threshold = -3\n",
    "output_filetypes = \"xml mat json\"\n",
    "objective_dict = {}\n",
    "general_model_file = \"GeneralModelUpdatedV2.mat\"\n",
    "recon_algorithms = ['IMAT']\n",
    "solver = \"GUROBI\"\n",
    "boundary_reactions_filename = \"default_boundary_rxns.csv\"\n",
    "force_reactions_filename = \"default_force_rxns.csv\"\n",
    "exclude_reactions_filename = \"\"\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from py.project import configs\n",
    "\n",
    "# Load the output of step 1, which is a dictionary that specifies the merged list of active Gene IDs for each tissue\n",
    "step1_results_file = os.path.join(configs.datadir, 'results', 'step1_results_files.json')\n",
    "with open(step1_results_file) as json_file:\n",
    "    context_gene_exp = json.load(json_file)\n",
    "\n",
    "\n",
    "for recon_algorithm in recon_algorithms:\n",
    "    for context in context_gene_exp.keys():\n",
    "        objective = objective_dict[context]\n",
    "\n",
    "        if recon_algorithm.upper() in [\"IMAT\", \"TINIT\"]:\n",
    "            genes_zscore_file = os.path.join(configs.datadir, \"results\", context, f\"model_scores_{context}.csv\")\n",
    "            active_genes_filepath = os.path.join(configs.datadir, \"results\", context, genes_zscore_file)\n",
    "        else:\n",
    "            gene_expression_file = context_gene_exp[context]\n",
    "            active_genes_filename = Path(gene_expression_file).name\n",
    "            active_genes_filepath = os.path.join(configs.datadir, \"results\", context, active_genes_filename)\n",
    "\n",
    "        general_model_filepath = os.path.join(configs.datadir, general_model_file)\n",
    "        boundary_reactions_filepath = os.path.join(configs.datadir, \"boundary_rxns\", boundary_reactions_filename)\n",
    "        force_reactions_filepath = os.path.join(configs.datadir, \"force_rxns\", force_reactions_filename)\n",
    "        exclude_reactions_filepath = os.path.join(configs.datadir, \"exclude_rxns\", exclude_reactions_filename)\n",
    "\n",
    "        cmd = \" \".join(\n",
    "            [\n",
    "                \"python3\", \"py/create_context_specific_model.py\",\n",
    "                \"--context-name\", f\"{context}\",\n",
    "                \"--reference-model-file\", f\"{general_model_filepath}\",\n",
    "                \"--active-genes-filepath\", f\"{active_genes_filepath}\",\n",
    "                \"--objective\", f\"{objective}\",\n",
    "                \"--boundary-reactions-filepath\", f\"{boundary_reactions_filepath}\",\n",
    "                #\"--exclude-reactions-filepath\", f\"{exclude_reactions_filepath}\",\n",
    "                \"--force-reactions-filepath\", f\"{force_reactions_filepath}\",\n",
    "                \"--algorithm\", f\"{recon_algorithm}\",\n",
    "                \"--low-threshold\", f\"{low_threshold}\",\n",
    "                \"--high-threshold\", f\"{high_threshold}\",\n",
    "                \"--solver\", f\"{solver}\",\n",
    "                \"--output-filetypes\", f\"{output_filetypes}\"\n",
    "            ]\n",
    "        )\n",
    "        !{cmd}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MEMOTE Reports\n",
    "> NOTE: This step is entirely optional\n",
    "\n",
    "MEMOTE is an open-source tool to automate the testing and reporting of metabolic models. This report is a detailed summary of the tests performed by MEMOTE on a given metabolic model (i.e., the one you just generated), along with the results and recommendations for improving the model. In order to create these reports, a metabolic \"map\" is required. Several of these are included in COMO, found under `data/maps/RECON1`. If you would like to add your own maps, they can be included in multiple places:\n",
    "1. If you have mapped a `local_files` directory to the container before starting, you can simply copy-and-paste them into the `local_files/maps` directory using the file browser of your computer. This is the most robust solution because the files will not be deleted by the container after it stops, or if it is updated in the future\n",
    "2. You can upload them to the Jupyter notebook under the `data/maps` directory. The code block below will search for any `.json` files that are not already included in the `map_dict` dictionary\n",
    "\n",
    "configs.datadir,\n",
    "                \"results\",\n",
    "                context,\n",
    "                \"figures\",\n",
    "                f\"{key}_map_{context}_{algorithm}.html\"\n",
    "\n",
    "The resulting MEMOTE reports will be saved to `data/results/exampleTissue/figures/mapName_map_exampleTissue_ALGORITHM.html`.\n",
    "\n",
    "- `mapName`: This is the name of the map file. In the `map_dict` dictionary below, this value would be `trypto`, `retinol`, etc.\n",
    "- `exampleTissue`: This is the name of the tissue context\n",
    "- `ALGORITHM`: This is the algorithm (`recon_algorithm`) used in the above model creation step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from escher import Builder\n",
    "import cobra\n",
    "import os\n",
    "from pathlib import Path\n",
    "from project import configs\n",
    "\n",
    "user_map_dir = Path(f\"{configs.datadir}/local_files/maps/\")\n",
    "map_dict = {\n",
    "    \"trypto\": f\"{configs.datadir}/maps/RECON1/RECON1.tryptophan_metabolism.json\",\n",
    "    # \"lipid\": f\"{configs.datadir}/maps/RECON1/RECON1.\",  # Not present in COMO by default yet\n",
    "    \"retinol\": f\"{configs.datadir}/maps/RECON1/RECON1.inositol_retinol_metabolism.json\",\n",
    "    \"glyco\": f\"{configs.datadir}/maps/RECON1/RECON1.glycolysis_TCA_PPP.json\",\n",
    "    \"combined\": f\"{configs.datadir}/maps/RECON1/RECON1.combined.json\",\n",
    "    \"carbo\": f\"{configs.datadir}/maps/RECON1/RECON1.carbohydrate_metabolism.json\",\n",
    "    \"amino\": f\"{configs.datadir}/maps/RECON1/RECON1.amino_acid_partial_metabolism.json\"\n",
    "}\n",
    "\n",
    "# Collect files from user-input json maps\n",
    "index = 1\n",
    "for file in user_map_dir.glob(\"**/*.json\"):\n",
    "    map_dict[file.stem] = file\n",
    "    index += 1\n",
    "\n",
    "# Collect any additional maps under the `{configs.datadir}/maps/` directory\n",
    "for file in Path(f\"{configs.datadir}/maps\").glob(\"**/*.json\"):\n",
    "    if file not in map_dict.values():\n",
    "        map_dict[file.stem] = file\n",
    "\n",
    "for recon_algorithm in recon_algorithms:\n",
    "    for context in context_gene_exp.keys():\n",
    "    # for context in [\"naiveB\", \"smB\"]:\n",
    "        print(f\"Starting {context}\")\n",
    "        model_json=os.path.join(configs.datadir,\n",
    "                                \"results\",\n",
    "                                context,\n",
    "                                f\"{context}_SpecificModel_{recon_algorithm}.json\")\n",
    "\n",
    "        model = cobra.io.load_json_model(model_json)\n",
    "        for key in map_dict.keys():\n",
    "            print(f\"Running with: {key}\")\n",
    "            builder = Builder(map_json=str(map_dict[key]))\n",
    "            builder.model = model\n",
    "            solution = cobra.flux_analysis.pfba(model)\n",
    "            builder.reaction_data  = solution.fluxes\n",
    "            builder.reaction_scale = [\n",
    "                { \"type\": \"min\", \"color\": \"#ff3300\", \"size\": 12 },\n",
    "                { \"type\": \"q1\", \"color\": \"#ffc61a\", \"size\": 14 },\n",
    "                { \"type\": \"median\", \"color\": \"#ffe700\", \"size\": 16 },\n",
    "                { \"type\": \"q3\", \"color\": \"#4ffd3c\", \"size\": 18 },\n",
    "                { \"type\": \"max\", \"color\": \"#3399ff\", \"size\": 20 }\n",
    "            ]\n",
    "            builder.reaction_no_data_color = \"#8e8e8e\"\n",
    "\n",
    "            builder.save_html(\n",
    "                os.path.join(\n",
    "                    configs.datadir,\n",
    "                    \"results\",\n",
    "                    context,\n",
    "                    \"figures\",\n",
    "                    f\"{key}_map_{context}_{recon_algorithm}.html\"\n",
    "                )\n",
    "            )\n",
    "\n",
    "        out_dir = os.path.join(configs.datadir, \"results\", context)\n",
    "        # for algorithm in [\"GIMME\", \"IMAT\", \"FASTCORE\", \"tINIT\"]:\n",
    "        report_file = os.path.join(out_dir, f\"memote_report_{context}_{recon_algorithm}.html\")\n",
    "        model_file = os.path.join(out_dir, f\"{context}_SpecificModel_{recon_algorithm}.xml\")\n",
    "        log_dir = os.path.join(out_dir, \"memote\")\n",
    "        log_file = os.path.join(log_dir, f\"{context}_{recon_algorithm}_memote.log\")\n",
    "\n",
    "        if not os.path.exists(log_dir):\n",
    "            os.mkdir(log_dir)\n",
    "\n",
    "        cmd = \" \".join(\n",
    "            [\n",
    "                \"memote\",\n",
    "                \"report\",\n",
    "                \"snapshot\",\n",
    "                \"--filename\",\n",
    "                f\"{report_file}\", f\"{model_file}\", \">\", f\"{log_file}\"\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        !{cmd}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Disease-related Gene Identification\n",
    "This step can identify disease related genes by analyzing patient transcriptomics' data\n",
    "\n",
    "In the `data/config_sheets` folder, create another folder called `disease`. Add an Excel file for each tissue/cell type called `disease_data_inputs_<TISSUE_NAME>`, where `<TISSUE_NAME>` is the name of the tissue you are interested in. Each sheet of this file should correspond to a separate disease to analyze using differential gene analysis. The source data can be either microarray or bulk RNA sequencing; the file is formatted in the same fashion as described in the [final part of Step 1](#Importing-a-Pre-Generated-Counts-Matrix). The sheet names should be in the following format: `<DISEASE_NAME>_<MICROARRAY | BULK>`\n",
    "- `<DISEASE_NAME>`: This is the name of the disease you are analyzing.\n",
    "- `<MICROARRAY | BULK>`: This should be \"microarray\" or \"bulk\", literally. It will match what method was used to create the data.\n",
    "\n",
    "For example, if the disease we are interested in is lupus, and the source of the data is bulk RNA sequencing, the name of the first sheet would be `lupus_bulk`. If you are using bulk RNA sequencing, there should be a gene counts matrix file located at `data/data_matrices/<tissue_name>/<disease>` called `BulkRNAseqDataMatrix<DISEASE_NAME>_<TISSUE_NAME>`\n",
    "\n",
    "## Parameters\n",
    "- `disease_names`: The diseases you are using. This should match the first section of the sheet name in the Excel file\n",
    "- `data_source`: The datasource you are using for disease analysis. This should be `\"microarray\"` or `\"rnaseq\"`\n",
    "- `taxon_id`: The [NCBI Taxon ID](https://www.ncbi.nlm.nih.gov/taxonomy) to use for disease analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_names = [\"arthritis\", \"lupus_a\", \"lupus_b\"]\n",
    "data_source = \"rnaseq\"\n",
    "taxon_id = \"human\"\n",
    "\n",
    "for context_name in context_names:\n",
    "    disease_config_file = f\"disease_data_inputs_{context_name}.xlsx\"\n",
    "    cmd = \" \".join(\n",
    "        [\n",
    "            \"python3\", \"py/disease_analysis.py\",\n",
    "            \"--context-name\", f\"{context_name}\",\n",
    "            \"--config-file\", f\"{disease_config_file}\",\n",
    "            \"--data-source\", f\"{data_source}\",\n",
    "            \"--taxon-id\", f\"{taxon_id}\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    !{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Drug Target & Repurposable Drug Identification\n",
    "This step performs a series of tasks:\n",
    "1. Map drug targets in metabolic models\n",
    "2. Performs knock out simulations\n",
    "3. Compares simulation results with \"disease genes\"\n",
    "4. Identifies drug targets and repurposable drugs\n",
    "\n",
    "## Execution Steps\n",
    "### Drug Database\n",
    "A processed drug-target file is included in the `data` folder, called `Repurposing_Hub_export.txt`. If you would like to include an additional drug-target file, please model your own file after the included one. Alternatively, if you would like to update to a newer version of the database, simply export from the [Drug Repurposing Hub](https://clue.io/repurposing-app). If you do this, remove all `activators`, `agonists`, and `withdrawn` drugs. Replace the `data/Repurposing_Hub_export.txt` file.\n",
    "\n",
    "### Using Automatically Created Models\n",
    "This step will use the models generated in Step 4, above. It is **highly** recommended to use refined and validated models for further analysis (i.e., before running this step of the pipeline). If you would like to use a custom model, instead of the one created by COMO, edit the `model_files` dictionary. An example is shown here:\n",
    "```python\n",
    "model_files = {\n",
    "   \"exampleTissueModel\": \"/home/jovyan/main/data/myModels/exampleTissueModel.mat\",\n",
    "   \"anotherTissueModel\": \"/home/jovyan/main/data/myModels/anotherTissueModel.json\",\n",
    "   \"thirdTissueModel\": \"/home/jovyan/main/data/myModels/thirdTissueModel.xml\"\n",
    "}\n",
    "```\n",
    "\n",
    "❗The path `/home/jovyan/main/` **<ins>MUST</ins>** stay the same. If it does not, your model **will not be found**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knock out simulation for the analyzed tissues and diseases\n",
    "model_files = {\n",
    "    # \"context_name\": \"/path/to/model.mat\"\n",
    "    # EXAMPLE -> \"Treg\": \"/home/jovyan/main/data/results/naiveB/naiveB_SpecificModel_IMAT.mat\"\n",
    "}\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "drug_raw_file = \"Repurposing_Hub_export.txt\"\n",
    "for context in context_names:\n",
    "    for recon_algorithm in recon_algorithms:\n",
    "        for disease in disease_names:\n",
    "\n",
    "            disease_path = os.path.join(configs.datadir, \"results\", context, disease)\n",
    "            out_dir = os.path.join(configs.datadir, \"results\", context, disease)\n",
    "            tissue_gene_folder = os.path.join(configs.datadir, context)\n",
    "            os.makedirs(tissue_gene_folder, exist_ok=True)\n",
    "\n",
    "            if not os.path.exists(disease_path):\n",
    "                print(f\"Disease path doesn't exist! Looking for {disease_path}\")\n",
    "                continue\n",
    "\n",
    "            # load the results of step 3 to dictionary \"disease_files\"\n",
    "            step3_results_file = os.path.join(\n",
    "                configs.datadir,\n",
    "                \"results\",\n",
    "                context,\n",
    "                disease,\n",
    "                \"step2_results_files.json\"\n",
    "            )\n",
    "\n",
    "            with open(step3_results_file) as json_file:\n",
    "                disease_files = json.load(json_file)\n",
    "                down_regulated_disease_genes = disease_files[\"down_regulated\"]\n",
    "                up_regulated_disease_genes = disease_files[\"up_regulated\"]\n",
    "\n",
    "            if context in model_files.keys():\n",
    "                tissueSpecificModelfile = model_files[context]\n",
    "            else:\n",
    "                tissueSpecificModelfile  = os.path.join(\n",
    "                    configs.datadir,\n",
    "                    \"results\",\n",
    "                    context,\n",
    "                    f\"{context}_SpecificModel_{recon_algorithm}.mat\"\n",
    "                )\n",
    "\n",
    "            cmd = \" \".join(\n",
    "                [\n",
    "                    \"python3\" , \"py/knock_out_simulation.py\",\n",
    "                    \"--context-model\", f\"{tissueSpecificModelfile}\",\n",
    "                    \"--context-name\", f\"{context}\",\n",
    "                    \"--disease-name\", f\"{disease}\",\n",
    "                    \"--disease-up\", f\"{up_regulated_disease_genes}\",\n",
    "                    \"--disease-down\", f\"{down_regulated_disease_genes}\",\n",
    "                    \"--raw-drug-file\", f\"{drug_raw_file}\",\n",
    "                    #\"--test-all\"\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            if recon_algorithm == \"IMAT\":\n",
    "                cmd.extend(\n",
    "                    [\n",
    "                        \"--reference-flux-file\",\n",
    "                        os.path.join(configs.datadir, \"results\", context, \"IMAT_flux.csv\")\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "            !{cmd}\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
