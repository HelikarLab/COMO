{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MADRID - MetAbolic Drug Repurposing and IDentification** \n",
    "\n",
    "## **Who should use this pipeline?**\n",
    "\n",
    "This Jupyterlab pipeline has everything necessary to build a context-specific constraint-based metabolic model (CBMM) from any single source or combination of sources from the following '-omics' data.\n",
    "- Bulk RNA-seq\n",
    "- Single-cell RNA-seq\n",
    "- Proteomics (specific name???)\n",
    "- Microarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It also serves as a platform to use these models to identify drug targets and potentially repurposable drugs for metabolism-impacting diseases.\n",
    "\n",
    "MADRID does not require any amount of programming experience to create models. However every step of the pipeline is packaged in its own .py file to promote accessible modification, addition, or replacement of analysis steps. The Jupyterlab container comes pre-loaded with the most popular R and Python libraries, however, if you would like to use a library and cannot install it for any reason, please request it on our Github page!<br>\n",
    "https://github.com/HelikarLab/MADRID\n",
    "\n",
    "In this pipeline, **the term \"context\" refers to a specific state that can be subset from a genome-scale metabolic model using experimental data.** This context can be a specific type of cell, or tissue in a specific experimental state such as a control or a disease. For drug perturbation scoring of a specific cell-type or tissue, **it is only necessary to build a CBMM (Steps 1-5) for the healthy control state.** Differential gene expression (Step 6) will be used to for disease analysis so that multiple diseaes can be analyzed using the same CBMM.\n",
    "\n",
    "***Warning! If you terminate your session after running the Docker, any changes you make WILL NOT BE SAVED! Please mount a local directory to the Docker image as instructed on the Github and Dockerhub README's to prevent data loss.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "\n",
    "## **Before You Start**\n",
    "\n",
    "### **Before running, you must provide the proper files depending on the types of data you will use for model creation.**\n",
    "- For RNA-seq: Either a correctly formatted folder named \"MADRID_input\" in the the data directory. Proper inputs can be generated using our Snakemake pipeline specifically designed for MADRID: https://github.com/HelikarLab/FastqToGeneCounts.  RNA-seq data can either be single-cell or bulk, but our Snakemake pipeline provided is for bulk only at the time. If processing RNA-seq data with an alternative procedure, or importing a pre-made gene count matrix, follow the instructions in Step 1.\n",
    "\n",
    "- For proteomics. A matrix of measurement ****NEED TO DISCUSS WITH BHANWAR WHAT THESE VAULES MEAN***** where rows are proteins in Entrez format and columns are arbitrary sample names.\n",
    "\n",
    "- For microarray, results must be uploaded to Gene Expression Omnibus, the only thing to provide in MADRID is a configuration file with GSE, GSM, and GPL codes. microarray_data_inputs.xlsx shows a template to use. Note that microarray has become obsolete and it is recomended to use RNA-seq if possible.\n",
    "\n",
    "### **Six steps to identifying drug targets, stop after step 3 if building a context-specific model for other purposes**\n",
    "        \n",
    "1. Preprocess Bulk RNAseq data by converting STAR outputed gene counts files into a unified matrix, fetch necessary info about each gene required for normalization, and generate a configuration sheet.\n",
    "\n",
    "2. Analyze any combination of microarray, RNAseq (total, polyA, single-cell), and proteomics data, output a list of active genes for each strategy.\n",
    "\n",
    "3. Check for consensus amongst strategies according to desired rigor and merge into a singular set of active genes\n",
    "\n",
    "4. Create tissue specific models based on the list of active genes. If required the user can manually refine these models and supply them in Step 4. \n",
    "\n",
    "5. Identify differential gene expressions from disease datasets using either microarray or bulk RNAseq transcriptomics information.\n",
    "\n",
    "6. Identify drug targets and repruposable drugs. This step consists of four substeps. \n",
    "    - mapping drugs on automatically created or user-supplied models\n",
    "    - knock-out simulation\n",
    "    - compare simulation results of perturbed and unperturbed models\n",
    "    - integrate with disease genes and score drug targets.\n",
    "\n",
    "### **Configuration sheet information**\n",
    "The user should upload config .xlsx files to `/work/data/config_sheets`. The sheet names in these config files should correspond to the context (tissue name, cell name, control, etc.) where each sheet contains the sample names to include in that context-specifc model. These sample names should correspond to the sample (column) names in the source data matrix which should be uploaded (or outputed) in `/work/data/data_matrices/<model name>/`\n",
    "    \n",
    "In the original Docker image, some exemplary input files are included to build metabolic models of naive, Th1, Th2, and Th17 subtypes and identify drug targets for rheumatoid arthritis. User can follow the documentation and the format of the exemplary input files and and use the provided template files to create your own input files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Step 1: Initialize and Preprocess RNA-seq data**\n",
    "**(Skip if not using RNA-seq)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNA-seq data is read by MADRID as count matrix where each column is a different sample/replicate named 'exampleTissueName_SXRYrZ' where:\n",
    "- X is the study (or batch) number\n",
    "- Y is the replicate number\n",
    "- Z is the run number. If the replicate does not contain multiple runs for a single replicate, then \"rZ\" should be neglected.\n",
    "- exampleTissueName is the name of the model that will be built from this data. It should be consistant with other data sources if they are to be integrated. **Note that this identifier should not have any special characters including \"\\_\" since it may interfere with parsing.**\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replicates should come from the same study/batch group and different study/batch numbers can come from different published studies (or batches) as long as the tissue/cell was under similar enough conditions for your modeling purpose. Run numbers in the same replicate will be summed together.\n",
    "<br>\n",
    "<br>\n",
    "#### **Example:**\n",
    "Say S1 represents a study or batch, and S2 represents a different study or batch of RNA-seq data from m0 macrophages whose model we will name m0Macro. The studies were conducted in a different lab, by different researchers at different times using a different library preparation kit. In each study there are two replicates (R1, and R2) obtained for each one. m0Macro_S1R1 and m0Macro_S1R2 will be checked for consensus to generate a list of active genes in both replicates. These active genes will then be checked for consensus with the consensus of m0Macro_S2R1 and m0Macro_S2R2 to output a list of active genes in both studies.\n",
    "<br><br>\n",
    "The reason this system is used is not only to help keep you and MADRID organized. Most types of normalized gene counts are not good for direct comparisons across replicates, and are especially not suitable for comparisons across different experiments. Therefore, MADRID will convert normalized gene counts into a boolean list of active genes. These lists will be compared at the the level of replicates in a batch (or study) and then again at the level of all provided batches (or study). Finally, the active genes will be merged with the outputs of proteomics, microarray and differnt RNA-seq stategies if provided. The rigor used at each level can be easily modified by the user.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Two ways to initialize RNA-seq data**\n",
    "\n",
    "1. Import a properly formatted `MADRID_inputs` folder in the `data` directory. \n",
    "<br>\n",
    "\n",
    "> **It is recommended that you use our Snakemake pipeline to align and create a properly formated MADRID_inputs folder.** The pipeline also runs a series of important quality control methods to help determine if any of the provided samples are not suitable for model creation. This pipeline can be found at https://github.com/HelikarLab/FastqToGeneCounts.\n",
    "\n",
    "> Or, **if using your own alignment protocol**, follow this guide to create a `MADRID_inputs` folder.\n",
    "\n",
    "> - The top level of the directory has seperate tissues/cells to create seperate models from. The next level must have a folder called `geneCounts` and optionally a `strandedness` folder. If using zFPKM normalization, there should also be two more folders called `layouts` and `fragmentSizes`. Inside each of these folders should be folders named SX (wherer X is an arbitrary user-defined number that replicates are associated with. \n",
    "<br>    \n",
    "\n",
    "> - Inside these study number folders of `geneCounts` should be outputs of STAR aligner with using --quantMode GeneCounts. To help MADRID (and you!) stay organized, these outputs should be renamed `exampleTissueName_SXRYrZ.tab` where X is the study (or batch) number, Y is the replicate number, and Z is the run number. If the replicate does not contain multiple runs the rZ should be neglected. Replicates should come from the same study/sample group and different samples can come from different published studies (or batches) as long as the tissue/cell was under similar enough conditions for your modeling purpose.\n",
    "<br>\n",
    "\n",
    "> - Inside the study number folders of `strandedness` should be files named `exampleTissue_SXRYrZ_strandedness.txt`. These files must tell the strandedness of the the RNA-seq method used, and must contain one of the following text (and nothing else):\n",
    ">> * NONE\n",
    ">> * FIRST_READ_TRANSCRIPTION_STRAND\n",
    ">> * SECOND_READ_TRANSCRIPTION_STRAND\n",
    "<br>\n",
    "\n",
    "> - Inside the study number folders of `layouts` should be files named `exampleTissue_SXRYrZ_layout.txt` where each file tells the layout of the library used, and must contain one of the following text (and nothing else):\n",
    ">> * paired-end\n",
    ">> * single-end\n",
    "<br>\n",
    "\n",
    "> - Inside the study number folders of `fragmentSizes` should be files named `exampleTissue_SXRYrZ_fragment_sizes.txt` and contain the output of RSeQC's RNA_fragment_size.py function.\n",
    "\n",
    "> - Inside the study number folders of `prepMethods` should be files named `exampleTissue_SXRYrZ_prep_method.txt` where each file tells the library preparation strategy, which must be one of the following.\n",
    ">> * total\n",
    ">> * mRNA\n",
    "<br><br>\n",
    "where 'total' refers to Total RNA and mRNA refers to polyA enriched RNA. Note that these strategies serve only to differentiate the methods in the event that both are used to build a model. If a different library strategy is desired, you can use either one as a placeholder, or will very little Python knowledge, it is easy add a new strategy to `merge_xomics.py`.  \n",
    "\n",
    "2. Import a properly formatted counts matrix in `/work/data/data_matrices/exampleTissue/gene_counts_matrix_exampleTissue.csv` where the rows are name exampleTissue_SXRY (note the lack of run number since runs should be summed into a single set of counts). **If providing the count matrix this way, instead of generating one using method 1, you will also have to create a configuration file** that has each sample's name, study/batch number, and if using zFPKM, layout and mean fragment length. **Use the provided template** to help. Once provided, run rnaseq_preprocess.py with the '--provide-matrix' argument. <br><br> ***This method is best if you are downloading a premade count matrix, or using single-cell data that has already been batch corrected, clustered, and sorted into only the cell type of interest!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, MADRID can filter raw RNA-seq counts using three normalization techniques.\n",
    "\n",
    "> - TPM Quantile, where each replicate is normalized with Transcripts-per-million and an upper quantile is taken to create a boolean list of active genes for the replicate. Replicates are compared for consensus within the study/batch number according to user-defined ratios and then study/batch numbers are checked for consensus according to different user defined ratios. **Recomended if user wants more control over the size of the model, like a smaller model that allows for only the most expressed reactions, or a larger more encompassing one that contains less essential reactions.\n",
    "\n",
    "> - zFPKM method outlined in: https://pubmed.ncbi.nlm.nih.gov/24215113/ can be used. Counts will be normalized using zFPKM and genes > -3 will be considered expressed per thier recommendation. Expressed genes will be checked for consensus at the replicate and study/batch levels the same as TPM Quantile. **Recommended if user wants to give least input over gene essentially determination and use the most standardized method of active gene determination. \n",
    "\n",
    "> - flat cutoff of CPM (counts per million) normalized values, check for consensus the same as other methods. **Not recommended**\n",
    "\n",
    "Regardless of normalization technique used, or provided files used for RNA-seq, preprocessing is required to fetch relevent gene information needed for harmonization and normalization such as Entrez ID, and the start and end postions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import necessary python packages\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from subprocess import call\n",
    "from project import configs\n",
    "import bioservices\n",
    "import pprint\n",
    "import troppo"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 1: Preprocess RNAseq data by generating a counts matrix, config sheet, and gene file from MADRID_inputs.\n",
    "\n",
    "# tissue name or list of tissue names within a string\n",
    "context_names = \"naiveB smB\"\n",
    "create_counts_matrix = True  # set to false if using a pregenerated matrix file\n",
    "gene_format = \"Ensembl\"      # accepts 'Entrez', 'Ensembl', and 'Symbol'\n",
    "taxon_id = \"human\"           # accepts integer (bioDBnet taxon id) or 'human' or 'mouse'\n",
    "preprocess_mode = \"create-matrix\" # \"create-matrix\" or \"provide-matrix\"\n",
    "\n",
    "cmd = ' '.join(\n",
    "    [\n",
    "        'python3', 'rnaseq_preprocess.py',\n",
    "        '--context-names', f'\"{context_names}\"',\n",
    "        '--gene-format', f'\"{gene_format}\"',\n",
    "        '--taxon-id', f'\"{taxon_id}\"',\n",
    "        f'--{preprocess_mode}'\n",
    "    ]\n",
    ")\n",
    "\n",
    "!{cmd}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 2: Identifying Gene Activity in Transcriptomics and Proteomics Datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Identify gene activity in the following data sources \n",
    " - RNA-seq (bulk or single-cell)\n",
    " - Proteomics\n",
    " - Microarray\n",
    "\n",
    " Only one sources is required for model generation, multiple can be helpful for additional validation if of high-quality. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Microarrays"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From wikipedia: A microarray is a multiplex lab-on-a-chip. Its purpose is to simultaneously detect the expression of thousands of genes from a sample (e.g. from a tissue). It is a two-dimensional array on a solid substrate—usually a glass slide or silicon thin-film cell—that assays (tests) large amounts of biological material using high-throughput screening miniaturized, multiplexed and parallel processing and detection methods.\n",
    "\n",
    "MADRID can directly download and analyze microarray data from GEO for Agilent and Affymetrix platoforms. Follow the template and example in `/work/data/config_sheets/` to use microarray data in your analysis.\n",
    "\n",
    "Microarray technology is becoming increasingly obsolete, if possible it is recommended that you use RNA-seq instead. Although different strategies exist for microarrays, MADRID does not distinguish between them nor are  there any plans to in the future due to it's obsoelecense."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **RNA-seq Analysis**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "RNA-seq analysis has two primary types, bulk tissue, and single-cell. Bulk RNA-seq also has multiple strategies of library preparation. If using public data, the user may run into a situation where they wish to use a combination of bulk RNA-seq data produced using two very different library preparation strategies. \n",
    "  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **Bulk RNA-seq**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "MADRID currently supports the two most common strategies, mRNA (polyA) enriched RNA-seq, and total RNA-seq. \n",
    "\n",
    "Because of expected differences in distribution of transcripts, MADRID is written to handle each strategy seperately before the integration step. The recommended Snakemake alignment pipeline is designed to work with MADRID's preprocessing step (Step 1) to split RNA-seq data from GEO into seperate input matrices and config sheets.\n",
    "\n",
    "**To create a gene expression file for total RNA-seq data, use the \"total\" for the '--library-prep' argument**\n",
    "\n",
    "**To create a gene expression file for mRNA enriched / polA RNA-seq data, use the \"mRNA\" for the '--library-prep' argument.**\n",
    "\n",
    "The analysis of each strategy is identical so specifying the type only serves to ensure MADRID analyzes them seperately."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### **Single-cell RNA-seq**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "While the Snakemake pipeline does not yet support single-cell alignment and MADRID does not yet support automated configuration file and counts-matrix file creation for single-cell alignment output from STAR, it is possible to use single-cell data to create a model with MADRID. \n",
    "\n",
    "Since normalization strategies can be applied to single-cell the same way it is applied to bulk, rnaseq_gen.py can be used with a provided counts matrix and config sheet (see Step 1 to help create it). \n",
    "\n",
    "Just like 'total' and 'mRNA', rnaseq_gen.py can be run with \"SC\" as the '--library-prep' argument to help MADRID differentiate it from the bulk RNA-seq data if using multiple strategies.   "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# step 2.2 RNA-seq Analysis for Total RNA-seq library preparation\n",
    "\n",
    "# config for total rna-seq\n",
    "trnaseq_config_file = 'trnaseq_data_inputs_auto.xlsx'\n",
    "\n",
    "rep_ratio = 0.75         # proportion of replicates for a gene to be active in a sample\n",
    "group_ratio = 0.75       # proportion of samples with expression required for gene\n",
    "rep_ratio_h = 1.0        # proportion of replicates with expression required for high-confidence\n",
    "group_ratio_h = 1.0      # proportion of replicates with expression required for high-confidence\n",
    "technique = \"zFPKM\"      # quantile, cpm, or zfpkm\n",
    "quantile = 50            # cutoff TPM quantile for quantile filtering\n",
    "min_zfpkm = -3           # cutoff for CPM filtering\n",
    "prep_method = \"total\"    # library prepartion method ('total', mRNA', or 'SC')\n",
    "\n",
    "cmd = ' '.join(\n",
    "    [\n",
    "        'python3', 'rnaseq_gen.py',\n",
    "        '--config-file', f'\"{trnaseq_config_file}\"',\n",
    "        '--replicate-ratio', f'\"{rep_ratio}\"',\n",
    "        '--batch-ratio', f'\"{group_ratio}\"',\n",
    "        '--high-replicate-ratio', f'\"{rep_ratio_h}\"',\n",
    "        '--high-batch-ratio', f'\"{group_ratio_h}\"',\n",
    "        '--filt-technique', f'\"{technique}\"',\n",
    "        '--min-zfpkm', f'\"{min_zfpkm}\"',\n",
    "        '--library-prep', f'\"{prep_method}\"'\n",
    "    ]\n",
    ")\n",
    "\n",
    "!{cmd}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    " # step 2.3 mRNA capture (polyA) RNA-seq Analysis\n",
    "\n",
    "# config for mRNA (polyA) enriched RNA-seq\n",
    "mrnaseq_config_file = 'mrnaseq_data_inputs_auto.xlsx'\n",
    "\n",
    "rep_ratio = 0.75         # proportion of replicates for a gene to be active in a sample\n",
    "group_ratio = 0.75       # proportion of samples with expression required for gene  \n",
    "rep_ratio_h = 1.0        # proportion of replicates with expression required for high-confidence\n",
    "group_ratio_h = 1.0      # proportion of replicates with expression required for high-confidence\n",
    "technique = \"zfpkm\"      # quantile-tpm, cpm, or zfpkm\n",
    "min_zfpkm = -3           # cutoff for CPM for filtering\n",
    "prep_method = \"mrna\"     # library preparation method\n",
    "\n",
    "cmd = ' '.join(\n",
    "    [\n",
    "        'python3', 'rnaseq_gen.py',\n",
    "        '--config-file', f'\"{mrnaseq_config_file}\"',\n",
    "        '--replicate-ratio', f'\"{rep_ratio}\"',\n",
    "        '--batch-ratio', f'\"{group_ratio}\"',\n",
    "        '--high-replicate-ratio', f'\"{rep_ratio_h}\"',\n",
    "        '--high-batch-ratio', f'\"{group_ratio_h}\"',\n",
    "        '--filt-technique', f'\"{technique}\"',\n",
    "        '--min-zfpkm', f'\"{min_zfpkm}\"',\n",
    "        '--quantile', f'\"{quantile}\"',\n",
    "        '--library-prep', f'\"{prep_method}\"'\n",
    "    ]\n",
    ")\n",
    "                \n",
    "!{cmd}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 2.5 Proteomics Analysis\n",
    "\n",
    "# config file for proteomics\n",
    "proteomics_config_file = 'proteomics_data_inputs_paper.xlsx'\n",
    "\n",
    "# ratio of replicates required for a gene to be considered active in that sampler\n",
    "rep_ratio = 0.75\n",
    "batch_ratio = 0.75\n",
    "\n",
    "# Genes can be considered high confidence if they are expressed in a high proportion of samples.\n",
    "# High confidence genes will be considered expressed regardless of agreement with other data sources\n",
    "high_rep_ratio = 1.0\n",
    "high_batch_ratio = 1.0\n",
    "quantile = 25\n",
    "\n",
    "cmd = ' '.join(\n",
    "    [\n",
    "        'python3', 'proteomics_gen.py',\n",
    "        '--config-file', f'\"{proteomics_config_file}\"',\n",
    "        '--replicate-ratio', f'\"{rep_ratio}\"',\n",
    "        '--high-replicate-ratio', f'\"{high_rep_ratio}\"',\n",
    "        '--batch-ratio', f'\"{batch_ratio}\"',\n",
    "        '--high-batch-ratio', f'\"{high_batch_ratio}\"',\n",
    "        '--quantile', f'\"{quantile}\"'\n",
    "    ]\n",
    ")\n",
    "\n",
    "!{cmd}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 3: Merge Expression from Different Data Sources"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "So far, active genes have been determined for at least one data source. If using multiple sources of any combination of microarray, bulk RNA-seq of either total RNA or mRNA capture (polyA), proteomics, or single-cell RNA-seq. Now we can merge the active genes from each data source to make a list of active genes that is more comprehenisve or more strict than any individual list. \n",
    "\n",
    "`merge_xomics.py` takes each data source discussed so far as an argument, and it is easy to add new ones to the script if desired. The other arguments to consider are:\n",
    "- **--expression-requirement** which is the number of data souces with expression required for a gene to be considered active if not a high-confidence gene for any source (defaults to the total number of input data sources arguments provided)\n",
    "\n",
    "- **--requirement-adjust** is the method to adjust this requirement in the event that tissues have different numbers of provided data sources. (*Note that this does nothing if there is only one tissue type in the config files). \n",
    "\n",
    "> - \"progressive\" - expression requirement applies to tissue(s) with lowest number of data source types. Tissues with more will require 1 more source to have an active gene per additional source provided for the gene to be active in the model.\n",
    "        \n",
    "> - \"regressive\" - expression requirement applies to the tissue(s) with largest number of data source types. Tissues with less will require 1 less source to have an active gene per missing source for the gene to be active in the model\n",
    "                    \n",
    "> - \"flat\" - (default) expression requirement is used regardless of differences in number of data sources provided for different tissues\n",
    "\n",
    "> - \"custom\" - (Not yet implemented!) an .xlsx file where column one is the tissue type, and column two is the expression requirement. Requires additional argument '--requirements-file' whose value is the filename of this .xlsx file in `/work/data/`\n",
    "                          \n",
    "- **--no-hc** use this flag to prevent high-confidence gene from overiding expression_requirement\n",
    "\n",
    "- **--no-na-adjustment** use this flag to prevent genes that are not a present in one data source, but are present in others from subtracting one from the expression requirement.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If the '--no-hc' flag is not used, any gene that was determined to be high-confidence in any input data source will cause the gene to be active in the final model, regardless of agreement with other sources.**\n",
    "<br />\n",
    "\n",
    "If the '--no-na-adjustment' flag is not used, any time a gene is NA in a data source, meaning it was not tested for in the library of that data source, but was tested in the library of at least one other, it will subtract one from the expression requirement.\n",
    "\n",
    "***Adjusted expression requirement will never resolve to be < 1 or > the number of data sources that tissue is given**"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Step 2.4 Merge the gene lists of data sources, create a list of active gene IDs\n",
    "trnaseq_config_file = \"trnaseq_data_inputs_auto.xlsx\"\n",
    "mrnaseq_config_file = \"mrnaseq_data_inputs_auto.xlsx\"\n",
    "proteomics_config_file = \"proteomics_data_inputs_paper.xlsx\"\n",
    "\n",
    "expression_requirement = 3\n",
    "        \n",
    "requirement_adjust = \"regressive\" \n",
    "tweight = 6\n",
    "mweight = 6\n",
    "scweight = 6\n",
    "pweight = 10\n",
    "\n",
    "\n",
    "cmd = ' '.join(\n",
    "    [\n",
    "        'python3', 'merge_xomics.py',\n",
    "        '--merge-distribution',\n",
    "        #'--microarray-config-file', f'\"{microarray_config_file}\"',  # If using micro-array, uncomment the start of this line\n",
    "        '--total-rnaseq-config-file', f'\"{trnaseq_config_file}\"',\n",
    "        '--mrnaseq-config-file', f'\"{mrnaseq_config_file}\"',\n",
    "        #'--scrnaseq-config-file', f'\"{scrnaseq_config_file}\"',      # If using single-cell data, uncomment the start of this line\n",
    "        '--proteomics-config-file', f'\"{proteomics_config_file}\"',\n",
    "        '--expression-requirement', f'\"{expression_requirement}\"',\n",
    "        '--requirement-adjust', f'\"{requirement_adjust}\"',\n",
    "        '--total-rnaseq-weight', f'\"{tweight}\"',\n",
    "        '--mrnaseq-weight', f'\"{mweight}\"',\n",
    "        #'--single-cell-rnaseq-weight', f'\"{scweight}\"',             # If using single-cell data, uncomment the start of this line\n",
    "        '--protein-weight', f'\"{pweight}\"',\n",
    "        '--no-hc'\n",
    "    ]\n",
    ")\n",
    "\n",
    "!{cmd}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 4: Create Tissue/Cell-Type Specific Models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the output of step 1, which is a dictionary that specifies the merged list of active Gene IDs for each tissue\n",
    "step1_results_file = os.path.join(configs.datadir, 'results', 'step1_results_files.json')\n",
    "with open(step1_results_file) as json_file:\n",
    "    context_gene_exp = json.load(json_file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create tissue specific model, the names of output files are stored in dictionary tissue_spec_model\n",
    "\n",
    "general_model_file = \"GeneralModelUpdatedV2.mat\"\n",
    "\n",
    "recon_algorithm = 'IMAT' # troppo reconstruction algorithm to use\n",
    "solver = \"GUROBI\"\n",
    "output_filetypes = \"xml mat json\"\n",
    "\n",
    "objective_dict = {\n",
    "    \"naiveB\": 'biomass_maintenance',\n",
    "    \"smB\": \"biomass_reaction\"\n",
    "}\n",
    "\n",
    "low_thresh = -5\n",
    "high_thresh = -3\n",
    "\n",
    "rev_dict = dict(reversed(context_gene_exp.items()))\n",
    "\n",
    "for key,value in rev_dict.items():\n",
    "\n",
    "    objective = objective_dict[key]\n",
    "    active_genes_file = re.split('/|\\\\\\\\', value)[-1]\n",
    "    genes_zscore_file = os.path.join(configs.datadir, \"results\", key, f\"model_scores_{key}.csv\")\n",
    "\n",
    "    if recon_algorithm.upper() in [\"IMAT\", \"TINIT\"]:\n",
    "        active_genes_filepath = os.path.join(configs.datadir, \"results\", key, genes_zscore_file)\n",
    "    else:\n",
    "        active_genes_filepath = os.path.join(configs.datadir, \"results\", key, active_genes_file)\n",
    "        \n",
    "    general_model_filepath = os.path.join(configs.datadir, general_model_file)\n",
    "    boundary_rxns_filepath = os.path.join(configs.datadir, \"boundary_rxns\", \"bcell_boundary_rxns.csv\")\n",
    "    force_rxns_filepath = os.path.join(configs.datadir, \"force_rxns\", \"bcell_force_rxns.csv\")\n",
    "\n",
    "    cmd = ' '.join(\n",
    "        [\n",
    "            'python3', 'create_context_specific_model.py',\n",
    "            '--context-name', f'\"{key}\"',\n",
    "            '--reference-model-file', f'\"{general_model_filepath}\"',\n",
    "            '--active-genes-filepath', f'\"{active_genes_filepath}\"',\n",
    "            '--objective', f'\"{objective}\"',\n",
    "            '--boundary-reactions-filepath', f'\"{boundary_rxns_filepath}\"',\n",
    "            #'--exclude-reactions-filepath', f'\"{exclude_rxns_file}\"',\n",
    "            '--force-reactions-filepath', f'\"{force_rxns_filepath}\"',\n",
    "            '--algorithm', f'\"{recon_algorithm}\"',\n",
    "            '--low-threshold', f'\"{low_thresh}\"',\n",
    "            '--high-threshold', f'\"{high_thresh}\"',\n",
    "            '--solver', f'\"{solver}\"',\n",
    "            '--output-filetypes', f'\"{output_filetypes}\"'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    !{cmd}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Optional: Generate Memote Reports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from escher import Builder\n",
    "import cobra\n",
    "import pandas as pd\n",
    "import os\n",
    "from project import configs\n",
    "\n",
    "map_dir = os.path.join(\n",
    "    configs.datadir,\n",
    "    \"local_files\",\n",
    "    \"maps\",\n",
    "    \"community-maps\",\n",
    "    \"RECON1\"\n",
    ")\n",
    "\n",
    "map_dict = {\n",
    "    \"trypto\": os.path.join(map_dir, \"RECON1.Tryptophan metabolism.json\"),\n",
    "    \"lipid\": os.path.join(map_dir, \"RECON1.LIPID_METABOLISM.json\"),\n",
    "    \"retinol\": os.path.join(map_dir, \"RECON1.Inositol retinol metabolism.json\"),\n",
    "    \"glyco\": os.path.join(map_dir, \"RECON1.Glycolysis_TCA_PPP.json\"),\n",
    "    \"combined\": os.path.join(map_dir, \"RECON1.COMBINED.json\"),\n",
    "    \"carbo\": os.path.join(map_dir, \"RECON1.CARBOHYDRATE_METABOLISM.json\"),\n",
    "    \"amino\": os.path.join(map_dir, \"RECON1.Amino acid metabolism (partial).json\")\n",
    "}\n",
    "\n",
    "\n",
    "for context in [\"naiveB\", \"smB\"]:\n",
    "    print(f\"Starting {context}\")\n",
    "    for algorithm in [\"IMAT\"]:\n",
    "        model_json=os.path.join(\n",
    "            configs.datadir,\n",
    "            \"results\",\n",
    "            context,\n",
    "            f\"{context}_SpecificModel_{algorithm}.json\"\n",
    "        )\n",
    "\n",
    "        model = cobra.io.load_json_model(model_json)\n",
    "        for key in map_dict.keys():\n",
    "            print(f\"Running with: {key}\")\n",
    "            builder = Builder(map_json=map_dict[key])\n",
    "            builder.model = model\n",
    "            solution = cobra.flux_analysis.pfba(model)\n",
    "            builder.reaction_data  = solution.fluxes\n",
    "            #print(builder.fluxes.fluxes)\n",
    "            #builder.fluxes = pd.read_csv(os.path.join(configs.datadir, \"results\", context, \"iMAT_flux.csv\"))[\"flux\"].tolist()\n",
    "            builder.reaction_scale = [\n",
    "                { 'type': 'min', 'color': '#ff3300', 'size': 12 },\n",
    "                { 'type': 'q1', 'color': '#ffc61a', 'size': 14 },\n",
    "                { 'type': 'median', 'color': '#ffe700', 'size': 16 },\n",
    "                { 'type': 'q3', 'color': '#4ffd3c', 'size': 18 },\n",
    "                { 'type': 'max', 'color': '#3399ff', 'size': 20 }\n",
    "            ]\n",
    "            #builder.highlight_missing = TrueYeah I am still working on them. Cannot figure out a way to make them not contain a huge number of reactions though\n",
    "\n",
    "            builder.reaction_no_data_color = \"#8e8e8e\"\n",
    "            builder.save_html(os.path.join(\n",
    "                configs.datadir,\n",
    "                \"results\",\n",
    "                context,\n",
    "                \"figures\",\n",
    "                f\"{key}_map_{context}_{algorithm}.html\"\n",
    "            ))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# generate memote reports for each  model\n",
    "import os\n",
    "\n",
    "for key,value in context_gene_exp.items():\n",
    "    out_dir = os.path.join(\n",
    "            configs.datadir, \n",
    "            \"results\",\n",
    "            key\n",
    "    )\n",
    "    for algo in [\"GIMME\", \"IMAT\", \"FASTCORE\"]:\n",
    "        report_file = os.path.join(out_dir, f\"memote_report_{key}_{algo}.html\")\n",
    "        model_file = os.path.join(out_dir, f\"{key}_SpecificModel_{algo}.xml\")\n",
    "        log_dir = os.path.join(out_dir, \"memote\")\n",
    "        log_file = os.path.join(log_dir, f\"{key}_{algo}_memote.log\")\n",
    "\n",
    "        if not os.path.exists(log_dir):\n",
    "            os.mkdir(log_dir)\n",
    "\n",
    "        cmd = ' '.join(\n",
    "            [\n",
    "                'memote',\n",
    "                'report',\n",
    "                'snapshot',\n",
    "                '--filename',\n",
    "                f'\"{report_file}\"', f'\"{model_file}\"', \">\", f'\"{log_file}\"'\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        !{cmd}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 5: Identifying disease related genes by analyzing transcriptomics data of patients\n",
    "Differential Expression Analysis\n",
    "\n",
    "In the config_sheets folder, there should be a folder called \"disease\". You can add a spreadsheet for each cell/tissue type called `disease_data_inputs_<tissue_name>`. Each sheet of this file should correspond to a seperate disease to analyze using DGE nfor that tissue. The source data can be either microarray or bulk RNA-seq and is formatted the same as if creating the base tissue model. The sheet names should contain the disease name, an underscore, and than either \"microarray\" or \"bulk\" depending on the source data. For example, if the disease is lupus, and the source data is bulk RNA-seq, the name of the sheet should be \"lupus_bulk\". This can be seen in the example sheet. If using bulk RNA-seq data, there should be a count matrix file in `/work/data/data_matrices/<tissue_name>/disease/` called `BulkRNAseqDataMatrix_<disease name>_<tissue name>`. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*** Specify input files for step 3 here ***"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# specify tissue names to perform a disease analysis on. The diseases to analyze should be\n",
    "# specified in `/work/data/config_sheets/disease/diease_data_inputs_<tissue name>`\n",
    "context_names = ['naiveB', 'smB']\n",
    "disease_names = ['arthritis', 'lupus_a', 'lupus_b']\n",
    "data_source = 'rnaseq'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Differential gene expression analysis\n",
    "taxon_id = \"human\"\n",
    "for context_name in context_names:\n",
    "    disease_config_file = f\"disease_data_inputs_{context_name}.xlsx\"\n",
    "    cmd = ' '.join(\n",
    "        [\n",
    "            'python3', 'disease_analysis.py',\n",
    "            '--context-name', f'\"{context_name}\"',\n",
    "            '--config-file', f'\"{disease_config_file}\"',\n",
    "            '--data-source', f'\"{data_source}\"',\n",
    "            '--taxon-id', f'\"{taxon_id}\"'\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    !{cmd}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Step 6: Identification of drug targets and repurposable drugs\n",
    "This step maps drug targets in metabolic models,prforms knock out simulation, and compare simulation results with disease genes and identifies drug targets and repurposable drugs\n",
    "\n",
    "*** Specify input files for step 4 here ***\n",
    "\n",
    "1. Instruction: A processed Drug-Target file is included in the `/root/pipelines/data/`. (Optional step) For the updated versions the users can download `Repurposing_Hub_export.txt` from [Drug Repurposing Hub](https://clue.io/repurposing-app). From the downloaded file first remove all the activators, agonists, and withdrawn drugs and then upload to to `/root/pipelines/data/`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "2. To use automatically created tissue specific models. Note: It is recommended to use refined and validated models for further analysis. User can define cutomized models in next sub-step."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "3. To use customized model, please specify `tissue_spec_model` manually, e.g. uncomment tissue_spec_model in the following cell."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Knock out simulation for the analyzed tissues and diseases\n",
    "\n",
    "# Define custom models to use in drug repurposing\n",
    "# \"context_name\" should match one of context_names from Step 5\n",
    "# Right-click the model name in the file viewer (on the left), and select \"copy path\"\n",
    "# Make sure a leading \"/\" is present at the beginning of the file path\n",
    "model_files = {\n",
    "    # \"context_name\": \"/path/to/model.mat\"\n",
    "    # EXAMPLE -> \"Treg\": \"/home/jovyan/work/data/results/naiveB/naiveB_SpecificModel_IMAT.mat\"\n",
    "}\n",
    "\n",
    "diseases = [\"arthritis\", \"lupus_a\", \"lupus_b\"]\n",
    "methods = [\"IMAT\"]\n",
    "\n",
    "for context in context_names:\n",
    "    for method in methods:\n",
    "        for disease in diseases:\n",
    "\n",
    "            disease_path = os.path.join(configs.datadir, \"results\", context, disease)\n",
    "            out_dir = os.path.join(configs.datadir, \"results\", context, disease)\n",
    "            tissue_gene_folder = os.path.join(configs.datadir, context)\n",
    "            os.makedirs(tissue_gene_folder, exist_ok=True)\n",
    "            inhibitors_file = f'{context}_inhibitors_Entrez.txt'\n",
    "\n",
    "            if not os.path.exists(disease_path):\n",
    "                continue\n",
    "\n",
    "            # load the results of step 3 to dictionary 'disease_files'\n",
    "            step3_results_file = os.path.join(\n",
    "                configs.datadir,\n",
    "                'results',\n",
    "                context,\n",
    "                disease,\n",
    "                'step2_results_files.json'\n",
    "            )\n",
    "\n",
    "            with open(step3_results_file) as json_file:\n",
    "                disease_files = json.load(json_file)\n",
    "\n",
    "            Disease_Down = disease_files['DN_Reg']\n",
    "            Disease_Up = disease_files['UP_Reg']\n",
    "            drug_raw_file = 'Repurposing_Hub_export.txt'\n",
    "\n",
    "            # Test if the user has specified a model for this cell type\n",
    "            # If they have not specified a model, use the automatically generated one\n",
    "            if context in model_files.keys():\n",
    "                tissueSpecificModelfile = model_files[context]\n",
    "            else:\n",
    "                tissueSpecificModelfile  = os.path.join(\n",
    "                    configs.datadir,\n",
    "                    \"results\",\n",
    "                    context,\n",
    "                    f\"{context}_SpecificModel_{method}.mat\"\n",
    "                )\n",
    "\n",
    "            if method == \"IMAT\":\n",
    "                ref_flux_file = os.path.join(\n",
    "                    configs.datadir,\n",
    "                    \"results\",\n",
    "                    context,\n",
    "                    \"IMAT_flux.csv\"\n",
    "                )\n",
    "                cmd = ' '.join(\n",
    "                    [\n",
    "                        'python3' , 'knock_out_simulation.py',\n",
    "                        '--context-model', f'\"{tissueSpecificModelfile}\"',\n",
    "                        '--context-name', f'\"{context}\"',\n",
    "                        '--disease-name', f'\"{disease}\"',\n",
    "                        '--disease-up', f'\"{Disease_Up}\"',\n",
    "                        '--disease-down', f'\"{Disease_Down}\"',\n",
    "                        '--raw-drug-file', f'\"{drug_raw_file}\"',\n",
    "                        '--reference-flux-file', f'\"{ref_flux_file}\"',\n",
    "                        #'--test-all'\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                !{cmd}\n",
    "\n",
    "\n",
    "            else:\n",
    "                cmd = ' '.join(\n",
    "                    [\n",
    "                        'python3' , 'knock_out_simulation.py',\n",
    "                        '--context-model', f'\"{tissueSpecificModelfile}\"',\n",
    "                        '--context-name', f'\"{context}\"',\n",
    "                        '--disease-name', f'\"{disease}\"',\n",
    "                        '--disease-up', f'\"{Disease_Up}\"',\n",
    "                        '--disease-down', f'\"{Disease_Down}\"',\n",
    "                        '--raw-drug-file', f'\"{drug_raw_file}\"',\n",
    "                        #'--test-all'\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                !{cmd}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "map_dir = os.path.join(\n",
    "    configs.datadir,\n",
    "    \"local_files\",\n",
    "    \"maps\",\n",
    "    \"community-maps\",\n",
    "    \"RECON1\"\n",
    ")\n",
    "\n",
    "map_dict = {\n",
    "    \"trypto\": os.path.join(map_dir, \"RECON1.Tryptophan metabolism.json\"),\n",
    "    \"lipid\": os.path.join(map_dir, \"RECON1.LIPID_METABOLISM.json\"),\n",
    "    \"retinol\": os.path.join(map_dir, \"RECON1.Inositol retinol metabolism.json\"),\n",
    "    \"glyco\": os.path.join(map_dir, \"RECON1.Glycolysis_TCA_PPP.json\"),\n",
    "    \"combined\": os.path.join(map_dir, \"RECON1.COMBINED.json\"),\n",
    "    \"carbo\": os.path.join(map_dir, \"RECON1.CARBOHYDRATE_METABOLISM.json\"),\n",
    "    \"amino\": os.path.join(map_dir, \"RECON1.Amino acid metabolism (partial).json\")\n",
    "}\n",
    "\n",
    "targets_dict = {\n",
    "    \"SLC2A1\": \"6513\",\n",
    "    \"SLC2A3\": \"6515\",\n",
    "    \"HPRT1\": \"3251\",\n",
    "    \"SLC10A1\": \"6554\",\n",
    "    \"DHODH\": \"1723\"\n",
    "}\n",
    "\n",
    "tests_arthritis = [\n",
    "    \"arthritis_imat_neg5_neg3\",\n",
    "    \"arthritis_imat_neg5_2\",\n",
    "]\n",
    "\n",
    "tests_lupus = [\n",
    "    \"lupus_a_imat_neg5_neg3\",\n",
    "    \"lupus_a_imat_neg5_2\",\n",
    "    \"lupus_b_imat_neg5_neg3\",\n",
    "    \"lupus_b_imat_neg5_2\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_test_results(contexts, tests, targets_dict):\n",
    "    for context in contexts:\n",
    "        for test in tests:\n",
    "            if \"imat\" in test.split(\"_\"):\n",
    "                params = \"_\".join(test.split(\"_\")[-2:])\n",
    "                algo = \"IMAT\"\n",
    "            else:\n",
    "                params = \"_\".join(test.split(\"_\")[-4])\n",
    "                algo = \"GIMME\"\n",
    "\n",
    "            test_dir = os.path.join(configs.datadir, \"results\", context, test)\n",
    "            if os.path.exists(test_dir):\n",
    "                ratio_file = os.path.join(test_dir, \"flux_ratios_KO.csv\")\n",
    "                ratio_df = pd.read_csv(ratio_file)\n",
    "                for targ, entrez in targets_dict.items():\n",
    "                    targ_flux = ratio_df[entrez]\n",
    "                    model_json=os.path.join(\n",
    "                        configs.datadir, \n",
    "                        \"results\", \n",
    "                        context,\n",
    "                        f\"{context}_SpecificModel_{algo}_{params}.json\"\n",
    "                    )\n",
    "\n",
    "                    model = cobra.io.load_json_model(model_json)\n",
    "                    for m in map_dict.keys():\n",
    "                        map_test_dir = os.path.join(\n",
    "                            configs.datadir,\n",
    "                            \"results\",\n",
    "                            context,\n",
    "                            \"figures\",\n",
    "                            \"maps\",\n",
    "                            test\n",
    "                        )\n",
    "                        if not os.path.exists(map_test_dir):\n",
    "                            os.makedirs(map_test_dir)\n",
    "                        map_targ_dir = os.path.join(map_test_dir, targ)\n",
    "                        if not os.path.exists(map_targ_dir):\n",
    "                            os.makedirs(map_targ_dir)   \n",
    "                        builder = Builder(map_json=map_dict[m])\n",
    "                        builder.model = model\n",
    "                        #solution = cobra.flux_analysis.pfba(model)\n",
    "                        #builder.reaction_data  = solution.fluxes\n",
    "                        builder.reaction_data = targ_flux\n",
    "                        #print(builder.fluxes.fluxes)\n",
    "                        #builder.fluxes = pd.read_csv(os.path.join(configs.datadir, \"results\", context, \"iMAT_flux.csv\"))[\"flux\"].tolist()\n",
    "                        builder.reaction_scale = [\n",
    "                            { 'type': 'value', value: 0.5, 'color': '#ffffbf', 'size': 10 },\n",
    "                            { 'type': 'value', value: 0.9, 'color': '#ffffbf', 'size': 10 },\n",
    "                            { 'type': 'value', value: 1.0, 'color': '#ffffbf', 'size': 10 },\n",
    "                            { 'type': 'value', value: 1.1, 'color': '#ffffbf', 'size': 10 },\n",
    "                            { 'type': 'value', value: 2.0, 'color': '#ffffbf', 'size': 10 }\n",
    "                        ]\n",
    "                        #builder.highlight_missing = TrueYeah I am still working on them. Cannot figure out a way to make them not contain a huge number of reactions though\n",
    "\n",
    "                        builder.reaction_no_data_color = \"#8e8e8e\"\n",
    "                        builder.save_html(\n",
    "                            os.path.join(\n",
    "                                map_targ_dir,\n",
    "                                f\"{m}_map_{context}_{test}_{targ}.html\"\n",
    "                            )\n",
    "                        )                  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import escher\n",
    "from escher import Builder\n",
    "import cobra\n",
    "import pandas as pd\n",
    "import os\n",
    "from project import configs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test = \"arthritis_imat_neg5_neg3\"\n",
    "context = \"naiveB\"\n",
    "if \"imat\" in test.split(\"_\"):\n",
    "    params = \"_\".join(test.split(\"_\")[-2:])\n",
    "    algo = \"IMAT\"\n",
    "else:\n",
    "    params = \"_\".join(test.split(\"_\")[-4])\n",
    "    algo = \"GIMME\"\n",
    "print(\"param: \", params)\n",
    "test_dir = os.path.join(configs.datadir, \"results\", context, test)\n",
    "if os.path.exists(test_dir):\n",
    "    ratio_file = os.path.join(test_dir, \"flux_ratios_KO.csv\")\n",
    "    ratio_df = pd.read_csv(ratio_file)\n",
    "    targ = \"SLC2A1\"\n",
    "    entrez = \"6513\"\n",
    "    targ_flux = ratio_df[entrez]\n",
    "    model_json=os.path.join(\n",
    "        configs.datadir, \n",
    "        \"results\", \n",
    "        context,\n",
    "        f\"{context}_SpecificModel_{algo}_{params}.json\"\n",
    "    )\n",
    "    print(model_json)\n",
    "    #model = cobra.io.load_json_model(model_json)\n",
    "    m = 'glyco'\n",
    "    map_test_dir = os.path.join(\n",
    "        configs.datadir,\n",
    "        \"results\",\n",
    "        context,\n",
    "        \"figures\",\n",
    "        \"maps\",\n",
    "        test\n",
    "    )\n",
    "    if not os.path.exists(map_test_dir):\n",
    "        os.makedirs(map_test_dir)\n",
    "    map_targ_dir = os.path.join(map_test_dir, targ)\n",
    "    if not os.path.exists(map_targ_dir):\n",
    "        os.makedirs(map_targ_dir)   "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#model = cobra.io.load_json_model(model_json)\n",
    "builder = Builder(map_json=map_dict[m])\n",
    "#builder.model = model\n",
    "builder.model_json = model_json"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "if 'builder' in locals(): del builder\n",
    "#solution = cobra.flux_analysis.pfba(model)\n",
    "#builder.reaction_data  = solution.fluxes\n",
    "rxns = [rxn.id for rxn in model.reactions]\n",
    "targ_flux.index = rxns\n",
    "#targ_flux.fillna(-9999,inplace=True)\n",
    "print(list(np.where(np.isnan(targ_flux.tolist()))))\n",
    "targ_flux.replace(np.inf, 9999, inplace=True)\n",
    "targ_flux.replace(-np.inf, -9999, inplace=True)\n",
    "targ_flux.replace(np.nan, 1.0 , inplace=True) # nans should be 1.0\n",
    "print(targ_flux)\n",
    "bad_f = []\n",
    "print(targ_flux.tolist()[117])\n",
    "print(type(targ_flux.tolist()[117]))\n",
    "for f in targ_flux.tolist():\n",
    "    bad_f.append(type(f))\n",
    "print(set(bad_f))\n",
    "    \n",
    "#builder.reaction_data = targ_flux\n",
    "#builder.reactions_styles=['color', 'style', 'text']\n",
    "#print(builder.fluxes.fluxes)\n",
    "#builder.fluxes = pd.read_csv(os.path.join(configs.datadir, \"results\", context, \"iMAT_flux.csv\"))[\"flux\"].tolist()\n",
    "rxn_scale = [\n",
    "    { 'type': 'value', 'value': -9999, 'color': '#000000', 'size': 10 },\n",
    "    { 'type': 'value', 'value': 0.5, 'color': '#2c7bb6', 'size': 10 },\n",
    "    { 'type': 'value', 'value': 0.9, 'color': '#abd9e9', 'size': 10 },\n",
    "    { 'type': 'value', 'value': 1.0, 'color': '#ffffbf', 'size': 10 },\n",
    "    { 'type': 'value', 'value': 1.1, 'color': '#fdae61', 'size': 10 },\n",
    "    { 'type': 'value', 'value': 2.0, 'color': '#d7191c', 'size': 10 },\n",
    "    { 'type': 'value', 'value': 9999, 'color': '#c90076', 'size': 10 },\n",
    "    { 'type': 'value', 'value': -500, 'color': '#8e8e8e', 'size': 10 }\n",
    "    \n",
    "]\n",
    "builder = Builder(\n",
    "    model = model,\n",
    "    map_json=map_dict[m],\n",
    "\n",
    "    reaction_data = targ_flux,\n",
    "    reaction_scale = rxn_scale,\n",
    "    highlight_missing = True,\n",
    "    reaction_no_data_color = '#8e8e8e',\n",
    "    reaction_styles = ['color', 'style', 'text']\n",
    ")\n",
    "#builder.highlight_missing = True\n",
    "builder.reaction_no_data_color = \"#8e8e8e\"\n",
    "builder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "map_file = os.path.join(\n",
    "     map_targ_dir,\n",
    "    f\"{m}_map_{context}_{test}_{targ}.html\"\n",
    ")\n",
    "print(map_file)\n",
    "builder.save_html(os.path.join(map_targ_dir, f\"{m}_map_{context}_{test}_{targ}.html\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "get_test_results(context_names, tests_arthritis, targets_dict)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
