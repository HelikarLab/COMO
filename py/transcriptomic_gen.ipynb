{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from sqlalchemy import Column, ForeignKey, Integer, String, Float\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import relationship, sessionmaker, load_only\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import GEOparse\n",
    "from GSEpipeline import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create declarative_base instance\n",
    "Base = declarative_base()\n",
    "\n",
    "#creates a create_engine instance at the bottom of the file\n",
    "engine = create_engine('sqlite:///transcriptomics.db')\n",
    "\n",
    "#we'll add classes here\n",
    "class Sample(Base):\n",
    "    __tablename__ = 'sample'\n",
    "\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    ENTREZ_GENE_ID = Column(String(250), nullable=False)\n",
    "    VALUE = Column(Float, nullable=False)\n",
    "    P_VALUE = Column(Float)\n",
    "    ABS_CALL = Column(String(2))\n",
    "    Sample = Column(String(64))\n",
    "\n",
    "\n",
    "class IDMapps(Base):\n",
    "    __tablename__ = 'id_entrez_map'\n",
    "\n",
    "    idx = Column(Integer, primary_key=True)\n",
    "    ID = Column(String(250))\n",
    "    ENTREZ = Column(String(250))\n",
    "\n",
    "\n",
    "class GSEinfo(Base):\n",
    "    __tablename__ = 'gseinfo'\n",
    "\n",
    "    Sample = Column(String(64), primary_key=True)\n",
    "    GSE = Column(String(64))\n",
    "    Platform = Column(String(64))\n",
    "\n",
    "Base.metadata.create_all(engine)\n",
    "\n",
    "DBSession = sessionmaker(bind=engine)\n",
    "session = DBSession()\n",
    "\n",
    "# find project root dir\n",
    "currentdir = os.getcwd()\n",
    "dirlist = currentdir.split('/')\n",
    "projectdir = '/'.join(dirlist[0:-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookupTranscriptomicsDB(gseXXX):\n",
    "    '''\n",
    "    check if gse already in database\n",
    "    :param gseXXX:\n",
    "    :return:\n",
    "    '''\n",
    "    df = pd.read_sql(session.query(GSEinfo).filter_by(GSE=gseXXX.gsename).options(load_only(\"Sample\", \"GSE\")).statement,\n",
    "                     session.bind)\n",
    "    gsm_list = gseXXX.gsm_platform.keys()\n",
    "    gsm_db = df.Sample.tolist()\n",
    "    if set(gsm_list) == set(gsm_db):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    # df = pd.read_sql(\n",
    "    #     session.query(Sample).filter_by(Sample='GSM60728').options(load_only(\"ABS_CALL\", \"ENTREZ_GENE_ID\")).statement,\n",
    "    #     session.bind,\n",
    "    #     index_col='ENTREZ_GENE_ID'\n",
    "    #     )\n",
    "    # df.drop('id', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateTranscriptomicsDB(gseXXX):\n",
    "    '''\n",
    "    Update GSE info to transcriptomics.db\n",
    "    :param gseXXX: gse object\n",
    "    :return:\n",
    "    '''\n",
    "    # df_clean = gseXXX.get_entrez_table_pipeline()\n",
    "    try:\n",
    "        df_clean = gseXXX.get_entrez_table_default(fromcsv=False) # for test so that no need to download RAW data files\n",
    "    except:\n",
    "        df_clean = gseXXX.get_entrez_table_pipeline()\n",
    "\n",
    "    df_clean.sort_index(inplace=True)\n",
    "\n",
    "    # write to database table sample\n",
    "    df_samples = pd.DataFrame([],columns=['ENTREZ_GENE_ID','VALUE','P_VALUE','ABS_CALL','Sample'])\n",
    "    df_samples.index.name = 'id'\n",
    "\n",
    "    cols_clean = list(df_clean)\n",
    "    for key,val in gseXXX.gsm_platform.items():\n",
    "        col_val = '{}.cel.gz'.format(key.lower())\n",
    "        col_abs = '{}.cel.gz.1'.format(key.lower())\n",
    "        col_p = '{}.cel.gz.2'.format(key.lower())\n",
    "        if not col_val in cols_clean:\n",
    "            continue\n",
    "        df_s = pd.DataFrame([])\n",
    "        df_s['ENTREZ_GENE_ID'] = df_clean['ENTREZ_GENE_ID']\n",
    "        df_s['VALUE'] = df_clean[col_val]\n",
    "        df_s['ABS_CALL'] = df_clean[col_abs]\n",
    "        df_s['P_VALUE'] = df_clean[col_p]\n",
    "        df_s['Sample'] = key.upper()\n",
    "        df_s.index.name='id'\n",
    "        df_samples = pd.concat([df_samples, df_s.dropna(how='any')], ignore_index=True, sort=True)\n",
    "\n",
    "    df_samples.index.name = 'id'\n",
    "    df_samples.to_sql(con=engine,name='sample',if_exists='replace',index_label='id')\n",
    "\n",
    "    # write to database table GSEinfo\n",
    "    df_gseinfo = pd.DataFrame([],columns=['Sample','GSE','Platform'])\n",
    "    df_gseinfo['Sample'] = pd.Series(list(gseXXX.gsm_platform.keys()))\n",
    "    df_gseinfo['Platform'] = pd.Series(list(gseXXX.gsm_platform.values()))\n",
    "    df_gseinfo['GSE'] = gseXXX.gsename\n",
    "\n",
    "    df_gseinfo.to_sql(con=engine,name='gseinfo',if_exists='replace',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetchLogicalTable(gsm_ids):\n",
    "    '''\n",
    "    Fetch the Logical Table Based on ABS_CALL of Samples\n",
    "    :param gsm_ids: list of sample names to fetch\n",
    "    :return: pandas dataframe\n",
    "    '''\n",
    "    df_results = pd.DataFrame([], columns=['ENTREZ_GENE_ID'])\n",
    "    df_results.set_index('ENTREZ_GENE_ID', inplace=True)\n",
    "    for gsm in gsm_ids:\n",
    "        # print(gsm)\n",
    "        df = pd.read_sql(\n",
    "            session.query(Sample).filter_by(Sample=gsm).options(load_only(\"ABS_CALL\", \"ENTREZ_GENE_ID\")).statement,\n",
    "            session.bind,\n",
    "            index_col='ENTREZ_GENE_ID')\n",
    "        df.drop('id', axis=1, inplace=True)\n",
    "        df.rename(columns={'ABS_CALL': gsm}, inplace=True)\n",
    "        df.loc[df[gsm] == 'A', gsm] = 0\n",
    "        df.loc[df[gsm] == 'P', gsm] = 1\n",
    "        df.loc[df[gsm] == 'M', gsm] = 1\n",
    "\n",
    "        df_results = pd.concat([df_results, df], axis=1, sort=False)\n",
    "\n",
    "    # Need to set index name after merge\n",
    "    df_results.index.name = 'ENTREZ_GENE_ID'\n",
    "    return df_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Merge Output\n",
    "def mergeLogicalTable(df_results):\n",
    "    '''\n",
    "    Merge the Rows of Logical Table belongs to the same ENTREZ_GENE_ID\n",
    "    :param df_results:\n",
    "    :return: pandas dataframe of merged table\n",
    "    '''\n",
    "    # step 1: get all plural ENTREZ_GENE_IDs in the input table, extract unique IDs\n",
    "    id_list = []\n",
    "    entrez_id_list = df_results[df_results.index.str.contains('///')].index.tolist()\n",
    "    for entrez_id in entrez_id_list:\n",
    "        entrez_ids = entrez_id.split(' /// ')\n",
    "        id_list.extend(entrez_ids)\n",
    "\n",
    "    # print(len(id_list))\n",
    "    # id_list\n",
    "    # step 2: print out information about merge\n",
    "    entrez_single_id_list = df_results[~df_results.index.str.contains('///')].index.tolist()\n",
    "    common_elements = list(set(entrez_single_id_list).intersection(set(id_list)))\n",
    "    # information of merge\n",
    "    print('{} single ENTREZ_GENE_IDs to merge'.format(len(common_elements)))\n",
    "    print('id_list: {}, set: {}'.format(len(id_list),len(set(id_list))))\n",
    "    print('entrez_single_id_list: {}, set: {}'.format(len(entrez_single_id_list),len(set(entrez_single_id_list))))\n",
    "    print('entrez_id_list: {}, set: {}'.format(len(entrez_id_list),len(set(entrez_id_list))))\n",
    "\n",
    "    dups = [x for x in id_list if id_list.count(x) > 1]\n",
    "    print('dups: {}, set: {}'.format(len(dups),len(set(dups))))\n",
    "    dups = set(dups).union(common_elements)\n",
    "\n",
    "    full_entre_id_sets = []\n",
    "    cnt = 0\n",
    "    entrez_dups_list = []\n",
    "    for dup_id in dups:\n",
    "        print(dup_id+':')\n",
    "        id_set = []\n",
    "        entrez_dups = []\n",
    "        for multi_ids in entrez_id_list:\n",
    "            if dup_id in multi_ids.split(' /// '):\n",
    "                print('{}'.format(multi_ids))\n",
    "                id_set.extend(multi_ids.split(' /// '))\n",
    "                entrez_dups.append(multi_ids)\n",
    "        id_set = list(set(id_set))\n",
    "        id_set.sort(key=int)\n",
    "        entrez_dups.extend(id_set)\n",
    "        full_entre_id = ' /// '.join(id_set)\n",
    "        print('Merged {}: {}\\n'.format(dup_id,full_entre_id))\n",
    "        full_entre_id_sets.append(full_entre_id)\n",
    "        entrez_dups_list.append(entrez_dups)\n",
    "        cnt+=1\n",
    "    print('{} id merged'.format(cnt))\n",
    "    entrez_dups_dict = dict(zip(full_entre_id_sets,entrez_dups_list))\n",
    "    # full_entre_id_sets = list(set(full_entre_id_sets))\n",
    "\n",
    "    df_results.reset_index(inplace=True)\n",
    "    for merged_entrez_id, entrez_dups_list in entrez_dups_dict.items():\n",
    "        df_results['ENTREZ_GENE_ID'].replace(to_replace=entrez_dups_list,\n",
    "                                             value=merged_entrez_id,\n",
    "                                             inplace=True)\n",
    "\n",
    "    df_results.set_index('ENTREZ_GENE_ID',inplace=True)\n",
    "\n",
    "    df_output = df_results.fillna(-1).groupby(level=0).max()\n",
    "    return df_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to complete the inquery of a sheet\n",
    "def queryTest(df):\n",
    "    sr = df['GSE ID']\n",
    "    gse_ids = sr[sr.str.match('GSE')].unique()\n",
    "    sr = df['Samples'].dropna()\n",
    "    gsm_ids = sr.unique()\n",
    "    print('---\\nStart Collecting Data for:')\n",
    "    print(gse_ids)\n",
    "    print(gsm_ids)\n",
    "    print('---\\n')\n",
    "    # fetch data of each gse if it is not in the database, update database\n",
    "    for gse_id in gse_ids:\n",
    "        gseXXX = GSEproject(gse_id,projectdir)\n",
    "        if lookupTranscriptomicsDB(gseXXX):\n",
    "            print(\"{} already in database, skip over.\".format(gseXXX.gsename))\n",
    "            continue\n",
    "        updateTranscriptomicsDB(gseXXX)\n",
    "\n",
    "    df_results = fetchLogicalTable(gsm_ids)\n",
    "    df_output = mergeLogicalTable(df_results)\n",
    "    return df_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input from user\n",
    "filename = 'GeneExpressionDataUsed.xlsx'\n",
    "sheet_name = list(range(5)) # first 5 sheets\n",
    "\n",
    "# gse2770 = GSEproject('GSE2770',projectdir)\n",
    "\n",
    "inqueryFullPath = os.path.join(projectdir, 'data', filename)\n",
    "inqueries = pd.read_excel(inqueryFullPath, sheet_name=sheet_name, header=0)\n",
    "\n",
    "for i in range(5):\n",
    "    # print(list(inqueries[i]))\n",
    "    inqueries[i].fillna(method='ffill',inplace=True)\n",
    "    df = inqueries[i].loc[:,['GSE ID','Samples','GPL ID','Instrument']]\n",
    "    df_output = queryTest(df)\n",
    "    filename = 'logicaltable_sheet_{}.csv'.format(i+1)\n",
    "    fullsavepath = os.path.join(projectdir,'data',filename)\n",
    "    df_output.to_csv(fullsavepath)\n",
    "    print('Save to {}'.format(fullsavepath))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
